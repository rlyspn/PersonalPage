From bd914ab500679a2766ac5c9eecd6c399b5637787 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Tue, 5 Mar 2013 18:27:51 -0500
Subject: [PATCH 01/99] added a file for notes.

---
 NOTES.txt |   20 ++++++++++++++++++++
 1 file changed, 20 insertions(+)
 create mode 100644 NOTES.txt

diff --git a/NOTES.txt b/NOTES.txt
new file mode 100644
index 0000000..03b52d0
--- /dev/null
+++ b/NOTES.txt
@@ -0,0 +1,20 @@
+
+
+# TODO
+
+## Reading (Books and Code):
+* LKD 58-61 - wait queues
+* LKD Ch. 4 - all about scheduling
+* LKD Ch. 6 - kernel data structures.  May be useful.
+* LKD Ch. 11 - kernel timers
+* Documentation/scheduler/sched-design-CFS.txt - scheduling classes
+* include/linux/sched.h 
+* kernel/sched.c
+* kernel/sched_fair.c
+* kernel/sched_rt.c
+* sched_class structure
+
+## Implementation:
+* Part 1:
+* Part 2:
+* Part 3:
-- 
1.7.9.5


From 16b56880921c91661efe5d76739e5b6898b5637e Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Tue, 5 Mar 2013 21:58:38 -0500
Subject: [PATCH 02/99] -added entries to system call table -defined syscall
 numbers in unistd_32.h -created netlock.c

---
 arch/x86/include/asm/unistd_32.h   |    3 +++
 arch/x86/kernel/syscall_table_32.S |    3 +++
 kernel/netlock.c                   |   19 +++++++++++++++++++
 3 files changed, 25 insertions(+)
 create mode 100644 kernel/netlock.c

diff --git a/arch/x86/include/asm/unistd_32.h b/arch/x86/include/asm/unistd_32.h
index f2bba78..58ccdfa 100644
--- a/arch/x86/include/asm/unistd_32.h
+++ b/arch/x86/include/asm/unistd_32.h
@@ -338,6 +338,9 @@
 #define __NR_dup3		330
 #define __NR_pipe2		331
 #define __NR_inotify_init1	332
+#define __NR_net_lock		333		/* Added on 3/5/2013 */
+#define __NR_net_unlock		334		/* Added on 3/5/2013 */
+#define __NR_net_lock_wait_timeout	335	/* Added on 3/5/2013 */
 
 #ifdef __KERNEL__
 
diff --git a/arch/x86/kernel/syscall_table_32.S b/arch/x86/kernel/syscall_table_32.S
index e2e86a0..ad876bc 100644
--- a/arch/x86/kernel/syscall_table_32.S
+++ b/arch/x86/kernel/syscall_table_32.S
@@ -332,3 +332,6 @@ ENTRY(sys_call_table)
 	.long sys_dup3			/* 330 */
 	.long sys_pipe2
 	.long sys_inotify_init1
+	.long sys_net_lock				/* Added on 3/5/2013 */
+	.long sys_net_unlock				/* Added on 3/5/2013 */
+	.long sys_net_lock_wait_timeout /* 335 */	/* Added on 3/5/2013 */
diff --git a/kernel/netlock.c b/kernel/netlock.c
new file mode 100644
index 0000000..041e39c
--- /dev/null
+++ b/kernel/netlock.c
@@ -0,0 +1,19 @@
+#include <syscalls.h>
+
+/* int net_lock(netlock_t type, u_int16_t timeout_val) */
+SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
+{
+
+}
+
+/* int net_unlock(void) */
+SYSCALL_DEFINE0(net_unlock)
+{
+
+}
+
+/* int net_lock_wait_timeout() */
+SYSCALL_DEFINE0(net_lock_wait_timeout)
+{
+
+}
-- 
1.7.9.5


From 968e0854af6aff58619b52f1ebadcd06b400a0b5 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 7 Mar 2013 14:28:35 -0500
Subject: [PATCH 03/99] -added framework for edf sched class.

---
 NOTES.txt          |   20 -----------
 kernel/sched_edf.c |   98 ++++++++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 98 insertions(+), 20 deletions(-)
 delete mode 100644 NOTES.txt
 create mode 100644 kernel/sched_edf.c

diff --git a/NOTES.txt b/NOTES.txt
deleted file mode 100644
index 03b52d0..0000000
--- a/NOTES.txt
+++ /dev/null
@@ -1,20 +0,0 @@
-
-
-# TODO
-
-## Reading (Books and Code):
-* LKD 58-61 - wait queues
-* LKD Ch. 4 - all about scheduling
-* LKD Ch. 6 - kernel data structures.  May be useful.
-* LKD Ch. 11 - kernel timers
-* Documentation/scheduler/sched-design-CFS.txt - scheduling classes
-* include/linux/sched.h 
-* kernel/sched.c
-* kernel/sched_fair.c
-* kernel/sched_rt.c
-* sched_class structure
-
-## Implementation:
-* Part 1:
-* Part 2:
-* Part 3:
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
new file mode 100644
index 0000000..36c31f5
--- /dev/null
+++ b/kernel/sched_edf.c
@@ -0,0 +1,98 @@
+check_preempt_curr_edf(struct rq *rq, struct task_struct *p, int
+		flags)
+{
+	/* TODO */
+}
+
+/*
+ * Get the next task.
+ */
+static void pick_next_task_edf(struct rq *rq)
+{
+	/* TODO */
+}
+
+/*
+ *
+ */
+static void put_prev_task_edf(struct rq *rq, struct task_struct *)
+{
+	/* TODO */
+}
+
+#ifdef CONFIG_SMP
+
+static int select_task_rq_edf(struct task_struct *p, int sd_flag, int flags)
+{
+	/* TODO */
+	return 0;
+}
+
+/*
+ */
+static unsigned long load_balance_edf(struct rq *rq, int cpu, struct rq *busy,
+		  unsigned long max_load_move,
+		  struct sched_domain *sd, enum cpu_idle_type idle,
+		  int *all_pinned, int *this_best_prio)
+{
+	/* TODO */
+	return 0;
+}
+
+static int move_one_task_edf(struct rq *rq, int cpu, struct rq *busy,
+		struct sched_domain *sd, enum cpu_idle_type)
+{
+	/* TODO */
+	return 0;
+}
+#endif /* CONFIG_SMP */
+
+static void set_curr_task_edf(struct rq *rq)
+{
+	/* TODO */
+}
+
+static void set_curr_task_edf(struct rq *rq)
+{
+	/* TODO */
+}
+
+static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
+{
+	/* TODO */
+}
+
+static void task_new_edf(struct rq *rq, struct task_struct *p)
+{
+	/* TODO */
+}
+
+static void prio_changed_edf(struct rq *rq, struct task_struct *p, int old,
+		int running)
+{
+	/* TODO */
+}
+
+static void switched_to_edf(struct rq *rq, struct task_struct *p, int running)
+{
+	/* TODO */
+}
+
+struct const struct sched_class edf_sched_class = {
+	.next = &idle_sched_class,
+	.enqueue_task = enqueue_task_fair,
+	.dequeue_task = dequeue_task_fair,
+	.check_preemt_curr = check_preempt_curr_edf,
+	.pick_next_task = pick_next_task_edf,
+	.put_prev_task = put_prev_task_fair,
+#ifdef CONFIG_SMP
+	.select_task_rq = select_task_rq_edf,
+	.load_balance = load_balance_edf,
+	.move_one_task = move_one_task_edf,
+#endif /* CONFIG_SMP */
+	.set_curr_task = set_curr_task_edf,
+	.task_tick = task_tick_edf,
+	.task_new = task_new_edf,
+	.prio_changed = prio_changed_edf,
+	.switched_to = switched_to_edf,
+};
-- 
1.7.9.5


From 099fbbbbcf56a07582ec2992a97f3408a1b9e00e Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 7 Mar 2013 18:07:28 -0500
Subject: [PATCH 04/99] -added return values and types for the basic system
 calls.

---
 kernel/netlock.c |   13 ++++++++++---
 1 file changed, 10 insertions(+), 3 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 041e39c..358409c 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -1,19 +1,26 @@
-#include <syscalls.h>
+#include <linux/syscalls.h>
+
+enum __netlock_t {
+	NET_LOCK_USE,
+	NET_LOCK_SLEEP,
+};
+typedef enum __netlock_t netlock_t;
 
 /* int net_lock(netlock_t type, u_int16_t timeout_val) */
 SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 {
-
+	return -1;
 }
 
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
 
+	return -1;
 }
 
 /* int net_lock_wait_timeout() */
 SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
-
+	return -1;
 }
-- 
1.7.9.5


From 0eb638397154f81fbe17494240ce695ebd9e696c Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 7 Mar 2013 19:56:33 -0500
Subject: [PATCH 05/99] -added rwsem to netlock

---
 kernel/Makefile  |    2 +-
 kernel/netlock.c |   27 ++++++++++++++++++++++++---
 2 files changed, 25 insertions(+), 4 deletions(-)

diff --git a/kernel/Makefile b/kernel/Makefile
index e4791b3..34fea09 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -10,7 +10,7 @@ obj-y     = sched.o fork.o exec_domain.o panic.o printk.o \
 	    kthread.o wait.o kfifo.o sys_ni.o posix-cpu-timers.o mutex.o \
 	    hrtimer.o rwsem.o nsproxy.o srcu.o semaphore.o \
 	    notifier.o ksysfs.o pm_qos_params.o sched_clock.o cred.o \
-	    async.o
+	    async.o netlock.o
 
 ifdef CONFIG_FUNCTION_TRACER
 # Do not trace debug files and internal ftrace files
diff --git a/kernel/netlock.c b/kernel/netlock.c
index 358409c..294b3bb 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -1,3 +1,4 @@
+#include <linux/rwswem.h>
 #include <linux/syscalls.h>
 
 enum __netlock_t {
@@ -6,17 +7,37 @@ enum __netlock_t {
 };
 typedef enum __netlock_t netlock_t;
 
+struct semaphore radio_rw;
+DECLARE_RWSEM(radio_rw);
+
+/*
+ * Called by the scheduler when a process on the EDF queue is moved to a queue
+ * with a lower priority
+ */
+int up_rw_lock() {
+	up_read(&radio_rw);
+	return 0;
+}
+
 /* int net_lock(netlock_t type, u_int16_t timeout_val) */
 SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 {
-	return -1;
+	if (type == 0) {
+		down_read(&radio_rw);
+		return 0;
+	} else if (type == 1) {
+		down_write(&radio_rw);
+		return 0;
+	} else {
+		return -1;
+	}
 }
 
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
-
-	return -1;
+	up_write(radio_rw);
+	return 0;
 }
 
 /* int net_lock_wait_timeout() */
-- 
1.7.9.5


From 1fba645a3e9c447befc4c39ccaec5779db84ade7 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 7 Mar 2013 19:59:04 -0500
Subject: [PATCH 06/99] -corrected netlock errors.

---
 kernel/netlock.c |    5 ++---
 1 file changed, 2 insertions(+), 3 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 294b3bb..862e732 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -1,4 +1,4 @@
-#include <linux/rwswem.h>
+#include <linux/rwsem.h>
 #include <linux/syscalls.h>
 
 enum __netlock_t {
@@ -7,7 +7,6 @@ enum __netlock_t {
 };
 typedef enum __netlock_t netlock_t;
 
-struct semaphore radio_rw;
 DECLARE_RWSEM(radio_rw);
 
 /*
@@ -36,7 +35,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
-	up_write(radio_rw);
+	up_write(&radio_rw);
 	return 0;
 }
 
-- 
1.7.9.5


From 0f8928e7083ae1dbc45a334711e14b786042a700 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Fri, 8 Mar 2013 18:12:45 -0500
Subject: [PATCH 07/99] -added SCHED_EDF to linux/include/sched.h

---
 include/linux/sched.h |    1 +
 1 file changed, 1 insertion(+)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 011db2f..9c086e5 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -38,6 +38,7 @@
 #define SCHED_BATCH		3
 /* SCHED_ISO: reserved but not implemented yet */
 #define SCHED_IDLE		5
+#define SCHED_EDF		6
 
 #ifdef __KERNEL__
 
-- 
1.7.9.5


From 9174bf9d3447b581d7a4ece7a585aa1ab8218517 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Fri, 8 Mar 2013 19:36:54 -0500
Subject: [PATCH 08/99] -corrected errors in edf_sched. -should be ready to
 fill in.

---
 kernel/netlock.c   |    3 ++-
 kernel/sched.c     |    1 +
 kernel/sched_edf.c |   47 +++++++++++++++++++++++++++++++----------------
 kernel/sched_rt.c  |    2 +-
 4 files changed, 35 insertions(+), 18 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 862e732..6136a63 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -13,7 +13,8 @@ DECLARE_RWSEM(radio_rw);
  * Called by the scheduler when a process on the EDF queue is moved to a queue
  * with a lower priority
  */
-int up_rw_lock() {
+int up_rw_lock()
+{
 	up_read(&radio_rw);
 	return 0;
 }
diff --git a/kernel/sched.c b/kernel/sched.c
index 10330ea..b5ccf54 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -1657,6 +1657,7 @@ static void cfs_rq_set_shares(struct cfs_rq *cfs_rq, unsigned long shares)
 #include "sched_stats.h"
 #include "sched_idletask.c"
 #include "sched_fair.c"
+#include "sched_edf.c" /* added 3/8/13 */
 #include "sched_rt.c"
 #ifdef CONFIG_SCHED_DEBUG
 # include "sched_debug.c"
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 36c31f5..637bf67 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -1,21 +1,40 @@
-check_preempt_curr_edf(struct rq *rq, struct task_struct *p, int
-		flags)
+
+static const struct sched_class edf_sched_class;
+
+static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 {
-	/* TODO */
+
+}
+
+static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
+		int sync)
+{
+
+}
+static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
+{
+
+}
+static void yield_task_edf(struct rq *rq)
+{
+
 }
 
 /*
  * Get the next task.
  */
-static void pick_next_task_edf(struct rq *rq)
+static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
 	/* TODO */
+
+	struct task_struct *ts;
+	return ts;
 }
 
 /*
  *
  */
-static void put_prev_task_edf(struct rq *rq, struct task_struct *)
+static void put_prev_task_edf(struct rq *rq, struct task_struct *p)
 {
 	/* TODO */
 }
@@ -52,11 +71,6 @@ static void set_curr_task_edf(struct rq *rq)
 	/* TODO */
 }
 
-static void set_curr_task_edf(struct rq *rq)
-{
-	/* TODO */
-}
-
 static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
 {
 	/* TODO */
@@ -78,13 +92,14 @@ static void switched_to_edf(struct rq *rq, struct task_struct *p, int running)
 	/* TODO */
 }
 
-struct const struct sched_class edf_sched_class = {
-	.next = &idle_sched_class,
-	.enqueue_task = enqueue_task_fair,
-	.dequeue_task = dequeue_task_fair,
-	.check_preemt_curr = check_preempt_curr_edf,
+static const struct sched_class edf_sched_class = {
+	.next = &fair_sched_class,
+	.enqueue_task = enqueue_task_edf,
+	.dequeue_task = dequeue_task_edf,
+	.yield_task = yield_task_edf,
+	.check_preempt_curr = check_preempt_curr_edf,
 	.pick_next_task = pick_next_task_edf,
-	.put_prev_task = put_prev_task_fair,
+	.put_prev_task = put_prev_task_edf,
 #ifdef CONFIG_SMP
 	.select_task_rq = select_task_rq_edf,
 	.load_balance = load_balance_edf,
diff --git a/kernel/sched_rt.c b/kernel/sched_rt.c
index bac1061..514237a 100644
--- a/kernel/sched_rt.c
+++ b/kernel/sched_rt.c
@@ -1512,7 +1512,7 @@ static void set_curr_task_rt(struct rq *rq)
 }
 
 static const struct sched_class rt_sched_class = {
-	.next			= &fair_sched_class,
+	.next			= &edf_sched_class,
 	.enqueue_task		= enqueue_task_rt,
 	.dequeue_task		= dequeue_task_rt,
 	.yield_task		= yield_task_rt,
-- 
1.7.9.5


From d24c3fb824e6c8168ef91e3a0795c150b78e0bf0 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Wed, 13 Mar 2013 22:53:21 -0400
Subject: [PATCH 09/99] -added sched_edf_entity. -added edf_entity to
 task_struct -added edf_rq. -added date to .next in
 rt_sched_class.

---
 include/linux/sched.h |    7 +++++++
 kernel/sched.c        |    8 ++++++++
 kernel/sched_rt.c     |    2 +-
 3 files changed, 16 insertions(+), 1 deletion(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 9c086e5..5f919e3 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1112,6 +1112,12 @@ struct sched_rt_entity {
 #endif
 };
 
+/* Added 3/9/13 */
+struct sched_edf_entity {
+	u_int16_t deadline;
+	struct rb_node node;
+};
+
 struct task_struct {
 	volatile long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
 	void *stack;
@@ -1132,6 +1138,7 @@ struct task_struct {
 	const struct sched_class *sched_class;
 	struct sched_entity se;
 	struct sched_rt_entity rt;
+	struct sched_edf_entity edf; /* Added 3/9/13 */
 
 #ifdef CONFIG_PREEMPT_NOTIFIERS
 	/* list of struct preempt_notifier: */
diff --git a/kernel/sched.c b/kernel/sched.c
index b5ccf54..3308c83 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -399,6 +399,14 @@ static inline struct task_group *task_group(struct task_struct *p)
 
 #endif	/* CONFIG_GROUP_SCHED */
 
+
+/* Added: 3/9/13 */
+struct edf_rq {
+	struct rb_root radio_tasks;
+	struct rb_node *bottom_left;
+	struct rq *rq;
+};
+
 /* CFS-related fields in a runqueue */
 struct cfs_rq {
 	struct load_weight load;
diff --git a/kernel/sched_rt.c b/kernel/sched_rt.c
index 514237a..2b74e85 100644
--- a/kernel/sched_rt.c
+++ b/kernel/sched_rt.c
@@ -1512,7 +1512,7 @@ static void set_curr_task_rt(struct rq *rq)
 }
 
 static const struct sched_class rt_sched_class = {
-	.next			= &edf_sched_class,
+	.next			= &edf_sched_class, /* Added 3/8/13 */
 	.enqueue_task		= enqueue_task_rt,
 	.dequeue_task		= dequeue_task_rt,
 	.yield_task		= yield_task_rt,
-- 
1.7.9.5


From c5aa18050ed56c80d67de5d2b1ee074ab1417988 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sun, 17 Mar 2013 18:33:01 -0400
Subject: [PATCH 10/99] -added SCHED_EDF case to __setScheduler -added
 enqueue_edf_entity -added enqueue_task_edf -added
 various implementation notes

---
 include/linux/sched.h |    8 +++++--
 kernel/sched.c        |   10 ++++++++-
 kernel/sched_edf.c    |   55 ++++++++++++++++++++++++++++++++++++++++++++++---
 kernel/sched_fair.c   |    7 +++++++
 4 files changed, 74 insertions(+), 6 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 5f919e3..da11b6d 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -44,6 +44,10 @@
 
 struct sched_param {
 	int sched_priority;
+	/* I think that we can get away with just using the int priority.  
+	 * An unsigned 16bit number will still retain its value in an int.
+	 */
+	int deadline;
 };
 
 #include <asm/param.h>	/* for HZ */
@@ -1114,8 +1118,8 @@ struct sched_rt_entity {
 
 /* Added 3/9/13 */
 struct sched_edf_entity {
-	u_int16_t deadline;
-	struct rb_node node;
+	unsigned long deadline;
+	struct rb_node task_node;
 };
 
 struct task_struct {
diff --git a/kernel/sched.c b/kernel/sched.c
index 3308c83..661ca55 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -402,7 +402,7 @@ static inline struct task_group *task_group(struct task_struct *p)
 
 /* Added: 3/9/13 */
 struct edf_rq {
-	struct rb_root radio_tasks;
+	struct rb_root radio_task_root;
 	struct rb_node *bottom_left;
 	struct rq *rq;
 };
@@ -5298,6 +5298,9 @@ __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 	case SCHED_RR:
 		p->sched_class = &rt_sched_class;
 		break;
+	case SCHED_EDF: /* Added 3/14/13 */
+		p->sched_class = &edf_sched_class;
+		break;
 	}
 
 	p->rt_priority = prio;
@@ -5420,6 +5423,9 @@ recheck:
 		goto recheck;
 	}
 	update_rq_clock(rq);
+	/* It makes sense to test if the task is on the CFS because that is
+	 * where it is most likely to be.
+	 */
 	on_rq = p->se.on_rq;
 	running = task_current(rq, p);
 	if (on_rq)
@@ -5428,6 +5434,8 @@ recheck:
 		p->sched_class->put_prev_task(rq, p);
 
 	oldprio = p->prio;
+
+	/* This is where the p->sched_class actually gets set. */
 	__setscheduler(rq, p, policy, param->sched_priority);
 
 	if (running)
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 637bf67..a180205 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -1,8 +1,60 @@
 
 static const struct sched_class edf_sched_class;
 
+#define for_each_sched_edf_entity(edf_se) \
+	for (; edf_se; edf_se = NULL)
+
+static inline s64 get_deadline_key(struct sched_edf_entity *edf_entity)
+{
+	return edf_entity->deadline;
+}
+
+static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity
+		*edf_entity, int wakeup)
+{
+	/* This insert method is taken from the cfs enqueue function.  We have
+	 * very similary needs so it made sense to look at their code.
+	 */
+	struct rb_node **link = &erq->radio_task_root.rb_node;
+	struct rb_node *parent = NULL;
+	struct sched_edf_entity *current_entity;
+	int leftmost = 1;
+	s64 key = get_deadline_key(edf_entity);
+
+	while (*link) {
+		parent = *link;
+		current_entity = rb_entry(parent, struct sched_edf_entity,
+				task_node);
+
+		if (key < get_deadline_key(current_entity)) {
+			link = &parent->rb_left;
+		} else {
+			link = &parent->rb_right;
+			/* If you go right then you know it's not the
+			 * smallest
+			 */
+			leftmost = 0;
+		}
+	}
+	if (leftmost)
+		erq->bottom_left = &edf_entity->task_node;
+
+	rb_link_node(&edf_entity->task_node, parent, link);
+	rb_insert_color(&edf_entity->task_node, &erq->radio_task_root);
+}
+
+/**
+ * Called when a task is to be enqueued. Expects that the sched_edf_entity
+ * already has it's deadline set in hertz.
+ */
 static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 {
+	struct edf_rq *erq;
+	struct sched_edf_entity *edf_entity = &p->edf;
+
+	for_each_sched_edf_entity(edf_entity){
+		enqueue_edf_entity(erq, edf_entity, -1);
+	}
 
 }
 
@@ -26,9 +78,6 @@ static void yield_task_edf(struct rq *rq)
 static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
 	/* TODO */
-
-	struct task_struct *ts;
-	return ts;
 }
 
 /*
diff --git a/kernel/sched_fair.c b/kernel/sched_fair.c
index 0566f2a..b664a78 100644
--- a/kernel/sched_fair.c
+++ b/kernel/sched_fair.c
@@ -944,9 +944,16 @@ static inline void hrtick_update(struct rq *rq)
  */
 static void enqueue_task_fair(struct rq *rq, struct task_struct *p, int wakeup)
 {
+
+	/* cfs related fields to be used in the runqueue.  This contains an rq
+	 * structure that will be used as the attachment point for the rq.
+	 */
 	struct cfs_rq *cfs_rq;
 	struct sched_entity *se = &p->se;
 
+	/**
+	 * For each sched_entity test if it is currently on the rq.
+	 */
 	for_each_sched_entity(se) {
 		if (se->on_rq)
 			break;
-- 
1.7.9.5


From 701639d8c561fa18fd3b9c9469b5e07ba9f84f8e Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Tue, 19 Mar 2013 02:28:06 -0400
Subject: [PATCH 11/99] modified sched_edf_entity in sched.h

---
 include/linux/sched.h |    3 +++
 1 file changed, 3 insertions(+)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index da11b6d..0765c71 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1120,6 +1120,9 @@ struct sched_rt_entity {
 struct sched_edf_entity {
 	unsigned long deadline;
 	struct rb_node task_node;
+	struct sched_edf_entity *parent;
+	struct edf_rq *edf_rq;
+	struct edf_rq *my_q;
 };
 
 struct task_struct {
-- 
1.7.9.5


From 916124a4bb01a4cdc68775b33cb8f2c9c98c0526 Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Tue, 19 Mar 2013 17:32:02 -0400
Subject: [PATCH 12/99] modified __sched_setscheduler with SCHED_EDF

---
 kernel/sched.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index 661ca55..5992947 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -5342,7 +5342,7 @@ recheck:
 		policy = oldpolicy = p->policy;
 	else if (policy != SCHED_FIFO && policy != SCHED_RR &&
 			policy != SCHED_NORMAL && policy != SCHED_BATCH &&
-			policy != SCHED_IDLE)
+			policy != SCHED_IDLE && policy != SCHED_EDF) 
 		return -EINVAL;
 	/*
 	 * Valid priorities for SCHED_FIFO and SCHED_RR are
-- 
1.7.9.5


From 502fe35e402292d13b5aff3ec4470e2b757a32bc Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Thu, 21 Mar 2013 17:26:57 -0400
Subject: [PATCH 13/99] modified sched.h and sched.c

---
 include/linux/sched.h |    3 ---
 kernel/sched.c        |    2 +-
 2 files changed, 1 insertion(+), 4 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 0765c71..da11b6d 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1120,9 +1120,6 @@ struct sched_rt_entity {
 struct sched_edf_entity {
 	unsigned long deadline;
 	struct rb_node task_node;
-	struct sched_edf_entity *parent;
-	struct edf_rq *edf_rq;
-	struct edf_rq *my_q;
 };
 
 struct task_struct {
diff --git a/kernel/sched.c b/kernel/sched.c
index 5992947..4547611 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -5342,7 +5342,7 @@ recheck:
 		policy = oldpolicy = p->policy;
 	else if (policy != SCHED_FIFO && policy != SCHED_RR &&
 			policy != SCHED_NORMAL && policy != SCHED_BATCH &&
-			policy != SCHED_IDLE && policy != SCHED_EDF) 
+			policy != SCHED_IDLE) 
 		return -EINVAL;
 	/*
 	 * Valid priorities for SCHED_FIFO and SCHED_RR are
-- 
1.7.9.5


From 3869381d2649631bc89fe425fcee530a73d26f39 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Thu, 21 Mar 2013 19:32:04 -0400
Subject: [PATCH 14/99] temporarily changed the .next in rt_sched_class back
 to fair_sched_class to make sure we can correctly
 start the emulator before finishing the EDF scheduler

---
 kernel/sched_rt.c |    7 ++++++-
 1 file changed, 6 insertions(+), 1 deletion(-)

diff --git a/kernel/sched_rt.c b/kernel/sched_rt.c
index 2b74e85..a9b4d0c 100644
--- a/kernel/sched_rt.c
+++ b/kernel/sched_rt.c
@@ -1512,7 +1512,12 @@ static void set_curr_task_rt(struct rq *rq)
 }
 
 static const struct sched_class rt_sched_class = {
-	.next			= &edf_sched_class, /* Added 3/8/13 */
+	/*
+	 *Before we completely finish the EDF scheduler,we should not 
+	 *change the .next, or the emulator cannot be started correctly.
+	 */
+//	.next			= &edf_sched_class,
+	.next			= &fair_sched_class,
 	.enqueue_task		= enqueue_task_rt,
 	.dequeue_task		= dequeue_task_rt,
 	.yield_task		= yield_task_rt,
-- 
1.7.9.5


From 0c2ebd959594c1f1e8ee50277f8b8e1b824b254e Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Fri, 22 Mar 2013 00:29:06 -0400
Subject: [PATCH 15/99] -added timer in net_lock_wait_timeout() -modified
 net_lock() and net_unlock()

---
 kernel/netlock.c |   42 ++++++++++++++++++++++++++++++++++++++----
 1 file changed, 38 insertions(+), 4 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 6136a63..f971e7d 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -1,5 +1,10 @@
 #include <linux/rwsem.h>
 #include <linux/syscalls.h>
+#include <linux/timer.h>
+#include <linux/jiffies.h>
+
+unsigned long earlist_deadline;
+struct timer_list edf_timer;
 
 enum __netlock_t {
 	NET_LOCK_USE,
@@ -19,13 +24,26 @@ int up_rw_lock()
 	return 0;
 }
 
+unsigned long update(unsigned long new_deadline)
+{
+	if (new_deadline < earlist_deadline)
+		return new_deadline;
+	else
+		return earlist_deadline;
+}
+
 /* int net_lock(netlock_t type, u_int16_t timeout_val) */
 SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 {
-	if (type == 0) {
+	unsigned long deadline;
+	if (type == NET_LOCK_USE) {
+		deadline = jiffies + timeout_val * HZ;
+		earlist_deadline = update(deadline);
 		down_read(&radio_rw);
+		/* add setscheduler here */
+		
 		return 0;
-	} else if (type == 1) {
+	} else if (type == NET_LOCK_SLEEP) {
 		down_write(&radio_rw);
 		return 0;
 	} else {
@@ -36,12 +54,28 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
-	up_write(&radio_rw);
+	up_read(&radio_rw);
 	return 0;
 }
 
+void sleep_unlock(unsigned long data)
+{
+	up_write(&radio_rw);
+}
+
 /* int net_lock_wait_timeout() */
 SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
-	return -1;
+	/* 
+	   Only the first application needs to initialize the timer. Whenever a
+	   new application wants to acquire the use-lock, only the expires may 
+	   be modified via mod_timer(). We should try to improve the following 
+	   codes.
+	*/
+	init_timer(&edf_timer);
+	edf_timer.expires = earlist_deadline;
+	edf_timer.data = 0;	/* We need to research the usage of "data" */
+	edf_timer.function = sleep_unlock;
+	add_timer(&edf_timer);
+	return 0;
 }
-- 
1.7.9.5


From 185f3762a4358fb99176b0c750b12c3a1f59546f Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Fri, 22 Mar 2013 04:19:22 -0400
Subject: [PATCH 16/99] added test programs and modified netlock.c

---
 kernel/netlock.c         |   11 ++++++-----
 user_tests/my_net_app.c  |   35 +++++++++++++++++++++++++++++++++++
 user_tests/net_monitor.c |   28 ++++++++++++++++++++++++++++
 3 files changed, 69 insertions(+), 5 deletions(-)
 create mode 100644 user_tests/my_net_app.c
 create mode 100644 user_tests/net_monitor.c

diff --git a/kernel/netlock.c b/kernel/netlock.c
index f971e7d..9e3fc36 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -3,7 +3,7 @@
 #include <linux/timer.h>
 #include <linux/jiffies.h>
 
-unsigned long earlist_deadline;
+unsigned long earliest_deadline;
 struct timer_list edf_timer;
 
 enum __netlock_t {
@@ -26,10 +26,10 @@ int up_rw_lock()
 
 unsigned long update(unsigned long new_deadline)
 {
-	if (new_deadline < earlist_deadline)
+	if (new_deadline < earliest_deadline)
 		return new_deadline;
 	else
-		return earlist_deadline;
+		return earliest_deadline;
 }
 
 /* int net_lock(netlock_t type, u_int16_t timeout_val) */
@@ -38,7 +38,8 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 	unsigned long deadline;
 	if (type == NET_LOCK_USE) {
 		deadline = jiffies + timeout_val * HZ;
-		earlist_deadline = update(deadline);
+		earliest_deadline = update(deadline);
+		mod_timer(&edf_timer, jiffies + earliest_deadline);
 		down_read(&radio_rw);
 		/* add setscheduler here */
 		
@@ -73,7 +74,7 @@ SYSCALL_DEFINE0(net_lock_wait_timeout)
 	   codes.
 	*/
 	init_timer(&edf_timer);
-	edf_timer.expires = earlist_deadline;
+	edf_timer.expires = earliest_deadline;
 	edf_timer.data = 0;	/* We need to research the usage of "data" */
 	edf_timer.function = sleep_unlock;
 	add_timer(&edf_timer);
diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
new file mode 100644
index 0000000..d1da050
--- /dev/null
+++ b/user_tests/my_net_app.c
@@ -0,0 +1,35 @@
+#include<stdio.h>
+#include <stdlib.h>
+#include <dirent.h>
+#include <sys/types.h>
+#include <sys/syscall.h>
+#include <unistd.h>
+
+#ifdef __X86_32__
+# define __NR_net_lock 333
+# define __NR_net_unlock 334
+# define __NR_net_lock_wait_timeout 335
+#endif
+
+int main(int argc, char *argv[])
+{
+	char errormsg[] = "Error: my_net_app <wait> <timeout> <spin>";
+	char *str[argc];
+	int i;
+	int j;
+	
+	if (strcmp(argv[0], "./my_net_app") == 0) {
+		if (argc != 4) {
+			printf("Please provide a valid command.\n");
+			fprintf(stderr, errormsg);
+			return -1;
+		}
+		for (i =0; i < argc; i++)
+			str[i] = argv[i];
+		sleep(str[1]);
+		flag = syscall(__NR_net_lock, 0, str[2]);
+		if (flag != 0)
+			printf("Requiring lock failed.\n");
+		
+	return 0;
+}
diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
new file mode 100644
index 0000000..02b7de0
--- /dev/null
+++ b/user_tests/net_monitor.c
@@ -0,0 +1,28 @@
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <dirent.h>
+#include <sys/types.h>
+#include <sys/syscall.h>
+#include <unistd.h>
+
+#ifdef __X86_32__
+# define __NR_net_lock 333
+# define __NR_net_unlock 334
+# define __NR_net_lock_wait_timeout 335
+#endif
+
+int main(int argc, const char * argv[])
+{
+	int flag1;
+	int flag2;
+	while (1) {
+		flag1 = syscall(__NR_net_lock, 1, NULL);
+		if (flag1 != 0)
+			printf("Requiring lock failed.\n");
+		flag2 = syscall(__NR_net_lock_wait_timeout);
+		if (flag2 != 0)
+			printf("Waking up sleeper failed.\n");
+	}
+	return 0;
+}
-- 
1.7.9.5


From bbfedde97859cc3abf02869c5acbb46724be0a7a Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Fri, 22 Mar 2013 17:44:21 -0400
Subject: [PATCH 17/99] -modified timer in netlock.c -fixed errors
 net_monitor.c -finished the remaining of my_net_app.c

---
 kernel/netlock.c         |   22 ++++++---------
 user_tests/my_net_app.c  |   70 +++++++++++++++++++++++++++++++++-------------
 user_tests/net_monitor.c |   13 +++------
 3 files changed, 63 insertions(+), 42 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 9e3fc36..d6bff70 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -2,13 +2,14 @@
 #include <linux/syscalls.h>
 #include <linux/timer.h>
 #include <linux/jiffies.h>
+#include <linux/kernel.h>
 
 unsigned long earliest_deadline;
 struct timer_list edf_timer;
 
 enum __netlock_t {
 	NET_LOCK_USE,
-	NET_LOCK_SLEEP,
+	NET_LOCK_SLEEP
 };
 typedef enum __netlock_t netlock_t;
 
@@ -24,12 +25,11 @@ int up_rw_lock()
 	return 0;
 }
 
-unsigned long update(unsigned long new_deadline)
+void update_timer(unsigned long new_deadline)
 {
-	if (new_deadline < earliest_deadline)
-		return new_deadline;
-	else
-		return earliest_deadline;
+	earliest_deadline = min(new_deadline, earliest_deadline);
+	if (earliest_deadline == new_deadline)
+		mod_timer(&edf_timer, earliest_deadline);
 }
 
 /* int net_lock(netlock_t type, u_int16_t timeout_val) */
@@ -38,14 +38,14 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 	unsigned long deadline;
 	if (type == NET_LOCK_USE) {
 		deadline = jiffies + timeout_val * HZ;
-		earliest_deadline = update(deadline);
-		mod_timer(&edf_timer, jiffies + earliest_deadline);
+		update_timer(deadline);
 		down_read(&radio_rw);
 		/* add setscheduler here */
 		
 		return 0;
 	} else if (type == NET_LOCK_SLEEP) {
 		down_write(&radio_rw);
+		earliest_deadline = ULONG_MAX;
 		return 0;
 	} else {
 		return -1;
@@ -67,12 +67,6 @@ void sleep_unlock(unsigned long data)
 /* int net_lock_wait_timeout() */
 SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
-	/* 
-	   Only the first application needs to initialize the timer. Whenever a
-	   new application wants to acquire the use-lock, only the expires may 
-	   be modified via mod_timer(). We should try to improve the following 
-	   codes.
-	*/
 	init_timer(&edf_timer);
 	edf_timer.expires = earliest_deadline;
 	edf_timer.data = 0;	/* We need to research the usage of "data" */
diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index d1da050..cde65fd 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -1,35 +1,67 @@
-#include<stdio.h>
+#include <stdio.h>
 #include <stdlib.h>
-#include <dirent.h>
-#include <sys/types.h>
 #include <sys/syscall.h>
+#include <sys/time.h>
 #include <unistd.h>
 
-#ifdef __X86_32__
-# define __NR_net_lock 333
-# define __NR_net_unlock 334
-# define __NR_net_lock_wait_timeout 335
-#endif
+#define __NR_net_lock 333
+#define __NR_net_unlock 334
+#define __NR_net_lock_wait_timeout 335
+
+void print_sec()
+{
+	struct timeval tv;
+	gettimeofday(&tv, NULL);
+	printf("%lu: ", tv.tv_sec);
+}
 
 int main(int argc, char *argv[])
 {
-	char errormsg[] = "Error: my_net_app <wait> <timeout> <spin>";
-	char *str[argc];
+	pid_t pid;
+	int wait;
+	int timeout;
+	int spin;
+	int flag;
 	int i;
-	int j;
-	
 	if (strcmp(argv[0], "./my_net_app") == 0) {
 		if (argc != 4) {
 			printf("Please provide a valid command.\n");
-			fprintf(stderr, errormsg);
+			printf("e.g. ./my_net_app <wait> <timeout> <spin>\n");
 			return -1;
 		}
-		for (i =0; i < argc; i++)
-			str[i] = argv[i];
-		sleep(str[1]);
-		flag = syscall(__NR_net_lock, 0, str[2]);
-		if (flag != 0)
+		wait = atoi(argv[1]);
+		timeout = atoi(argv[2]);
+		spin = atoi(argv[3]);
+		pid = getpid();
+		print_sec();
+		printf("sleeping ");
+		printf("pid:%d ", pid);
+		printf("args:%d,%d\n", wait, timeout);
+		/* start sleeping for wait seconds */
+		sleep(wait);
+		print_sec();
+		printf("calling_net_lock ");	
+		printf("pid:%d\n", pid);
+		/* start acquiring the use lock */
+		flag = syscall(__NR_net_lock, 0, timeout);
+		if (flag != 0) {
 			printf("Requiring lock failed.\n");
-		
+			return -1;
+		}
+		print_sec();
+		printf("return_net_lock ");
+		printf("pid:%d\n", pid);
+		/* start entering the loop */
+		for (i = 0; i < spin; i++);
+		print_sec();
+		printf("calling_net_unlock ");
+		printf("pid:%d\n", pid);
+		/* start releasing the use lock */
+		flag = syscall(__NR_net_unlock);
+		if (flag != 0) {
+			printf("Requiring unlock failed.\n");
+			return -1;
+		}
+	}
 	return 0;
 }
diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
index 02b7de0..03b8743 100644
--- a/user_tests/net_monitor.c
+++ b/user_tests/net_monitor.c
@@ -1,23 +1,18 @@
 #include <stdio.h>
-#include <string.h>
 #include <stdlib.h>
-#include <dirent.h>
-#include <sys/types.h>
 #include <sys/syscall.h>
 #include <unistd.h>
 
-#ifdef __X86_32__
-# define __NR_net_lock 333
-# define __NR_net_unlock 334
-# define __NR_net_lock_wait_timeout 335
-#endif
+#define __NR_net_lock 333
+#define __NR_net_unlock 334
+#define __NR_net_lock_wait_timeout 335
 
 int main(int argc, const char * argv[])
 {
 	int flag1;
 	int flag2;
 	while (1) {
-		flag1 = syscall(__NR_net_lock, 1, NULL);
+		flag1 = syscall(__NR_net_lock, 1, 0);
 		if (flag1 != 0)
 			printf("Requiring lock failed.\n");
 		flag2 = syscall(__NR_net_lock_wait_timeout);
-- 
1.7.9.5


From 4893d63b0425d3dbde9f360767869a9f716aadb5 Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Fri, 22 Mar 2013 18:55:44 -0400
Subject: [PATCH 18/99] added user_setsched.c syscall

---
 kernel/user_setsched.c |   16 ++++++++++++++++
 1 file changed, 16 insertions(+)
 create mode 100644 kernel/user_setsched.c

diff --git a/kernel/user_setsched.c b/kernel/user_setsched.c
new file mode 100644
index 0000000..342ac6b
--- /dev/null
+++ b/kernel/user_setsched.c
@@ -0,0 +1,16 @@
+#include <linux/timer.h>
+#include <linux/jiffies.h>
+#include <linux/kernel.h>
+
+/* int user_setsched(pid_t pid, int policy, u_int16_t timeout_val) */
+SYSCALL_DEFINE3(user_setsched, pid_t, pid, int, policy, u_int16_t, timeout_val)
+{
+	struct task_struct *crnt_tsk;
+	struct sched_param *param;
+	unsigned long deadline;
+
+	crnt_tsk = find_task_by_vpid(pid);
+	deadline = jiffies + timeout_val * HZ;
+	param.deadline = deadline;
+	return	sched_setscheduler(&crnt_tsk, policy, &param);
+}
-- 
1.7.9.5


From 8d4500254ea28c17eadb738b1f9d472d1e60edb0 Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Fri, 22 Mar 2013 19:24:40 -0400
Subject: [PATCH 19/99] added syscall user_setsched to systable and unistd

---
 arch/x86/include/asm/unistd_32.h   |    1 +
 arch/x86/kernel/syscall_table_32.S |    1 +
 kernel/Makefile                    |    2 +-
 kernel/user_setsched.c             |    2 ++
 4 files changed, 5 insertions(+), 1 deletion(-)

diff --git a/arch/x86/include/asm/unistd_32.h b/arch/x86/include/asm/unistd_32.h
index 58ccdfa..9407755 100644
--- a/arch/x86/include/asm/unistd_32.h
+++ b/arch/x86/include/asm/unistd_32.h
@@ -341,6 +341,7 @@
 #define __NR_net_lock		333		/* Added on 3/5/2013 */
 #define __NR_net_unlock		334		/* Added on 3/5/2013 */
 #define __NR_net_lock_wait_timeout	335	/* Added on 3/5/2013 */
+#define __NR_user_setsched	336		/* Added on 3/22/2013*/
 
 #ifdef __KERNEL__
 
diff --git a/arch/x86/kernel/syscall_table_32.S b/arch/x86/kernel/syscall_table_32.S
index ad876bc..54087fb 100644
--- a/arch/x86/kernel/syscall_table_32.S
+++ b/arch/x86/kernel/syscall_table_32.S
@@ -335,3 +335,4 @@ ENTRY(sys_call_table)
 	.long sys_net_lock				/* Added on 3/5/2013 */
 	.long sys_net_unlock				/* Added on 3/5/2013 */
 	.long sys_net_lock_wait_timeout /* 335 */	/* Added on 3/5/2013 */
+	.long sys_user_setsched		/* 336 */	/* Added on 3/22/2013*/
diff --git a/kernel/Makefile b/kernel/Makefile
index 34fea09..8d21b72 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -10,7 +10,7 @@ obj-y     = sched.o fork.o exec_domain.o panic.o printk.o \
 	    kthread.o wait.o kfifo.o sys_ni.o posix-cpu-timers.o mutex.o \
 	    hrtimer.o rwsem.o nsproxy.o srcu.o semaphore.o \
 	    notifier.o ksysfs.o pm_qos_params.o sched_clock.o cred.o \
-	    async.o netlock.o
+	    async.o netlock.o user_setsched.o
 
 ifdef CONFIG_FUNCTION_TRACER
 # Do not trace debug files and internal ftrace files
diff --git a/kernel/user_setsched.c b/kernel/user_setsched.c
index 342ac6b..56d5661 100644
--- a/kernel/user_setsched.c
+++ b/kernel/user_setsched.c
@@ -1,6 +1,8 @@
 #include <linux/timer.h>
 #include <linux/jiffies.h>
 #include <linux/kernel.h>
+#include <linux/syscalls.h>
+#include <linux/sched.h>
 
 /* int user_setsched(pid_t pid, int policy, u_int16_t timeout_val) */
 SYSCALL_DEFINE3(user_setsched, pid_t, pid, int, policy, u_int16_t, timeout_val)
-- 
1.7.9.5


From 4b8e184269f29810083aaa92a97385529ebee108 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Fri, 22 Mar 2013 20:23:19 -0400
Subject: [PATCH 20/99] -fixed errors in user_setsched.c

---
 include/linux/sched.h  |    2 +-
 kernel/netlock.c       |    4 +---
 kernel/user_setsched.c |    4 ++--
 3 files changed, 4 insertions(+), 6 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index da11b6d..7cb7da7 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -47,7 +47,7 @@ struct sched_param {
 	/* I think that we can get away with just using the int priority.  
 	 * An unsigned 16bit number will still retain its value in an int.
 	 */
-	int deadline;
+	unsigned long deadline;
 };
 
 #include <asm/param.h>	/* for HZ */
diff --git a/kernel/netlock.c b/kernel/netlock.c
index d6bff70..5fbe504 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -40,8 +40,6 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		deadline = jiffies + timeout_val * HZ;
 		update_timer(deadline);
 		down_read(&radio_rw);
-		/* add setscheduler here */
-		
 		return 0;
 	} else if (type == NET_LOCK_SLEEP) {
 		down_write(&radio_rw);
@@ -69,7 +67,7 @@ SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
 	init_timer(&edf_timer);
 	edf_timer.expires = earliest_deadline;
-	edf_timer.data = 0;	/* We need to research the usage of "data" */
+	edf_timer.data = 0;
 	edf_timer.function = sleep_unlock;
 	add_timer(&edf_timer);
 	return 0;
diff --git a/kernel/user_setsched.c b/kernel/user_setsched.c
index 56d5661..665cd78 100644
--- a/kernel/user_setsched.c
+++ b/kernel/user_setsched.c
@@ -13,6 +13,6 @@ SYSCALL_DEFINE3(user_setsched, pid_t, pid, int, policy, u_int16_t, timeout_val)
 
 	crnt_tsk = find_task_by_vpid(pid);
 	deadline = jiffies + timeout_val * HZ;
-	param.deadline = deadline;
-	return	sched_setscheduler(&crnt_tsk, policy, &param);
+	param->deadline = deadline;
+	return	sched_setscheduler(crnt_tsk, policy, param);
 }
-- 
1.7.9.5


From 2144d846c914b4b8382c876e3f8be600e31a2323 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sat, 23 Mar 2013 15:28:25 -0400
Subject: [PATCH 21/99] -added nr_running in struct edf_rq -added
 dequeue_task_edf in sched_edf.c

---
 kernel/sched.c     |    3 ++-
 kernel/sched_edf.c |   40 +++++++++++++++++++++++++++++-----------
 2 files changed, 31 insertions(+), 12 deletions(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index 4547611..9b9c719 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -402,6 +402,7 @@ static inline struct task_group *task_group(struct task_struct *p)
 
 /* Added: 3/9/13 */
 struct edf_rq {
+	unsigned long nr_running;
 	struct rb_root radio_task_root;
 	struct rb_node *bottom_left;
 	struct rq *rq;
@@ -569,7 +570,7 @@ struct rq {
 
 	struct cfs_rq cfs;
 	struct rt_rq rt;
-
+	struct edf_rq edf;	/* Added on 3/23/2013 */
 #ifdef CONFIG_FAIR_GROUP_SCHED
 	/* list of leaf cfs_rq on this cpu: */
 	struct list_head leaf_cfs_rq_list;
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index a180205..1eff91c 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -4,13 +4,13 @@ static const struct sched_class edf_sched_class;
 #define for_each_sched_edf_entity(edf_se) \
 	for (; edf_se; edf_se = NULL)
 
-static inline s64 get_deadline_key(struct sched_edf_entity *edf_entity)
+static inline s64 get_deadline_key(struct sched_edf_entity *ee)
 {
-	return edf_entity->deadline;
+	return ee->deadline;
 }
 
-static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity
-		*edf_entity, int wakeup)
+static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
+				 int wakeup)
 {
 	/* This insert method is taken from the cfs enqueue function.  We have
 	 * very similary needs so it made sense to look at their code.
@@ -19,7 +19,7 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity
 	struct rb_node *parent = NULL;
 	struct sched_edf_entity *current_entity;
 	int leftmost = 1;
-	s64 key = get_deadline_key(edf_entity);
+	s64 key = get_deadline_key(ee);
 
 	while (*link) {
 		parent = *link;
@@ -37,10 +37,23 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity
 		}
 	}
 	if (leftmost)
-		erq->bottom_left = &edf_entity->task_node;
+		erq->bottom_left = &ee->task_node;
 
-	rb_link_node(&edf_entity->task_node, parent, link);
-	rb_insert_color(&edf_entity->task_node, &erq->radio_task_root);
+	rb_link_node(&ee->task_node, parent, link);
+	rb_insert_color(&ee->task_node, &erq->radio_task_root);
+}
+
+static void dequeue_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
+				int sleep)
+{
+	if (erq->rb_leftmost == &ee->task_node) {
+		struct rb_node *next_node;
+
+		next_node = rb_next(&ee->task_node);
+		erq->rb_leftmost = next_node;
+	}
+
+	rb_erase(&ee->task_node, &erq->radio_task_root);
 }
 
 /**
@@ -50,10 +63,10 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity
 static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 {
 	struct edf_rq *erq;
-	struct sched_edf_entity *edf_entity = &p->edf;
+	struct sched_edf_entity *ee = &p->edf;
 
-	for_each_sched_edf_entity(edf_entity){
-		enqueue_edf_entity(erq, edf_entity, -1);
+	for_each_sched_edf_entity(ee){
+		enqueue_edf_entity(erq, ee, -1);
 	}
 
 }
@@ -65,7 +78,12 @@ static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 }
 static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 {
+	struct edf_rq *erq;
+	struct sched_edf_entity *ee = &p->edf;
 
+	for_each_sched_edf_entity(ee) {
+		dequeue_entity(erq, ee, -1);
+	}
 }
 static void yield_task_edf(struct rq *rq)
 {
-- 
1.7.9.5


From a7f0611d0a59fd4f251cd86579e2ae3ff6010e65 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sat, 23 Mar 2013 15:57:03 -0400
Subject: [PATCH 22/99] added nr_running updates in enqueue and dequeue

---
 kernel/sched_edf.c |    2 ++
 1 file changed, 2 insertions(+)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 1eff91c..e391463 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -41,6 +41,7 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 
 	rb_link_node(&ee->task_node, parent, link);
 	rb_insert_color(&ee->task_node, &erq->radio_task_root);
+	erq->nr_running++;
 }
 
 static void dequeue_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
@@ -54,6 +55,7 @@ static void dequeue_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	}
 
 	rb_erase(&ee->task_node, &erq->radio_task_root);
+	erq->nr_running--;
 }
 
 /**
-- 
1.7.9.5


From 2219c50b0fed4b123d3a1e5f64ed982d87d8f11f Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sat, 23 Mar 2013 18:57:17 -0400
Subject: [PATCH 23/99] -corrected rb_leftmost to bottom_left. changed
 dequeue_entity to dequeue_entity_edf so that it does
 not conflict.

---
 kernel/sched_edf.c |   11 +++++++----
 1 file changed, 7 insertions(+), 4 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index e391463..2d074fa 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -1,6 +1,8 @@
 
 static const struct sched_class edf_sched_class;
 
+
+
 #define for_each_sched_edf_entity(edf_se) \
 	for (; edf_se; edf_se = NULL)
 
@@ -44,14 +46,14 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	erq->nr_running++;
 }
 
-static void dequeue_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
+static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
 				int sleep)
 {
-	if (erq->rb_leftmost == &ee->task_node) {
+	if (erq->bottom_left == &ee->task_node) {
 		struct rb_node *next_node;
 
 		next_node = rb_next(&ee->task_node);
-		erq->rb_leftmost = next_node;
+		erq->bottom_left = next_node;
 	}
 
 	rb_erase(&ee->task_node, &erq->radio_task_root);
@@ -84,7 +86,7 @@ static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 	struct sched_edf_entity *ee = &p->edf;
 
 	for_each_sched_edf_entity(ee) {
-		dequeue_entity(erq, ee, -1);
+		dequeue_entity_edf(erq, ee, -1);
 	}
 }
 static void yield_task_edf(struct rq *rq)
@@ -98,6 +100,7 @@ static void yield_task_edf(struct rq *rq)
 static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
 	/* TODO */
+	return NULL;
 }
 
 /*
-- 
1.7.9.5


From e2034d39594a2669d828dd043c20c7e3bb506b96 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sat, 23 Mar 2013 19:41:14 -0400
Subject: [PATCH 24/99] -fixed various checkpatch issues. -added a list of all
 tasks to the edf_rq. -added SCHED_EDF as a valid
 scheduling policy -added initialization function for
 edf_rq -added calling that intilialization function.

---
 include/linux/sched.h   |    2 +-
 kernel/sched.c          |   23 ++++++++++++++++++++++-
 kernel/sched_rt.c       |    2 +-
 user_tests/my_net_app.c |    2 +-
 4 files changed, 25 insertions(+), 4 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 7cb7da7..b76f26e 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -44,7 +44,7 @@
 
 struct sched_param {
 	int sched_priority;
-	/* I think that we can get away with just using the int priority.  
+	/* I think that we can get away with just using the int priority.
 	 * An unsigned 16bit number will still retain its value in an int.
 	 */
 	unsigned long deadline;
diff --git a/kernel/sched.c b/kernel/sched.c
index 9b9c719..63efec6 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -406,6 +406,10 @@ struct edf_rq {
 	struct rb_root radio_task_root;
 	struct rb_node *bottom_left;
 	struct rq *rq;
+
+	/* We want to have a list of all tasks outside of the rb tree. */
+	struct list_head all_tasks;
+
 };
 
 /* CFS-related fields in a runqueue */
@@ -5343,7 +5347,7 @@ recheck:
 		policy = oldpolicy = p->policy;
 	else if (policy != SCHED_FIFO && policy != SCHED_RR &&
 			policy != SCHED_NORMAL && policy != SCHED_BATCH &&
-			policy != SCHED_IDLE) 
+			policy != SCHED_IDLE && policy != SCHED_EDF)
 		return -EINVAL;
 	/*
 	 * Valid priorities for SCHED_FIFO and SCHED_RR are
@@ -8270,6 +8274,17 @@ int in_sched_functions(unsigned long addr)
 		&& addr < (unsigned long)__sched_text_end);
 }
 
+static void init_edf_rq(struct edf_rq *edf_rq, struct rq *rq)
+{
+	edf_rq->rq = rq;
+	edf_rq->nr_running = 0;
+
+	/* set up the rb tree and task list. */
+	edf_rq->radio_task_root = RB_ROOT;
+	INIT_LIST_HEAD(&edf_rq->all_tasks);
+
+}
+
 static void init_cfs_rq(struct cfs_rq *cfs_rq, struct rq *rq)
 {
 	cfs_rq->tasks_timeline = RB_ROOT;
@@ -8451,12 +8466,18 @@ void __init sched_init(void)
 #endif /* CONFIG_USER_SCHED */
 #endif /* CONFIG_GROUP_SCHED */
 
+	/* 
+	 * We will need to add code in this loop to initialize a queue for each
+	 * of the cpus.
+	 */
 	for_each_possible_cpu(i) {
 		struct rq *rq;
 
 		rq = cpu_rq(i);
 		spin_lock_init(&rq->lock);
 		rq->nr_running = 0;
+		/* Initialize the edf_rq */
+		init_edf_rq(&rq->edf, rq);
 		init_cfs_rq(&rq->cfs, rq);
 		init_rt_rq(&rq->rt, rq);
 #ifdef CONFIG_FAIR_GROUP_SCHED
diff --git a/kernel/sched_rt.c b/kernel/sched_rt.c
index a9b4d0c..c4f927f 100644
--- a/kernel/sched_rt.c
+++ b/kernel/sched_rt.c
@@ -1513,7 +1513,7 @@ static void set_curr_task_rt(struct rq *rq)
 
 static const struct sched_class rt_sched_class = {
 	/*
-	 *Before we completely finish the EDF scheduler,we should not 
+	 *Before we completely finish the EDF scheduler,we should not
 	 *change the .next, or the emulator cannot be started correctly.
 	 */
 //	.next			= &edf_sched_class,
diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index cde65fd..aef75a2 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -40,7 +40,7 @@ int main(int argc, char *argv[])
 		/* start sleeping for wait seconds */
 		sleep(wait);
 		print_sec();
-		printf("calling_net_lock ");	
+		printf("calling_net_lock ");
 		printf("pid:%d\n", pid);
 		/* start acquiring the use lock */
 		flag = syscall(__NR_net_lock, 0, timeout);
-- 
1.7.9.5


From 640acd89591b68072723fc1702fede2c46974e73 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sat, 23 Mar 2013 20:18:20 -0400
Subject: [PATCH 25/99] -added pick_next_entity_edf function to pick the next
 entity from the queue. -filled in the
 pick_next_task_edf function.

---
 kernel/sched.c     |    2 +-
 kernel/sched_edf.c |   20 ++++++++++++++++++--
 2 files changed, 19 insertions(+), 3 deletions(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index 63efec6..539c3f5 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -8466,7 +8466,7 @@ void __init sched_init(void)
 #endif /* CONFIG_USER_SCHED */
 #endif /* CONFIG_GROUP_SCHED */
 
-	/* 
+	/*
 	 * We will need to add code in this loop to initialize a queue for each
 	 * of the cpus.
 	 */
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 2d074fa..b0c2248 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -69,7 +69,7 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 	struct edf_rq *erq;
 	struct sched_edf_entity *ee = &p->edf;
 
-	for_each_sched_edf_entity(ee){
+	for_each_sched_edf_entity(ee) {
 		enqueue_edf_entity(erq, ee, -1);
 	}
 
@@ -94,13 +94,29 @@ static void yield_task_edf(struct rq *rq)
 
 }
 
+static struct sched_edf_entity *pick_next_entity_edf(struct edf_rq *erq)
+{
+	struct rb_node *left = erq->bottom_left;
+
+	/* If there are no elements in the queue. */
+	if (!left)
+		return NULL;
+
+	/* Get the entry out of the rb tree node. */
+	return rb_entry(left, struct sched_edf_entity, task_node);
+
+}
+
 /*
  * Get the next task.
  */
 static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
 	/* TODO */
-	return NULL;
+
+	struct sched_edf_entity *next_entity = pick_next_entity_edf(&rq->edf);
+
+	return container_of(next_entity, struct task_struct, edf);
 }
 
 /*
-- 
1.7.9.5


From 75f3804133a5fc2819754fb0ae7a7f074201ffc8 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sat, 23 Mar 2013 20:34:47 -0400
Subject: [PATCH 26/99] -realligned edf_sched_class functions.

---
 kernel/sched_edf.c |   30 +++++++++++++++---------------
 1 file changed, 15 insertions(+), 15 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index b0c2248..93089d3 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -181,21 +181,21 @@ static void switched_to_edf(struct rq *rq, struct task_struct *p, int running)
 }
 
 static const struct sched_class edf_sched_class = {
-	.next = &fair_sched_class,
-	.enqueue_task = enqueue_task_edf,
-	.dequeue_task = dequeue_task_edf,
-	.yield_task = yield_task_edf,
-	.check_preempt_curr = check_preempt_curr_edf,
-	.pick_next_task = pick_next_task_edf,
-	.put_prev_task = put_prev_task_edf,
+	.next			= &fair_sched_class,
+	.enqueue_task		= enqueue_task_edf,
+	.dequeue_task		= dequeue_task_edf,
+	.yield_task		= yield_task_edf,
+	.check_preempt_curr	= check_preempt_curr_edf,
+	.pick_next_task		= pick_next_task_edf,
+	.put_prev_task		= put_prev_task_edf,
 #ifdef CONFIG_SMP
-	.select_task_rq = select_task_rq_edf,
-	.load_balance = load_balance_edf,
-	.move_one_task = move_one_task_edf,
+	.select_task_rq		= select_task_rq_edf,
+	.load_balance		= load_balance_edf,
+	.move_one_task		= move_one_task_edf,
 #endif /* CONFIG_SMP */
-	.set_curr_task = set_curr_task_edf,
-	.task_tick = task_tick_edf,
-	.task_new = task_new_edf,
-	.prio_changed = prio_changed_edf,
-	.switched_to = switched_to_edf,
+	.set_curr_task		= set_curr_task_edf,
+	.task_tick		= task_tick_edf,
+	.task_new		= task_new_edf,
+	.prio_changed		= prio_changed_edf,
+	.switched_to		= switched_to_edf,
 };
-- 
1.7.9.5


From f9139c1bcc7c24cba02bb5ca0570a2a5fdc3299b Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Sat, 23 Mar 2013 21:20:15 -0400
Subject: [PATCH 27/99] -added check for null return from
 pick_next_entity_edf. -added edf as next scheduler to
 rt scheduler module.

---
 kernel/sched_edf.c |    7 ++++---
 kernel/sched_rt.c  |    3 +--
 2 files changed, 5 insertions(+), 5 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index b0c2248..4c74074 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -112,11 +112,12 @@ static struct sched_edf_entity *pick_next_entity_edf(struct edf_rq *erq)
  */
 static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
-	/* TODO */
-
 	struct sched_edf_entity *next_entity = pick_next_entity_edf(&rq->edf);
 
-	return container_of(next_entity, struct task_struct, edf);
+	if (next_entity == NULL)
+		return NULL;
+	else
+		return container_of(next_entity, struct task_struct, edf);
 }
 
 /*
diff --git a/kernel/sched_rt.c b/kernel/sched_rt.c
index c4f927f..3c757d9 100644
--- a/kernel/sched_rt.c
+++ b/kernel/sched_rt.c
@@ -1516,8 +1516,7 @@ static const struct sched_class rt_sched_class = {
 	 *Before we completely finish the EDF scheduler,we should not
 	 *change the .next, or the emulator cannot be started correctly.
 	 */
-//	.next			= &edf_sched_class,
-	.next			= &fair_sched_class,
+	.next			= &edf_sched_class,
 	.enqueue_task		= enqueue_task_rt,
 	.dequeue_task		= dequeue_task_rt,
 	.yield_task		= yield_task_rt,
-- 
1.7.9.5


From 0efb9716ccd4796dc5042d732df6bbc4f14136fc Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sat, 23 Mar 2013 21:22:27 -0400
Subject: [PATCH 28/99] -added notes about preemption. -added notes about
 atomics.

---
 kernel/sched_edf.c |    5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 93089d3..02e4942 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -43,6 +43,8 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 
 	rb_link_node(&ee->task_node, parent, link);
 	rb_insert_color(&ee->task_node, &erq->radio_task_root);
+
+	/* This should be atomic*/
 	erq->nr_running++;
 }
 
@@ -57,6 +59,7 @@ static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
 	}
 
 	rb_erase(&ee->task_node, &erq->radio_task_root);
+	/* This should be atomic.*/
 	erq->nr_running--;
 }
 
@@ -78,7 +81,7 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 		int sync)
 {
-
+	/* We will check to see if this task currently holds a read net_lock. */
 }
 static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 {
-- 
1.7.9.5


From f50dba20ae0a7c5a45e032d74f020d69e83e2954 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sun, 24 Mar 2013 12:59:59 -0400
Subject: [PATCH 29/99] -added makefile for user_tests.

---
 user_tests/Makefile |   65 +++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 65 insertions(+)
 create mode 100644 user_tests/Makefile

diff --git a/user_tests/Makefile b/user_tests/Makefile
new file mode 100644
index 0000000..b99b147
--- /dev/null
+++ b/user_tests/Makefile
@@ -0,0 +1,65 @@
+APP := test
+ROOT:=$(HOME)
+NDK_PLATFORM_VER := 14
+INSTALL_DIR := /data/tmp
+NET_APP := my_net_app
+NET_MON := net_monitor
+
+ANDROID_SDK_ROOT:=$(ROOT)/android-sdk-linux
+ANDROID_NDK_ROOT:=$(ROOT)/android-ndk-r8d
+ANDROID_NDK_HOST:=linux-x86
+ANDROID_TARGET:=i686-linux-android
+ANDROID_TARGET_ARCH:=x86
+ANDROID_TOOLCHAIN:=x86-4.4.3
+
+BINDIR:=$(ANDROID_NDK_ROOT)/toolchains/$(ANDROID_TOOLCHAIN)/prebuilt/$(ANDROID_NDK_HOST)
+LIBDIR:=$(ANDROID_NDK_ROOT)/platforms/android-$(NDK_PLATFORM_VER)/arch-$(ANDROID_TARGET_ARCH)/usr/lib
+INCDIR:=$(ANDROID_NDK_ROOT)/platforms/android-$(NDK_PLATFORM_VER)/arch-$(ANDROID_TARGET_ARCH)/usr/include
+BIN := $(BINDIR)/bin
+ 
+CPP := $(BIN)/$(ANDROID_TARGET)-g++
+CC := $(BIN)/$(ANDROID_TARGET)-gcc
+CFLAGS := -I$(INCDIR)
+LDFLAGS := -Wl,-rpath-link=$(LIBDIR),-dynamic-linker=/system/bin/linker -L$(LIBDIR) 
+LDFLAGS += $(LIBDIR)/crtbegin_dynamic.o $(LIBDIR)/crtend_android.o -nostdlib -lc -disable-multilib -lm
+ 
+ 
+all: $(NET_MON)
+ 
+OBJS += $(APP).o
+ 
+$(APP): $(OBJS)
+	$(CC) $(LDFLAGS) -o $@ $^
+ 
+%.o: %.c
+	$(CC) -c $(INCLUDE) $(CFLAGS) $< -o $@ 
+
+$(NET_MON): $(NET_MON).c
+	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_MON).c -o $(NET_MON).o
+	$(CC) $(LDFLAGS) -o $(NET_MON) $(NET_MON)
+
+
+install: $(APP)
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_APP)
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_MON)
+ 
+shell:
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell
+ 
+run:
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_APP)
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_MON)
+ 
+r: $(APP)
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_APP)
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_APP)
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_MON)
+	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_MON)
+ 
+clean:
+	@rm -f *.o $(NET_MON) $(NET_APP)
+
-- 
1.7.9.5


From a4444b691549907c10c955cdeea1caeb454ed331 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Sun, 24 Mar 2013 13:02:48 -0400
Subject: [PATCH 30/99] makefile builds correctly.

---
 user_tests/Makefile |   15 +++++----------
 1 file changed, 5 insertions(+), 10 deletions(-)

diff --git a/user_tests/Makefile b/user_tests/Makefile
index b99b147..df80795 100644
--- a/user_tests/Makefile
+++ b/user_tests/Makefile
@@ -24,20 +24,15 @@ LDFLAGS := -Wl,-rpath-link=$(LIBDIR),-dynamic-linker=/system/bin/linker -L$(LIBD
 LDFLAGS += $(LIBDIR)/crtbegin_dynamic.o $(LIBDIR)/crtend_android.o -nostdlib -lc -disable-multilib -lm
  
  
-all: $(NET_MON)
+all: $(NET_MON) $(NET_APP)
  
-OBJS += $(APP).o
- 
-$(APP): $(OBJS)
-	$(CC) $(LDFLAGS) -o $@ $^
- 
-%.o: %.c
-	$(CC) -c $(INCLUDE) $(CFLAGS) $< -o $@ 
-
 $(NET_MON): $(NET_MON).c
 	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_MON).c -o $(NET_MON).o
-	$(CC) $(LDFLAGS) -o $(NET_MON) $(NET_MON)
+	$(CC) $(LDFLAGS) -o $(NET_MON) $(NET_MON).o
 
+$(NET_APP): $(NET_APP).c
+	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_APP).c -o $(NET_APP).o
+	$(CC) $(LDFLAGS) -o $(NET_APP) $(NET_APP).o
 
 install: $(APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP) 
-- 
1.7.9.5


From 924356379969ee441399c10fe69fa8b0c5cbd857 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sun, 24 Mar 2013 14:28:25 -0400
Subject: [PATCH 31/99] -added debug statements to enqueuing, dequeueing and
 seting sched. -added setting scheduler to syscall.

---
 kernel/netlock.c    |    6 ++++++
 kernel/sched_edf.c  |    4 ++++
 user_tests/Makefile |   32 ++++++++++++++++----------------
 3 files changed, 26 insertions(+), 16 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 5fbe504..e978e0c 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -3,6 +3,7 @@
 #include <linux/timer.h>
 #include <linux/jiffies.h>
 #include <linux/kernel.h>
+#include <linux/sched.h>
 
 unsigned long earliest_deadline;
 struct timer_list edf_timer;
@@ -36,10 +37,15 @@ void update_timer(unsigned long new_deadline)
 SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 {
 	unsigned long deadline;
+	struct sched_param param;
+	pid_t pid = current->pid;
 	if (type == NET_LOCK_USE) {
 		deadline = jiffies + timeout_val * HZ;
+		param.deadline = deadline;
 		update_timer(deadline);
 		down_read(&radio_rw);
+		printk(KERN_DEBUG "Setting scheduler for : %d\n", pid);
+		sched_setscheduler(current, SCHED_EDF, &param);
 		return 0;
 	} else if (type == NET_LOCK_SLEEP) {
 		down_write(&radio_rw);
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index a5bb189..d83b4bb 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -72,6 +72,8 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 	struct edf_rq *erq;
 	struct sched_edf_entity *ee = &p->edf;
 
+	printk(KERN_DEBUG "EDF: enqueueing task(%d)\n", p->pid);
+
 	for_each_sched_edf_entity(ee) {
 		enqueue_edf_entity(erq, ee, -1);
 	}
@@ -88,6 +90,8 @@ static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 	struct edf_rq *erq;
 	struct sched_edf_entity *ee = &p->edf;
 
+	printk(KERN_DEBUG "EDF: denqueueing task(%d)\n", p->pid);
+
 	for_each_sched_edf_entity(ee) {
 		dequeue_entity_edf(erq, ee, -1);
 	}
diff --git a/user_tests/Makefile b/user_tests/Makefile
index b99b147..809029d 100644
--- a/user_tests/Makefile
+++ b/user_tests/Makefile
@@ -16,23 +16,23 @@ BINDIR:=$(ANDROID_NDK_ROOT)/toolchains/$(ANDROID_TOOLCHAIN)/prebuilt/$(ANDROID_N
 LIBDIR:=$(ANDROID_NDK_ROOT)/platforms/android-$(NDK_PLATFORM_VER)/arch-$(ANDROID_TARGET_ARCH)/usr/lib
 INCDIR:=$(ANDROID_NDK_ROOT)/platforms/android-$(NDK_PLATFORM_VER)/arch-$(ANDROID_TARGET_ARCH)/usr/include
 BIN := $(BINDIR)/bin
- 
+
 CPP := $(BIN)/$(ANDROID_TARGET)-g++
 CC := $(BIN)/$(ANDROID_TARGET)-gcc
 CFLAGS := -I$(INCDIR)
-LDFLAGS := -Wl,-rpath-link=$(LIBDIR),-dynamic-linker=/system/bin/linker -L$(LIBDIR) 
+LDFLAGS := -Wl,-rpath-link=$(LIBDIR),-dynamic-linker=/system/bin/linker -L$(LIBDIR)
 LDFLAGS += $(LIBDIR)/crtbegin_dynamic.o $(LIBDIR)/crtend_android.o -nostdlib -lc -disable-multilib -lm
- 
- 
+
+
 all: $(NET_MON)
- 
+
 OBJS += $(APP).o
- 
+
 $(APP): $(OBJS)
 	$(CC) $(LDFLAGS) -o $@ $^
- 
+
 %.o: %.c
-	$(CC) -c $(INCLUDE) $(CFLAGS) $< -o $@ 
+	$(CC) -c $(INCLUDE) $(CFLAGS) $< -o $@
 
 $(NET_MON): $(NET_MON).c
 	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_MON).c -o $(NET_MON).o
@@ -40,26 +40,26 @@ $(NET_MON): $(NET_MON).c
 
 
 install: $(APP)
-	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_APP)
-	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_MON)
- 
+
 shell:
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell
- 
+
 run:
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_MON)
- 
+
 r: $(APP)
-	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_APP)
-	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_MON)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell $(INSTALL_DIR)/$(NET_MON)
- 
+
 clean:
 	@rm -f *.o $(NET_MON) $(NET_APP)
 
-- 
1.7.9.5


From 7039b12a99370817c69a017089d31b92275a514d Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Sun, 24 Mar 2013 14:36:58 -0400
Subject: [PATCH 32/99] added tests to makefile. -added print stateuemnts to
 <en|de>queue.

---
 kernel/sched_edf.c  |    4 ++++
 user_tests/Makefile |    6 ++++--
 2 files changed, 8 insertions(+), 2 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index a5bb189..175eb4f 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -72,6 +72,8 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 	struct edf_rq *erq;
 	struct sched_edf_entity *ee = &p->edf;
 
+	printk(KERN_DEBUG, "EDF: enqueueing task(%d)\n", p->pid);
+
 	for_each_sched_edf_entity(ee) {
 		enqueue_edf_entity(erq, ee, -1);
 	}
@@ -88,6 +90,8 @@ static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 	struct edf_rq *erq;
 	struct sched_edf_entity *ee = &p->edf;
 
+	printk(KERN_DEBUG, "EDF: enqueueing task(%d)\n", p->pid);
+
 	for_each_sched_edf_entity(ee) {
 		dequeue_entity_edf(erq, ee, -1);
 	}
diff --git a/user_tests/Makefile b/user_tests/Makefile
index df80795..c826ecd 100644
--- a/user_tests/Makefile
+++ b/user_tests/Makefile
@@ -24,7 +24,9 @@ LDFLAGS := -Wl,-rpath-link=$(LIBDIR),-dynamic-linker=/system/bin/linker -L$(LIBD
 LDFLAGS += $(LIBDIR)/crtbegin_dynamic.o $(LIBDIR)/crtend_android.o -nostdlib -lc -disable-multilib -lm
  
  
-all: $(NET_MON) $(NET_APP)
+all: tests
+
+tests: $(NET_MON) $(NET_APP)
  
 $(NET_MON): $(NET_MON).c
 	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_MON).c -o $(NET_MON).o
@@ -34,7 +36,7 @@ $(NET_APP): $(NET_APP).c
 	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_APP).c -o $(NET_APP).o
 	$(CC) $(LDFLAGS) -o $(NET_APP) $(NET_APP).o
 
-install: $(APP)
+install:
 	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP) 
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON) 
-- 
1.7.9.5


From dd901c6d21220ff2aa1e2f76d5657fa4304c0c25 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Sun, 24 Mar 2013 14:51:10 -0400
Subject: [PATCH 33/99] -added printk debug statements.

---
 kernel/netlock.c    |    6 +++++-
 user_tests/Makefile |    3 ---
 2 files changed, 5 insertions(+), 4 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index e978e0c..05b5e9f 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -43,12 +43,16 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		deadline = jiffies + timeout_val * HZ;
 		param.deadline = deadline;
 		update_timer(deadline);
+		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
 		down_read(&radio_rw);
-		printk(KERN_DEBUG "Setting scheduler for : %d\n", pid);
+		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
+		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n", pid);
 		sched_setscheduler(current, SCHED_EDF, &param);
 		return 0;
 	} else if (type == NET_LOCK_SLEEP) {
+		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
 		down_write(&radio_rw);
+		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
 		earliest_deadline = ULONG_MAX;
 		return 0;
 	} else {
diff --git a/user_tests/Makefile b/user_tests/Makefile
index c8176ae..7f60903 100644
--- a/user_tests/Makefile
+++ b/user_tests/Makefile
@@ -22,11 +22,8 @@ CC := $(BIN)/$(ANDROID_TARGET)-gcc
 CFLAGS := -I$(INCDIR)
 LDFLAGS := -Wl,-rpath-link=$(LIBDIR),-dynamic-linker=/system/bin/linker -L$(LIBDIR)
 LDFLAGS += $(LIBDIR)/crtbegin_dynamic.o $(LIBDIR)/crtend_android.o -nostdlib -lc -disable-multilib -lm
-<<<<<<< HEAD
- 
  
 all: tests
-=======
 
 all: $(NET_MON)
 
-- 
1.7.9.5


From 02180a5cb56a43e58ad1b77f643254cf4e8d51ae Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Sun, 24 Mar 2013 14:53:24 -0400
Subject: [PATCH 34/99] -added debug statements to netlock.

---
 kernel/netlock.c |    2 ++
 1 file changed, 2 insertions(+)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index e978e0c..5242d6d 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -40,6 +40,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 	struct sched_param param;
 	pid_t pid = current->pid;
 	if (type == NET_LOCK_USE) {
+		printk(KERN_DEBUG "Acquiring NET_LOCK for user.\n");
 		deadline = jiffies + timeout_val * HZ;
 		param.deadline = deadline;
 		update_timer(deadline);
@@ -48,6 +49,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		sched_setscheduler(current, SCHED_EDF, &param);
 		return 0;
 	} else if (type == NET_LOCK_SLEEP) {
+		printk(KERN_DEBUG "Acquiring NET_LOCK for sleeper.\n");
 		down_write(&radio_rw);
 		earliest_deadline = ULONG_MAX;
 		return 0;
-- 
1.7.9.5


From d4bd594b505ad8af171328e88f168d260d480ec8 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Sun, 24 Mar 2013 17:04:35 -0400
Subject: [PATCH 35/99] -passing sched_param as a pointer like it should be.

---
 kernel/netlock.c    |   21 ++++++++++++++-------
 user_tests/Makefile |    6 +++---
 2 files changed, 17 insertions(+), 10 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 42b3604..7478db1 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -1,9 +1,10 @@
-#include <linux/rwsem.h>
-#include <linux/syscalls.h>
-#include <linux/timer.h>
 #include <linux/jiffies.h>
 #include <linux/kernel.h>
+#include <linux/rwsem.h>
 #include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/syscalls.h>
+#include <linux/timer.h>
 
 unsigned long earliest_deadline;
 struct timer_list edf_timer;
@@ -37,18 +38,24 @@ void update_timer(unsigned long new_deadline)
 SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 {
 	unsigned long deadline;
-	struct sched_param param;
+	struct sched_param *param;
 	pid_t pid = current->pid;
 	if (type == NET_LOCK_USE) {
+		param = (struct sched_param *)kmalloc(
+				sizeof(struct sched_param), 0);
+		if (param == NULL)
+			return -EINVAL;
 		printk(KERN_DEBUG "NETLOCK: Acquiring NET_LOCK for user.\n");
 		deadline = jiffies + timeout_val * HZ;
-		param.deadline = deadline;
+		param->deadline = deadline;
 		update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
 		down_read(&radio_rw);
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
-		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n", pid);
-		sched_setscheduler(current, SCHED_EDF, &param);
+		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
+				pid);
+		sched_setscheduler(current, SCHED_EDF, param);
+		kfree(param);
 		return 0;
 	} else if (type == NET_LOCK_SLEEP) {
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
diff --git a/user_tests/Makefile b/user_tests/Makefile
index 7f60903..2f16547 100644
--- a/user_tests/Makefile
+++ b/user_tests/Makefile
@@ -22,7 +22,7 @@ CC := $(BIN)/$(ANDROID_TARGET)-gcc
 CFLAGS := -I$(INCDIR)
 LDFLAGS := -Wl,-rpath-link=$(LIBDIR),-dynamic-linker=/system/bin/linker -L$(LIBDIR)
 LDFLAGS += $(LIBDIR)/crtbegin_dynamic.o $(LIBDIR)/crtend_android.o -nostdlib -lc -disable-multilib -lm
- 
+
 all: tests
 
 all: $(NET_MON)
@@ -36,7 +36,7 @@ $(APP): $(OBJS)
 	$(CC) -c $(INCLUDE) $(CFLAGS) $< -o $@
 
 tests: $(NET_MON) $(NET_APP)
- 
+
 $(NET_MON): $(NET_MON).c
 	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_MON).c -o $(NET_MON).o
 	$(CC) $(LDFLAGS) -o $(NET_MON) $(NET_MON).o
@@ -46,7 +46,7 @@ $(NET_APP): $(NET_APP).c
 	$(CC) $(LDFLAGS) -o $(NET_APP) $(NET_APP).o
 
 install:
-	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP) 
+	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_MON)
-- 
1.7.9.5


From a32575906286c02aaaff40075afaad6e0b3352db Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Mon, 25 Mar 2013 13:49:45 -0400
Subject: [PATCH 36/99] -added checks for invalid error returns.

---
 kernel/netlock.c |   23 ++++++++++++++++++-----
 kernel/sched.c   |    1 +
 2 files changed, 19 insertions(+), 5 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 7478db1..f828e23 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -37,14 +37,22 @@ void update_timer(unsigned long new_deadline)
 /* int net_lock(netlock_t type, u_int16_t timeout_val) */
 SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 {
+	int returnval;
+	pid_t pid;
 	unsigned long deadline;
 	struct sched_param *param;
-	pid_t pid = current->pid;
+
+	printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK.\n");
+	pid = current->pid;
 	if (type == NET_LOCK_USE) {
+		printk("NETLOCK: attempting to acquite NETLOCK_USE.\n");
 		param = (struct sched_param *)kmalloc(
-				sizeof(struct sched_param), 0);
-		if (param == NULL)
+				sizeof(struct sched_param), GFP_KERNEL);
+		printk("NETLOCK: allocated param memory.\n");
+		if (param == NULL){
+			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
 			return -EINVAL;
+		}
 		printk(KERN_DEBUG "NETLOCK: Acquiring NET_LOCK for user.\n");
 		deadline = jiffies + timeout_val * HZ;
 		param->deadline = deadline;
@@ -54,9 +62,13 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
 				pid);
-		sched_setscheduler(current, SCHED_EDF, param);
+		returnval = sched_setscheduler(current, SCHED_EDF, param);
+		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n", returnval);
 		kfree(param);
-		return 0;
+		if (returnval == 0)
+			return 0;
+		else
+			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
 		down_write(&radio_rw);
@@ -64,6 +76,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		earliest_deadline = ULONG_MAX;
 		return 0;
 	} else {
+		printk(KERN_DEBUG "NET_LOCK: invalid net_lock type.\n");
 		return -1;
 	}
 }
diff --git a/kernel/sched.c b/kernel/sched.c
index f8f0486..a0aef65 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -5304,6 +5304,7 @@ __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 		p->sched_class = &rt_sched_class;
 		break;
 	case SCHED_EDF: /* Added 3/14/13 */
+		printk(KERN_DEBUG, "SET_SCHED: Added task(%d) to SCHED_EDF\n", p->pid);
 		p->sched_class = &edf_sched_class;
 		break;
 	}
-- 
1.7.9.5


From 6c7d26592357185195866b65504b9dc9416838a7 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Mon, 25 Mar 2013 23:22:07 -0400
Subject: [PATCH 37/99] -there is some sort of bug when enqueueing.  it Hangs
 for some reason.

---
 kernel/netlock.c |    3 ++-
 kernel/sched.c   |   28 +++++++++++++++++++++++++---
 2 files changed, 27 insertions(+), 4 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index f828e23..a15a02a 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -42,7 +42,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 	unsigned long deadline;
 	struct sched_param *param;
 
-	printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK.\n");
+	printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK: %d\n", current->pid);
 	pid = current->pid;
 	if (type == NET_LOCK_USE) {
 		printk("NETLOCK: attempting to acquite NETLOCK_USE.\n");
@@ -56,6 +56,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		printk(KERN_DEBUG "NETLOCK: Acquiring NET_LOCK for user.\n");
 		deadline = jiffies + timeout_val * HZ;
 		param->deadline = deadline;
+		param->sched_priority = 0;
 		update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
 		down_read(&radio_rw);
diff --git a/kernel/sched.c b/kernel/sched.c
index a0aef65..41510e6 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -5290,7 +5290,9 @@ static struct task_struct *find_process_by_pid(pid_t pid)
 static void
 __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 {
+
 	BUG_ON(p->se.on_rq);
+	printk(KERN_DEBUG "Setting scheduler for %d\n", p->pid);
 
 	p->policy = policy;
 	switch (p->policy) {
@@ -5304,7 +5306,7 @@ __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 		p->sched_class = &rt_sched_class;
 		break;
 	case SCHED_EDF: /* Added 3/14/13 */
-		printk(KERN_DEBUG, "SET_SCHED: Added task(%d) to SCHED_EDF\n", p->pid);
+		printk(KERN_DEBUG "SET_SCHED: Added task(%d) to SCHED_EDF\n", p->pid);
 		p->sched_class = &edf_sched_class;
 		break;
 	}
@@ -5339,6 +5341,9 @@ static int __sched_setscheduler(struct task_struct *p, int policy,
 	unsigned long flags;
 	const struct sched_class *prev_class = p->sched_class;
 	struct rq *rq;
+	pid_t cpid;
+
+	cpid = p->pid;
 
 	/* may grab non-irq protected spin_locks */
 	BUG_ON(in_interrupt());
@@ -5352,13 +5357,17 @@ recheck:
 		return -EINVAL;
 
 	/* Set the deadline for an EDF scheduling. */
-	if (policy == SCHED_EDF)
+	if (policy == SCHED_EDF) {
 		p->edf.deadline = param->deadline;
+		printk(KERN_DEBUG "Setting deadline for task: %d.\n", cpid);
+
+	}
 	/*
 	 * Valid priorities for SCHED_FIFO and SCHED_RR are
 	 * 1..MAX_USER_RT_PRIO-1, valid priority for SCHED_NORMAL,
 	 * SCHED_BATCH and SCHED_IDLE is 0.
 	 */
+	printk(KERN_DEBUG "Testing for valid priorities %d .\n", cpid);
 	if (param->sched_priority < 0 ||
 	    (p->mm && param->sched_priority > MAX_USER_RT_PRIO-1) ||
 	    (!p->mm && param->sched_priority > MAX_RT_PRIO-1))
@@ -5366,6 +5375,8 @@ recheck:
 	if (rt_policy(policy) != (param->sched_priority != 0))
 		return -EINVAL;
 
+
+	printk(KERN_DEBUG "Allow unpriv rt taskss to decrease priority %d.\n", cpid);
 	/*
 	 * Allow unprivileged RT tasks to decrease priority:
 	 */
@@ -5399,6 +5410,7 @@ recheck:
 			return -EPERM;
 	}
 
+	printk(KERN_DEBUG "if(user) %d\n", cpid);
 	if (user) {
 #ifdef CONFIG_RT_GROUP_SCHED
 		/*
@@ -5415,6 +5427,7 @@ recheck:
 			return retval;
 	}
 
+	printk(KERN_DEBUG "spin_lock_irqsave.\n");
 	/*
 	 * make sure no PI-waiters arrive (or leave) while we are
 	 * changing the priority of the task:
@@ -5446,11 +5459,20 @@ recheck:
 	oldprio = p->prio;
 
 	/* This is where the p->sched_class actually gets set. */
+	printk(KERN_DEBUG "__setscheduler.\n");
 	__setscheduler(rq, p, policy, param->sched_priority);
 
-	if (running)
+	printk(KERN_DEBUG "if (running)\n");
+	if (running) {
+		printk(KERN_DEBUG "Task is running: %d\n", cpid);
+
+		/* Bug may be here */
 		p->sched_class->set_curr_task(rq);
+	}
 	if (on_rq) {
+		printk(KERN_DEBUG "Task is on rq: %d\n", cpid);
+
+		/* Bug may be here */
 		activate_task(rq, p, 0);
 
 		check_class_changed(rq, p, prev_class, oldprio, running);
-- 
1.7.9.5


From b4d266f6662d7ee516087a0758fd94dce436540a Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Tue, 26 Mar 2013 00:23:19 -0400
Subject: [PATCH 38/99] -added edf_rq to the edf_entity. -added body of
 yield_task_edf.

---
 include/linux/sched.h |    1 +
 kernel/sched_edf.c    |    8 ++++++++
 2 files changed, 9 insertions(+)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index b76f26e..400e3a0 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1120,6 +1120,7 @@ struct sched_rt_entity {
 struct sched_edf_entity {
 	unsigned long deadline;
 	struct rb_node task_node;
+	struct edf_rq *erq;
 };
 
 struct task_struct {
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index d83b4bb..f4b70a2 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -85,6 +85,7 @@ static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 {
 	/* We will check to see if this task currently holds a read net_lock. */
 }
+
 static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 {
 	struct edf_rq *erq;
@@ -98,6 +99,13 @@ static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 }
 static void yield_task_edf(struct rq *rq)
 {
+	struct task_struct *yield_task;
+	struct edf_rq *erq;
+
+	yield_task = rq->curr;
+	erq = yield_task->edf.erq;
+	dequeue_task_edf(rq, yield_task, 0);
+	enqueue_task_edf(rq, yield_task, 0);
 
 }
 
-- 
1.7.9.5


From a53e9ea5b8cf67d8fbd9a1308995eaf27a84b22d Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Tue, 26 Mar 2013 11:06:49 -0400
Subject: [PATCH 39/99] -added check_preempt_curr to edf. -cleaned up some
 checkpatching.

---
 kernel/netlock.c   |   16 +++++++++-------
 kernel/sched_edf.c |   19 +++++++++++++++++--
 2 files changed, 26 insertions(+), 9 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index a15a02a..2f24843 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -42,14 +42,15 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 	unsigned long deadline;
 	struct sched_param *param;
 
-	printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK: %d\n", current->pid);
+	printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK: %d\n",
+			current->pid);
+
 	pid = current->pid;
 	if (type == NET_LOCK_USE) {
-		printk("NETLOCK: attempting to acquite NETLOCK_USE.\n");
-		param = (struct sched_param *)kmalloc(
-				sizeof(struct sched_param), GFP_KERNEL);
-		printk("NETLOCK: allocated param memory.\n");
-		if (param == NULL){
+		printk(KERN_DEBUG "NETLOCK: attempting to acquite NETLOCK_USE.\n");
+		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
+		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
+		if (param == NULL) {
 			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
 			return -EINVAL;
 		}
@@ -64,7 +65,8 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
 				pid);
 		returnval = sched_setscheduler(current, SCHED_EDF, param);
-		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n", returnval);
+		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n",
+				returnval);
 		kfree(param);
 		if (returnval == 0)
 			return 0;
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index f4b70a2..e26b704 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -1,7 +1,10 @@
 
 static const struct sched_class edf_sched_class;
 
-
+static unsigned long get_deadline(struct task_struct *p)
+{
+	return p->edf.deadline;
+}
 
 #define for_each_sched_edf_entity(edf_se) \
 	for (; edf_se; edf_se = NULL)
@@ -83,7 +86,19 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 		int sync)
 {
-	/* We will check to see if this task currently holds a read net_lock. */
+	/*
+	 * if the new task's deadline is sooner then the current or if the new
+	 * task is the lower left task.
+	 *
+	 * resched the current task if it's deadline is greater than the new.
+	 *
+	 * TODO: Does this need to be more complicated?
+	 *
+	 */
+	unsigned long curr_deadline = get_deadline(rq->curr);
+	unsigned long new_deadline = get_deadline(p);
+	if (new_deadline < curr_deadline)
+		resched_task(rq->curr);
 }
 
 static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
-- 
1.7.9.5


From ad68f7ac5ef0e0183be8a031e7b3cdde1108616b Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Tue, 26 Mar 2013 17:02:22 -0400
Subject: [PATCH 40/99] -added notes and annotations.

---
 kernel/netlock.c       |    4 ++++
 kernel/sched_edf.c     |    7 +++++--
 kernel/user_setsched.c |    3 +++
 3 files changed, 12 insertions(+), 2 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 2f24843..98613d4 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -87,6 +87,10 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
+	/* 
+	 * Didn't the sleeper say that both the user and the sleeper needs to
+	 * be able to call this?
+	 */
 	up_read(&radio_rw);
 	return 0;
 }
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index e26b704..2ef689e 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -187,12 +187,15 @@ static int move_one_task_edf(struct rq *rq, int cpu, struct rq *busy,
 
 static void set_curr_task_edf(struct rq *rq)
 {
-	/* TODO */
+	struct task_struct *p = rq->curr;
 }
 
 static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
 {
-	/* TODO */
+	/* 
+	 * TODO: I don't think that we will need this because I think that this
+	 * should be handled in check_preempt.
+	 * */
 }
 
 static void task_new_edf(struct rq *rq, struct task_struct *p)
diff --git a/kernel/user_setsched.c b/kernel/user_setsched.c
index 665cd78..9e8a70d 100644
--- a/kernel/user_setsched.c
+++ b/kernel/user_setsched.c
@@ -11,6 +11,9 @@ SYSCALL_DEFINE3(user_setsched, pid_t, pid, int, policy, u_int16_t, timeout_val)
 	struct sched_param *param;
 	unsigned long deadline;
 
+	/* There is already a variable called 'current' that contains the current 
+	 * task.
+	 * */
 	crnt_tsk = find_task_by_vpid(pid);
 	deadline = jiffies + timeout_val * HZ;
 	param->deadline = deadline;
-- 
1.7.9.5


From fce148c2039ebd98cab57b30fbe8b870745b7552 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Tue, 26 Mar 2013 21:15:15 -0400
Subject: [PATCH 41/99] -added test for if the task is currently on the rq.

---
 include/linux/sched.h  |    1 +
 kernel/netlock.c       |    2 +-
 kernel/sched.c         |    6 ++++--
 kernel/sched_edf.c     |   12 ++++++++++--
 kernel/user_setsched.c |    4 ++--
 5 files changed, 18 insertions(+), 7 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 400e3a0..7f23f57 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1121,6 +1121,7 @@ struct sched_edf_entity {
 	unsigned long deadline;
 	struct rb_node task_node;
 	struct edf_rq *erq;
+	unsigned int on_rq;
 };
 
 struct task_struct {
diff --git a/kernel/netlock.c b/kernel/netlock.c
index 98613d4..551cbca 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -87,7 +87,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
-	/* 
+	/*
 	 * Didn't the sleeper say that both the user and the sleeper needs to
 	 * be able to call this?
 	 */
diff --git a/kernel/sched.c b/kernel/sched.c
index 41510e6..07b78d8 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -5306,7 +5306,8 @@ __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 		p->sched_class = &rt_sched_class;
 		break;
 	case SCHED_EDF: /* Added 3/14/13 */
-		printk(KERN_DEBUG "SET_SCHED: Added task(%d) to SCHED_EDF\n", p->pid);
+		printk(KERN_DEBUG "SET_SCHED: Added task(%d) to SCHED_EDF\n",
+				p->pid);
 		p->sched_class = &edf_sched_class;
 		break;
 	}
@@ -5376,7 +5377,8 @@ recheck:
 		return -EINVAL;
 
 
-	printk(KERN_DEBUG "Allow unpriv rt taskss to decrease priority %d.\n", cpid);
+	printk(KERN_DEBUG "Allow unpriv rt taskss to decrease priority %d.\n",
+			cpid);
 	/*
 	 * Allow unprivileged RT tasks to decrease priority:
 	 */
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 2ef689e..88dd013 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -26,6 +26,7 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	int leftmost = 1;
 	s64 key = get_deadline_key(ee);
 
+	ee->on_rq = 1;
 	while (*link) {
 		parent = *link;
 		current_entity = rb_entry(parent, struct sched_edf_entity,
@@ -54,6 +55,8 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
 				int sleep)
 {
+
+	ee->on_rq = 0;
 	if (erq->bottom_left == &ee->task_node) {
 		struct rb_node *next_node;
 
@@ -78,7 +81,12 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 	printk(KERN_DEBUG "EDF: enqueueing task(%d)\n", p->pid);
 
 	for_each_sched_edf_entity(ee) {
-		enqueue_edf_entity(erq, ee, -1);
+
+		/* If the entity is on an rq don't enqueue it. */
+		if (ee->on_rq)
+			break;
+		erq = ee->erq;
+		enqueue_edf_entity(erq, ee, wakeup);
 	}
 
 }
@@ -192,7 +200,7 @@ static void set_curr_task_edf(struct rq *rq)
 
 static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
 {
-	/* 
+	/*
 	 * TODO: I don't think that we will need this because I think that this
 	 * should be handled in check_preempt.
 	 * */
diff --git a/kernel/user_setsched.c b/kernel/user_setsched.c
index 9e8a70d..d36f2d6 100644
--- a/kernel/user_setsched.c
+++ b/kernel/user_setsched.c
@@ -11,8 +11,8 @@ SYSCALL_DEFINE3(user_setsched, pid_t, pid, int, policy, u_int16_t, timeout_val)
 	struct sched_param *param;
 	unsigned long deadline;
 
-	/* There is already a variable called 'current' that contains the current 
-	 * task.
+	/* There is already a variable called 'current' that contains the
+	 * current task.
 	 * */
 	crnt_tsk = find_task_by_vpid(pid);
 	deadline = jiffies + timeout_val * HZ;
-- 
1.7.9.5


From d5c46d042cf21f443367a5b652387e7f3e2bd51b Mon Sep 17 00:00:00 2001
From: Riley Spahn <rbs2152@columbia.edu>
Date: Wed, 27 Mar 2013 00:54:14 -0400
Subject: [PATCH 42/99] -found where bug in enqueue is but not how to fix it.

---
 kernel/sched.c     |    1 +
 kernel/sched_edf.c |   15 ++++++++++-----
 2 files changed, 11 insertions(+), 5 deletions(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index 07b78d8..da0a360 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -1720,6 +1720,7 @@ static void update_avg(u64 *avg, u64 sample)
 static void enqueue_task(struct rq *rq, struct task_struct *p, int wakeup)
 {
 	sched_info_queued(p);
+
 	p->sched_class->enqueue_task(rq, p, wakeup);
 	p->se.on_rq = 1;
 }
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 88dd013..b6f4934 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -26,8 +26,7 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	int leftmost = 1;
 	s64 key = get_deadline_key(ee);
 
-	ee->on_rq = 1;
-	while (*link) {
+	while (*link) { /* bug is in this line.  link is weird */
 		parent = *link;
 		current_entity = rb_entry(parent, struct sched_edf_entity,
 				task_node);
@@ -56,7 +55,6 @@ static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
 				int sleep)
 {
 
-	ee->on_rq = 0;
 	if (erq->bottom_left == &ee->task_node) {
 		struct rb_node *next_node;
 
@@ -77,14 +75,16 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 {
 	struct edf_rq *erq;
 	struct sched_edf_entity *ee = &p->edf;
+	struct sched_entity *se = &p->se;
 
 	printk(KERN_DEBUG "EDF: enqueueing task(%d)\n", p->pid);
 
 	for_each_sched_edf_entity(ee) {
 
 		/* If the entity is on an rq don't enqueue it. */
-		if (ee->on_rq)
+		if (se->on_rq)
 			break;
+		se->on_rq = 1;
 		erq = ee->erq;
 		enqueue_edf_entity(erq, ee, wakeup);
 	}
@@ -113,10 +113,14 @@ static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 {
 	struct edf_rq *erq;
 	struct sched_edf_entity *ee = &p->edf;
+	struct sched_entity *se;
+	se = &p->se;
+	se->on_rq = 0;
 
 	printk(KERN_DEBUG "EDF: denqueueing task(%d)\n", p->pid);
 
 	for_each_sched_edf_entity(ee) {
+		erq = ee->erq;
 		dequeue_entity_edf(erq, ee, -1);
 	}
 }
@@ -150,6 +154,7 @@ static struct sched_edf_entity *pick_next_entity_edf(struct edf_rq *erq)
  */
 static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
+	return NULL;
 	struct sched_edf_entity *next_entity = pick_next_entity_edf(&rq->edf);
 
 	if (next_entity == NULL)
@@ -195,7 +200,7 @@ static int move_one_task_edf(struct rq *rq, int cpu, struct rq *busy,
 
 static void set_curr_task_edf(struct rq *rq)
 {
-	struct task_struct *p = rq->curr;
+	// struct task_struct *p = rq->curr;
 }
 
 static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
-- 
1.7.9.5


From 240f56bc0e8983f5b68222142a87f47e30210e11 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Wed, 27 Mar 2013 11:05:44 -0400
Subject: [PATCH 43/99] -modified net_lock_wait_timeout() to be a blocking
 syscall -handled case that timeout_val is smaller
 than zero

---
 kernel/netlock.c |    6 ++++++
 1 file changed, 6 insertions(+)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 551cbca..a19c779 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -47,6 +47,10 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 
 	pid = current->pid;
 	if (type == NET_LOCK_USE) {
+		if (timeout_val < 0) {
+			printk(KERN_DEBUG "NETLOCK: timout_val should be >= 0.\n");
+			return -EINVAL;
+		}
 		printk(KERN_DEBUG "NETLOCK: attempting to acquite NETLOCK_USE.\n");
 		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
@@ -108,5 +112,7 @@ SYSCALL_DEFINE0(net_lock_wait_timeout)
 	edf_timer.data = 0;
 	edf_timer.function = sleep_unlock;
 	add_timer(&edf_timer);
+	/* block before timeout */
+	while (time_before(jiffies, earliest_deadline));
 	return 0;
 }
-- 
1.7.9.5


From ea07c009bcbba287240a5db3d4579b2f8f3ff50f Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Wed, 27 Mar 2013 13:53:19 -0400
Subject: [PATCH 44/99] -added netlock_type in task_struct

---
 include/linux/sched.h |    2 ++
 kernel/netlock.c      |   19 +++++++++++++++++--
 2 files changed, 19 insertions(+), 2 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 7f23f57..6efb3e2 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1431,6 +1431,8 @@ struct task_struct {
 	/* state flags for use by tracers */
 	unsigned long trace;
 #endif
+	/* 0:NET_LOCK_USE, 1:NET_LOCK_SLEEP */
+	int netlock_type;
 };
 
 /* Future-safe accessor for struct task_struct's cpus_allowed. */
diff --git a/kernel/netlock.c b/kernel/netlock.c
index a19c779..de9bcec 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -51,6 +51,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			printk(KERN_DEBUG "NETLOCK: timout_val should be >= 0.\n");
 			return -EINVAL;
 		}
+		current->netlock_type = NET_LOCK_USE;
 		printk(KERN_DEBUG "NETLOCK: attempting to acquite NETLOCK_USE.\n");
 		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
@@ -77,6 +78,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		else
 			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
+		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
 		down_write(&radio_rw);
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
@@ -95,10 +97,22 @@ SYSCALL_DEFINE0(net_unlock)
 	 * Didn't the sleeper say that both the user and the sleeper needs to
 	 * be able to call this?
 	 */
-	up_read(&radio_rw);
-	return 0;
+	if (current->netlock_type = NET_LOCK_USE) {
+		up_read(&radio_rw);
+		return 0;
+	} else if (current->netlock_type = NET_LOCK_USE) {
+		up_write(&radio_rw);
+		return 0;
+	} else {	
+		printk(KERN_DEBUG "NET_LOCK: invalid net_lock type.\n");
+		return -1;
+	}
 }
 
+/*
+ * This function will be called at the earliest deadline, but its function
+ * has been implemented in net_unlock().
+ */
 void sleep_unlock(unsigned long data)
 {
 	up_write(&radio_rw);
@@ -107,6 +121,7 @@ void sleep_unlock(unsigned long data)
 /* int net_lock_wait_timeout() */
 SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
+	earliest_deadline = jiffies + 7 * HZ;
 	init_timer(&edf_timer);
 	edf_timer.expires = earliest_deadline;
 	edf_timer.data = 0;
-- 
1.7.9.5


From b5e4ec22adc621b3509bd5c328fd664c1de86d8c Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Wed, 27 Mar 2013 14:35:52 -0400
Subject: [PATCH 45/99] -fixed errors in the usage of netlock_type

---
 kernel/netlock.c |    4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index de9bcec..6abd15d 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -51,7 +51,6 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			printk(KERN_DEBUG "NETLOCK: timout_val should be >= 0.\n");
 			return -EINVAL;
 		}
-		current->netlock_type = NET_LOCK_USE;
 		printk(KERN_DEBUG "NETLOCK: attempting to acquite NETLOCK_USE.\n");
 		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
@@ -66,6 +65,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
 		down_read(&radio_rw);
+		current->netlock_type = NET_LOCK_USE;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
 				pid);
@@ -78,9 +78,9 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		else
 			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
-		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
 		down_write(&radio_rw);
+		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
 		earliest_deadline = ULONG_MAX;
 		return 0;
-- 
1.7.9.5


From 9e138c7a16feb81cb1893457017e39d5b2677b9f Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Wed, 27 Mar 2013 18:24:05 -0400
Subject: [PATCH 46/99] fixed errors and bugs in netlock.c

---
 kernel/netlock.c |   15 +++++++++------
 1 file changed, 9 insertions(+), 6 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 6abd15d..d890ab2 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -51,7 +51,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			printk(KERN_DEBUG "NETLOCK: timout_val should be >= 0.\n");
 			return -EINVAL;
 		}
-		printk(KERN_DEBUG "NETLOCK: attempting to acquite NETLOCK_USE.\n");
+		printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK_USE.\n");
 		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
 		if (param == NULL) {
@@ -69,7 +69,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
 				pid);
-		returnval = sched_setscheduler(current, SCHED_EDF, param);
+	//	returnval = sched_setscheduler(current, SCHED_EDF, param);
 		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n",
 				returnval);
 		kfree(param);
@@ -97,11 +97,13 @@ SYSCALL_DEFINE0(net_unlock)
 	 * Didn't the sleeper say that both the user and the sleeper needs to
 	 * be able to call this?
 	 */
-	if (current->netlock_type = NET_LOCK_USE) {
+	if (current->netlock_type == NET_LOCK_USE) {
 		up_read(&radio_rw);
+		printk(KERN_DEBUG "NET_LOCK: radio rw lock (read) is released.\n");
 		return 0;
-	} else if (current->netlock_type = NET_LOCK_USE) {
+	} else if (current->netlock_type == NET_LOCK_SLEEP) {
 		up_write(&radio_rw);
+		printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
 		return 0;
 	} else {	
 		printk(KERN_DEBUG "NET_LOCK: invalid net_lock type.\n");
@@ -116,18 +118,19 @@ SYSCALL_DEFINE0(net_unlock)
 void sleep_unlock(unsigned long data)
 {
 	up_write(&radio_rw);
+	printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
 }
 
 /* int net_lock_wait_timeout() */
 SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
-	earliest_deadline = jiffies + 7 * HZ;
 	init_timer(&edf_timer);
 	edf_timer.expires = earliest_deadline;
 	edf_timer.data = 0;
 	edf_timer.function = sleep_unlock;
 	add_timer(&edf_timer);
 	/* block before timeout */
-	while (time_before(jiffies, earliest_deadline));
+	while (time_before(jiffies, earliest_deadline))
+		cond_resched();
 	return 0;
 }
-- 
1.7.9.5


From 3fa0f78d0741c04c158296c8aef6ba20266cd59f Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Wed, 27 Mar 2013 19:06:39 -0400
Subject: [PATCH 47/99] added negative inputs handers in my_net_app.c

---
 user_tests/my_net_app.c |    4 ++++
 1 file changed, 4 insertions(+)

diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index aef75a2..ee62d04 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -32,6 +32,10 @@ int main(int argc, char *argv[])
 		wait = atoi(argv[1]);
 		timeout = atoi(argv[2]);
 		spin = atoi(argv[3]);
+		if (wait < 0 || timeout < 0 || spin < 0) {
+			printf("Please provide positive values.\n");
+			return -1;
+		}
 		pid = getpid();
 		print_sec();
 		printf("sleeping ");
-- 
1.7.9.5


From 5ab6e3d2d860c582f802fd726ade0722ae1972df Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Wed, 27 Mar 2013 21:44:55 -0400
Subject: [PATCH 48/99] -added previous_prio and previous_policy in
 task_struct to record info of current process in the
 previous scheduler

---
 include/linux/sched.h |    2 ++
 kernel/netlock.c      |   24 +++++++++++++++++++-----
 2 files changed, 21 insertions(+), 5 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 6efb3e2..f9fe16a 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1140,6 +1140,7 @@ struct task_struct {
 #endif
 
 	int prio, static_prio, normal_prio;
+	int previous_prio;	/* Added 3/27/13 */
 	unsigned int rt_priority;
 	const struct sched_class *sched_class;
 	struct sched_entity se;
@@ -1166,6 +1167,7 @@ struct task_struct {
 #endif
 
 	unsigned int policy;
+	unsigned int previous_policy; /* Added 3/27/13 */
 	cpumask_t cpus_allowed;
 
 #ifdef CONFIG_PREEMPT_RCU
diff --git a/kernel/netlock.c b/kernel/netlock.c
index d890ab2..4e1424e 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -69,7 +69,17 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
 				pid);
-	//	returnval = sched_setscheduler(current, SCHED_EDF, param);
+		current->previous_policy = current->policy;
+		/*
+		 * I'm not quite sure if I assign the correct "priority" value
+		 * to current->previous_prio.
+		 */
+		if (current->previous_policy == SCHED_FIFO || 
+			current->previous_policy == SCHED_RR)
+			current->previous_prio = current->rt_priority;
+		else
+			current->previous_prio = current->prio;	
+		returnval = sched_setscheduler(current, SCHED_EDF, param);
 		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n",
 				returnval);
 		kfree(param);
@@ -93,12 +103,16 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
-	/*
-	 * Didn't the sleeper say that both the user and the sleeper needs to
-	 * be able to call this?
-	 */
+	struct sched_param *param; 
+	int returnval;
 	if (current->netlock_type == NET_LOCK_USE) {
 		up_read(&radio_rw);
+		param->sched_priority = current->previous_prio;
+		returnval = sched_setscheduler(current,
+					current->previous_policy, param);
+		kfree(param);
+		if (returnval != 0)
+			return -1;
 		printk(KERN_DEBUG "NET_LOCK: radio rw lock (read) is released.\n");
 		return 0;
 	} else if (current->netlock_type == NET_LOCK_SLEEP) {
-- 
1.7.9.5


From 778d39f0268146ddd4e65febb06ad54e6ddd95f2 Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Wed, 27 Mar 2013 23:09:24 -0400
Subject: [PATCH 49/99] Added unlock syscall in net_monitor.c

Please enter the commit message for your changes. Lines starting
---
 kernel/netlock.c         |   11 -----------
 user_tests/net_monitor.c |    4 ++++
 2 files changed, 4 insertions(+), 11 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 4e1424e..ab91b04 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -125,23 +125,12 @@ SYSCALL_DEFINE0(net_unlock)
 	}
 }
 
-/*
- * This function will be called at the earliest deadline, but its function
- * has been implemented in net_unlock().
- */
-void sleep_unlock(unsigned long data)
-{
-	up_write(&radio_rw);
-	printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
-}
-
 /* int net_lock_wait_timeout() */
 SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
 	init_timer(&edf_timer);
 	edf_timer.expires = earliest_deadline;
 	edf_timer.data = 0;
-	edf_timer.function = sleep_unlock;
 	add_timer(&edf_timer);
 	/* block before timeout */
 	while (time_before(jiffies, earliest_deadline))
diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
index 03b8743..1c2e1e3 100644
--- a/user_tests/net_monitor.c
+++ b/user_tests/net_monitor.c
@@ -11,6 +11,7 @@ int main(int argc, const char * argv[])
 {
 	int flag1;
 	int flag2;
+	int flag3;
 	while (1) {
 		flag1 = syscall(__NR_net_lock, 1, 0);
 		if (flag1 != 0)
@@ -18,6 +19,9 @@ int main(int argc, const char * argv[])
 		flag2 = syscall(__NR_net_lock_wait_timeout);
 		if (flag2 != 0)
 			printf("Waking up sleeper failed.\n");
+		flag3 = syscall(__NR_net_unlock);
+		if (flag3 != 0)
+                        printf("Releasing lock failed.\n");
 	}
 	return 0;
 }
-- 
1.7.9.5


From 24b6500e70a2e47a707150b7e24bfdc2ab9e27ae Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Wed, 27 Mar 2013 23:21:38 -0400
Subject: [PATCH 50/99] Fixed the timer function in netlock.c

---
 kernel/netlock.c         |    8 ++++----
 user_tests/my_net_app.c  |    3 ++-
 user_tests/net_monitor.c |    4 ++--
 3 files changed, 8 insertions(+), 7 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index ab91b04..1456c45 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -74,11 +74,11 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		 * I'm not quite sure if I assign the correct "priority" value
 		 * to current->previous_prio.
 		 */
-		if (current->previous_policy == SCHED_FIFO || 
+		if (current->previous_policy == SCHED_FIFO ||
 			current->previous_policy == SCHED_RR)
 			current->previous_prio = current->rt_priority;
 		else
-			current->previous_prio = current->prio;	
+			current->previous_prio = current->prio;
 		returnval = sched_setscheduler(current, SCHED_EDF, param);
 		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n",
 				returnval);
@@ -103,7 +103,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 /* int net_unlock(void) */
 SYSCALL_DEFINE0(net_unlock)
 {
-	struct sched_param *param; 
+	struct sched_param *param;
 	int returnval;
 	if (current->netlock_type == NET_LOCK_USE) {
 		up_read(&radio_rw);
@@ -119,7 +119,7 @@ SYSCALL_DEFINE0(net_unlock)
 		up_write(&radio_rw);
 		printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
 		return 0;
-	} else {	
+	} else {
 		printk(KERN_DEBUG "NET_LOCK: invalid net_lock type.\n");
 		return -1;
 	}
diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index ee62d04..e7a4d67 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -56,7 +56,8 @@ int main(int argc, char *argv[])
 		printf("return_net_lock ");
 		printf("pid:%d\n", pid);
 		/* start entering the loop */
-		for (i = 0; i < spin; i++);
+		for (i = 0; i < spin; i++)
+			;
 		print_sec();
 		printf("calling_net_unlock ");
 		printf("pid:%d\n", pid);
diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
index 1c2e1e3..e2fd1e0 100644
--- a/user_tests/net_monitor.c
+++ b/user_tests/net_monitor.c
@@ -7,7 +7,7 @@
 #define __NR_net_unlock 334
 #define __NR_net_lock_wait_timeout 335
 
-int main(int argc, const char * argv[])
+int main(int argc, const char *argv[])
 {
 	int flag1;
 	int flag2;
@@ -21,7 +21,7 @@ int main(int argc, const char * argv[])
 			printf("Waking up sleeper failed.\n");
 		flag3 = syscall(__NR_net_unlock);
 		if (flag3 != 0)
-                        printf("Releasing lock failed.\n");
+			printf("Releasing lock failed.\n");
 	}
 	return 0;
 }
-- 
1.7.9.5


From e6ad9608bc76043ed53a05cab0f4f1cedc12f9b9 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 09:09:01 -0400
Subject: [PATCH 51/99] -removed a bunch of todos.

---
 kernel/sched_edf.c |   11 ++++-------
 1 file changed, 4 insertions(+), 7 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index b6f4934..9f74101 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -26,6 +26,7 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	int leftmost = 1;
 	s64 key = get_deadline_key(ee);
 
+
 	while (*link) { /* bug is in this line.  link is weird */
 		parent = *link;
 		current_entity = rb_entry(parent, struct sched_edf_entity,
@@ -168,14 +169,15 @@ static struct task_struct *pick_next_task_edf(struct rq *rq)
  */
 static void put_prev_task_edf(struct rq *rq, struct task_struct *p)
 {
-	/* TODO */
+	/* TODO: This function must be implemented.  I think that that we can do it
+	 * by removing p from the rbtree and then calling pick_next_task
+	 * */
 }
 
 #ifdef CONFIG_SMP
 
 static int select_task_rq_edf(struct task_struct *p, int sd_flag, int flags)
 {
-	/* TODO */
 	return 0;
 }
 
@@ -186,14 +188,12 @@ static unsigned long load_balance_edf(struct rq *rq, int cpu, struct rq *busy,
 		  struct sched_domain *sd, enum cpu_idle_type idle,
 		  int *all_pinned, int *this_best_prio)
 {
-	/* TODO */
 	return 0;
 }
 
 static int move_one_task_edf(struct rq *rq, int cpu, struct rq *busy,
 		struct sched_domain *sd, enum cpu_idle_type)
 {
-	/* TODO */
 	return 0;
 }
 #endif /* CONFIG_SMP */
@@ -213,18 +213,15 @@ static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
 
 static void task_new_edf(struct rq *rq, struct task_struct *p)
 {
-	/* TODO */
 }
 
 static void prio_changed_edf(struct rq *rq, struct task_struct *p, int old,
 		int running)
 {
-	/* TODO */
 }
 
 static void switched_to_edf(struct rq *rq, struct task_struct *p, int running)
 {
-	/* TODO */
 }
 
 static const struct sched_class edf_sched_class = {
-- 
1.7.9.5


From 843cf96ce651a6e9d350116f1063e693a4193a85 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 09:49:05 -0400
Subject: [PATCH 52/99] -redid enqueue_entity_edf based on the insert function
 in rbtree.h

---
 kernel/sched_edf.c |   66 ++++++++++++++++++++++++----------------------------
 1 file changed, 31 insertions(+), 35 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 9f74101..c31be27 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -20,31 +20,27 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	/* This insert method is taken from the cfs enqueue function.  We have
 	 * very similary needs so it made sense to look at their code.
 	 */
-	struct rb_node **link = &erq->radio_task_root.rb_node;
+	struct rb_node **p = &erq->radio_task_root.rb_node;
 	struct rb_node *parent = NULL;
 	struct sched_edf_entity *current_entity;
 	int leftmost = 1;
-	s64 key = get_deadline_key(ee);
-
-
-	while (*link) { /* bug is in this line.  link is weird */
-		parent = *link;
-		current_entity = rb_entry(parent, struct sched_edf_entity,
-				task_node);
-
-		if (key < get_deadline_key(current_entity)) {
-			link = &parent->rb_left;
+	s64 insert_key = get_deadline_key(ee);
+	int is_smallest = 1;
+
+	/* Start at the root. */
+	while (*p) {
+		parent = *p;
+		current_entity = rb_entry(*parent, struct sched_edf_entity, task_node);
+		current_key = get_deadline_key(current_entity);
+		if (insert_key < current_key) {
+			p = &(*p)->rb_left;
 		} else {
-			link = &parent->rb_right;
-			/* If you go right then you know it's not the
-			 * smallest
-			 */
-			leftmost = 0;
+			p = &(*p)->rb_right;
+			is_smallest = 0;
 		}
 	}
-	if (leftmost)
-		erq->bottom_left = &ee->task_node;
-
+	if (is_smallest == 1)
+		erq->bottom_left = current_entity->task_node;
 	rb_link_node(&ee->task_node, parent, link);
 	rb_insert_color(&ee->task_node, &erq->radio_task_root);
 
@@ -52,22 +48,6 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	erq->nr_running++;
 }
 
-static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
-				int sleep)
-{
-
-	if (erq->bottom_left == &ee->task_node) {
-		struct rb_node *next_node;
-
-		next_node = rb_next(&ee->task_node);
-		erq->bottom_left = next_node;
-	}
-
-	rb_erase(&ee->task_node, &erq->radio_task_root);
-	/* This should be atomic.*/
-	erq->nr_running--;
-}
-
 /**
  * Called when a task is to be enqueued. Expects that the sched_edf_entity
  * already has it's deadline set in hertz.
@@ -89,9 +69,25 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 		erq = ee->erq;
 		enqueue_edf_entity(erq, ee, wakeup);
 	}
+}
+
+static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
+				int sleep)
+{
+
+	if (erq->bottom_left == &ee->task_node) {
+		struct rb_node *next_node;
+
+		next_node = rb_next(&ee->task_node);
+		erq->bottom_left = next_node;
+	}
 
+	rb_erase(&ee->task_node, &erq->radio_task_root);
+	/* This should be atomic.*/
+	erq->nr_running--;
 }
 
+
 static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 		int sync)
 {
-- 
1.7.9.5


From 7a0c04e1261399009e7658ec458bdda3ae315636 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 09:54:06 -0400
Subject: [PATCH 53/99] -fixed type errors.

---
 kernel/sched_edf.c |    8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index c31be27..e3b810e 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -23,14 +23,14 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	struct rb_node **p = &erq->radio_task_root.rb_node;
 	struct rb_node *parent = NULL;
 	struct sched_edf_entity *current_entity;
-	int leftmost = 1;
 	s64 insert_key = get_deadline_key(ee);
+	s64 current_key;
 	int is_smallest = 1;
 
 	/* Start at the root. */
 	while (*p) {
 		parent = *p;
-		current_entity = rb_entry(*parent, struct sched_edf_entity, task_node);
+		current_entity = rb_entry(parent, struct sched_edf_entity, task_node);
 		current_key = get_deadline_key(current_entity);
 		if (insert_key < current_key) {
 			p = &(*p)->rb_left;
@@ -40,8 +40,8 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 		}
 	}
 	if (is_smallest == 1)
-		erq->bottom_left = current_entity->task_node;
-	rb_link_node(&ee->task_node, parent, link);
+		erq->bottom_left = &ee->task_node;
+	rb_link_node(&ee->task_node, parent, p);
 	rb_insert_color(&ee->task_node, &erq->radio_task_root);
 
 	/* This should be atomic*/
-- 
1.7.9.5


From 2d2bb6a5e1d9ac77a030106790bea1bf27da269f Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 10:49:20 -0400
Subject: [PATCH 54/99] -added building commands to make install.

---
 user_tests/Makefile |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/user_tests/Makefile b/user_tests/Makefile
index 2f16547..0a1d581 100644
--- a/user_tests/Makefile
+++ b/user_tests/Makefile
@@ -45,7 +45,7 @@ $(NET_APP): $(NET_APP).c
 	$(CC) -c $(INCLUDE) $(CFLAGS) $(NET_APP).c -o $(NET_APP).o
 	$(CC) $(LDFLAGS) -o $(NET_APP) $(NET_APP).o
 
-install:
+install: $(NET_APP) $(NET_MON)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_APP) $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb shell chmod 777 $(INSTALL_DIR)/$(NET_APP)
 	$(ANDROID_SDK_ROOT)/platform-tools/adb push $(NET_MON) $(INSTALL_DIR)/$(NET_MON)
-- 
1.7.9.5


From 1a781a9108e03fb890dc3e5a64a41681abf690ad Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 12:16:32 -0400
Subject: [PATCH 55/99] -added param malloc in net_unlock so it does not free
 an unmalloced pointer.

---
 kernel/netlock.c |    8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 1456c45..32b7e75 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -107,6 +107,14 @@ SYSCALL_DEFINE0(net_unlock)
 	int returnval;
 	if (current->netlock_type == NET_LOCK_USE) {
 		up_read(&radio_rw);
+
+		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
+		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
+		if (param == NULL) {
+			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
+			return -EINVAL;
+		}
+
 		param->sched_priority = current->previous_prio;
 		returnval = sched_setscheduler(current,
 					current->previous_policy, param);
-- 
1.7.9.5


From 49eee4a0be8e5b513ddedf68b1a6f346783595b6 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Thu, 28 Mar 2013 14:06:26 -0400
Subject: [PATCH 56/99] fixed errors in netlock.c

---
 kernel/netlock.c |    8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 1456c45..5f54e56 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -107,6 +107,8 @@ SYSCALL_DEFINE0(net_unlock)
 	int returnval;
 	if (current->netlock_type == NET_LOCK_USE) {
 		up_read(&radio_rw);
+		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
+		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
 		param->sched_priority = current->previous_prio;
 		returnval = sched_setscheduler(current,
 					current->previous_policy, param);
@@ -125,12 +127,18 @@ SYSCALL_DEFINE0(net_unlock)
 	}
 }
 
+void do_nothing(unsigned long data)
+{
+	return;
+}
+
 /* int net_lock_wait_timeout() */
 SYSCALL_DEFINE0(net_lock_wait_timeout)
 {
 	init_timer(&edf_timer);
 	edf_timer.expires = earliest_deadline;
 	edf_timer.data = 0;
+	edf_timer.function = do_nothing;
 	add_timer(&edf_timer);
 	/* block before timeout */
 	while (time_before(jiffies, earliest_deadline))
-- 
1.7.9.5


From 82ab341aeeddbe492b250c1b5d03b8e8fceb8f5f Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Thu, 28 Mar 2013 14:18:47 -0400
Subject: [PATCH 57/99] fixed errors in netlock.c

---
 kernel/netlock.c |   11 -----------
 1 file changed, 11 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index fc34c5f..5f54e56 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -107,19 +107,8 @@ SYSCALL_DEFINE0(net_unlock)
 	int returnval;
 	if (current->netlock_type == NET_LOCK_USE) {
 		up_read(&radio_rw);
-<<<<<<< HEAD
 		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
-=======
-
-		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
-		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
-		if (param == NULL) {
-			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
-			return -EINVAL;
-		}
-
->>>>>>> 1a781a9108e03fb890dc3e5a64a41681abf690ad
 		param->sched_priority = current->previous_prio;
 		returnval = sched_setscheduler(current,
 					current->previous_policy, param);
-- 
1.7.9.5


From 3290d2467719337ca874b181599d17fa4b599276 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 14:32:42 -0400
Subject: [PATCH 58/99] -moevd enqueueing_task out of loop.

---
 kernel/sched_edf.c |   18 ++++++++----------
 1 file changed, 8 insertions(+), 10 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index e3b810e..6f8dee5 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -55,20 +55,19 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 {
 	struct edf_rq *erq;
-	struct sched_edf_entity *ee = &p->edf;
-	struct sched_entity *se = &p->se;
+	struct sched_edf_entity *edf_entity = &p->edf;
 
 	printk(KERN_DEBUG "EDF: enqueueing task(%d)\n", p->pid);
 
-	for_each_sched_edf_entity(ee) {
+	erq = edf_entity->erq;
+	enqueue_edf_entity(erq, edf_entity, wakeup);
+	/*
+	for_each_sched_edf_entity(edf_entity) {
 
-		/* If the entity is on an rq don't enqueue it. */
-		if (se->on_rq)
-			break;
-		se->on_rq = 1;
-		erq = ee->erq;
-		enqueue_edf_entity(erq, ee, wakeup);
+		erq = edf_entity->erq;
+		enqueue_edf_entity(erq, edf_entity, wakeup);
 	}
+	*/
 }
 
 static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
@@ -151,7 +150,6 @@ static struct sched_edf_entity *pick_next_entity_edf(struct edf_rq *erq)
  */
 static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
-	return NULL;
 	struct sched_edf_entity *next_entity = pick_next_entity_edf(&rq->edf);
 
 	if (next_entity == NULL)
-- 
1.7.9.5


From a44fcbbad597a335bd2764a3ffb0dc43fe338214 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 14:38:31 -0400
Subject: [PATCH 59/99] -corrected naming to correspond with macro.

---
 kernel/sched_edf.c |   14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 6f8dee5..325b8b0 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -55,19 +55,19 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 {
 	struct edf_rq *erq;
-	struct sched_edf_entity *edf_entity = &p->edf;
+	struct sched_edf_entity *edf_se = &p->edf;
 
 	printk(KERN_DEBUG "EDF: enqueueing task(%d)\n", p->pid);
 
-	erq = edf_entity->erq;
-	enqueue_edf_entity(erq, edf_entity, wakeup);
 	/*
-	for_each_sched_edf_entity(edf_entity) {
+	 * erq = edf_entity->erq;
+	 * enqueue_edf_entity(erq, edf_entity, wakeup);
+	*/
 
-		erq = edf_entity->erq;
-		enqueue_edf_entity(erq, edf_entity, wakeup);
+	for_each_sched_edf_entity(edf_se) {
+		erq = edf_se->erq;
+		enqueue_edf_entity(erq, edf_se, wakeup);
 	}
-	*/
 }
 
 static void dequeue_entity_edf(struct edf_rq *erq, struct sched_edf_entity *ee,
-- 
1.7.9.5


From d3489322aa4e19fd9bcfb7e28c4d8745ff0b7fc2 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Thu, 28 Mar 2013 22:53:59 -0400
Subject: [PATCH 60/99] -handled nulls in the enqueueing.

---
 kernel/sched.c     |    6 ++++++
 kernel/sched_edf.c |   24 +++++++++++++-----------
 2 files changed, 19 insertions(+), 11 deletions(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index da0a360..76299d9 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -2396,6 +2396,12 @@ int wake_up_state(struct task_struct *p, unsigned int state)
  */
 static void __sched_fork(struct task_struct *p)
 {
+
+	/* Added 3/28/13 */
+	p->edf.deadline = 0;
+	p->edf.on_rq = 0;
+	p->edf.erq = NULL;
+
 	p->se.exec_start		= 0;
 	p->se.sum_exec_runtime		= 0;
 	p->se.prev_sum_exec_runtime	= 0;
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 325b8b0..90897ef 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -20,14 +20,16 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	/* This insert method is taken from the cfs enqueue function.  We have
 	 * very similary needs so it made sense to look at their code.
 	 */
-	struct rb_node **p = &erq->radio_task_root.rb_node;
+	struct rb_root root = erq->radio_task_root;
+	struct rb_node **p = &(root.rb_node);
 	struct rb_node *parent = NULL;
 	struct sched_edf_entity *current_entity;
+
 	s64 insert_key = get_deadline_key(ee);
 	s64 current_key;
 	int is_smallest = 1;
 
-	/* Start at the root. */
+	/* Start at the root.*/
 	while (*p) {
 		parent = *p;
 		current_entity = rb_entry(parent, struct sched_edf_entity, task_node);
@@ -42,8 +44,12 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	if (is_smallest == 1)
 		erq->bottom_left = &ee->task_node;
 	rb_link_node(&ee->task_node, parent, p);
-	rb_insert_color(&ee->task_node, &erq->radio_task_root);
-
+	// printk(KERN_DEBUG "rb_is_red(parent) = %d\n", rb_is_red(parent));
+	if(parent == NULL) {
+		rb_set_black(root.rb_node);
+	} else {
+		rb_insert_color(&ee->task_node, &erq->radio_task_root);
+	}
 	/* This should be atomic*/
 	erq->nr_running++;
 }
@@ -57,14 +63,10 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 	struct edf_rq *erq;
 	struct sched_edf_entity *edf_se = &p->edf;
 
-	printk(KERN_DEBUG "EDF: enqueueing task(%d)\n", p->pid);
-
-	/*
-	 * erq = edf_entity->erq;
-	 * enqueue_edf_entity(erq, edf_entity, wakeup);
-	*/
-
 	for_each_sched_edf_entity(edf_se) {
+		if (edf_se->erq == NULL){
+			edf_se->erq = &(rq->edf);
+		}
 		erq = edf_se->erq;
 		enqueue_edf_entity(erq, edf_se, wakeup);
 	}
-- 
1.7.9.5


From 8d14d84f7dc09fbbe2ac4ae770dc0a500b426b17 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Fri, 29 Mar 2013 15:34:03 -0400
Subject: [PATCH 61/99] -added randomness in preemption to satisfy hw
 requirement.

---
 kernel/sched_edf.c |   20 +++++++++++++++++---
 1 file changed, 17 insertions(+), 3 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 90897ef..525e537 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -1,3 +1,4 @@
+#include <linux/random.h>
 
 static const struct sched_class edf_sched_class;
 
@@ -101,10 +102,23 @@ static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 	 * TODO: Does this need to be more complicated?
 	 *
 	 */
-	unsigned long curr_deadline = get_deadline(rq->curr);
-	unsigned long new_deadline = get_deadline(p);
-	if (new_deadline < curr_deadline)
+
+	unsigned char rand_byte;
+	unsigned char limit;
+	unsigned long curr_deadline;
+	unsigned long new_deadline;
+
+	limit = 205; /* 2^8*.8 ~= 205. */
+	get_random_bytes(&rand_byte, 1);
+	
+	if (rand_byte < limit) {
+		curr_deadline = get_deadline(rq->curr);
+		new_deadline = get_deadline(p);
+		if (new_deadline > curr_deadline)
+			resched_task(rq->curr);
+	} else {
 		resched_task(rq->curr);
+	}
 }
 
 static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
-- 
1.7.9.5


From 6751f0557c752a0c5c36f9ffc255d4029b82f2c8 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Fri, 29 Mar 2013 16:04:15 -0400
Subject: [PATCH 62/99] -checkpatch corrections I forgot on last commit.

---
 kernel/sched_edf.c |   20 +++++++++-----------
 1 file changed, 9 insertions(+), 11 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 525e537..17791a4 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -33,7 +33,8 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	/* Start at the root.*/
 	while (*p) {
 		parent = *p;
-		current_entity = rb_entry(parent, struct sched_edf_entity, task_node);
+		current_entity = rb_entry(parent, struct sched_edf_entity,
+				task_node);
 		current_key = get_deadline_key(current_entity);
 		if (insert_key < current_key) {
 			p = &(*p)->rb_left;
@@ -45,12 +46,10 @@ static void enqueue_edf_entity(struct edf_rq *erq, struct sched_edf_entity *ee,
 	if (is_smallest == 1)
 		erq->bottom_left = &ee->task_node;
 	rb_link_node(&ee->task_node, parent, p);
-	// printk(KERN_DEBUG "rb_is_red(parent) = %d\n", rb_is_red(parent));
-	if(parent == NULL) {
+	if (parent == NULL)
 		rb_set_black(root.rb_node);
-	} else {
+	else
 		rb_insert_color(&ee->task_node, &erq->radio_task_root);
-	}
 	/* This should be atomic*/
 	erq->nr_running++;
 }
@@ -65,9 +64,8 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 	struct sched_edf_entity *edf_se = &p->edf;
 
 	for_each_sched_edf_entity(edf_se) {
-		if (edf_se->erq == NULL){
+		if (edf_se->erq == NULL)
 			edf_se->erq = &(rq->edf);
-		}
 		erq = edf_se->erq;
 		enqueue_edf_entity(erq, edf_se, wakeup);
 	}
@@ -110,7 +108,7 @@ static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 
 	limit = 205; /* 2^8*.8 ~= 205. */
 	get_random_bytes(&rand_byte, 1);
-	
+
 	if (rand_byte < limit) {
 		curr_deadline = get_deadline(rq->curr);
 		new_deadline = get_deadline(p);
@@ -179,8 +177,8 @@ static struct task_struct *pick_next_task_edf(struct rq *rq)
  */
 static void put_prev_task_edf(struct rq *rq, struct task_struct *p)
 {
-	/* TODO: This function must be implemented.  I think that that we can do it
-	 * by removing p from the rbtree and then calling pick_next_task
+	/* TODO: This function must be implemented.  I think that that we can do
+	 * it by removing p from the rbtree and then calling pick_next_task
 	 * */
 }
 
@@ -210,7 +208,7 @@ static int move_one_task_edf(struct rq *rq, int cpu, struct rq *busy,
 
 static void set_curr_task_edf(struct rq *rq)
 {
-	// struct task_struct *p = rq->curr;
+	/* struct task_struct *p = rq->curr; */
 }
 
 static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
-- 
1.7.9.5


From 664360d335e0f5bdd93d15e7f5e06ae796bd2587 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Fri, 29 Mar 2013 16:57:37 -0400
Subject: [PATCH 63/99] -added select_task_rq to the edf scheduler.

---
 kernel/sched_edf.c |   33 +++++++++++++++++++++++++++------
 1 file changed, 27 insertions(+), 6 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 17791a4..89f095c 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -186,7 +186,28 @@ static void put_prev_task_edf(struct rq *rq, struct task_struct *p)
 
 static int select_task_rq_edf(struct task_struct *p, int sd_flag, int flags)
 {
-	return 0;
+	int i;
+	/*
+	 * Keep track of the cpu with the fewest processes on the rq and
+	 * the number associated with the cpu.
+	 *
+	 */
+	unsigned long lowest_cpu = -1;
+	unsigned long lowest_count = ULONG_MAX;
+
+	/* Online CPUs can be scheduled. */
+	for_each_online_cpu(i) {
+		struct rq *current_rq;
+		current_rq = cpu_rq(i);
+		if (current_rq->nr_running < lowest_count) {
+			lowest_cpu = i;
+			lowest_count = current_rq->nr_running;
+		}
+	}
+	if (lowest_cpu == -1)
+		return task_cpu(p);
+	else
+		return lowest_cpu;
 }
 
 /*
@@ -236,16 +257,16 @@ static const struct sched_class edf_sched_class = {
 	.next			= &fair_sched_class,
 	.enqueue_task		= enqueue_task_edf,
 	.dequeue_task		= dequeue_task_edf,
-	.yield_task		= yield_task_edf,
+	.yield_task		= yield_task_edf, /* Do not need. */
 	.check_preempt_curr	= check_preempt_curr_edf,
 	.pick_next_task		= pick_next_task_edf,
-	.put_prev_task		= put_prev_task_edf,
+	.put_prev_task		= put_prev_task_edf, /* Do not need. */
 #ifdef CONFIG_SMP
 	.select_task_rq		= select_task_rq_edf,
-	.load_balance		= load_balance_edf,
-	.move_one_task		= move_one_task_edf,
+	.load_balance		= load_balance_edf, /* Do not need. */
+	.move_one_task		= move_one_task_edf, /* Do not need. */
 #endif /* CONFIG_SMP */
-	.set_curr_task		= set_curr_task_edf,
+	.set_curr_task		= set_curr_task_edf, /* Do not need. */
 	.task_tick		= task_tick_edf,
 	.task_new		= task_new_edf,
 	.prio_changed		= prio_changed_edf,
-- 
1.7.9.5


From c12b4e6650b0c16d6942125fac28c68bb600b407 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Fri, 29 Mar 2013 17:20:55 -0400
Subject: [PATCH 64/99] -added task_tick_edf function. -It will call resched
 if the bottom left node has a sooner deadline.

---
 kernel/sched_edf.c |   17 +++++++++++++----
 1 file changed, 13 insertions(+), 4 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 89f095c..74db641 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -234,10 +234,19 @@ static void set_curr_task_edf(struct rq *rq)
 
 static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
 {
-	/*
-	 * TODO: I don't think that we will need this because I think that this
-	 * should be handled in check_preempt.
-	 * */
+	/* Check if there is a function with a sooner deadline. */
+	struct sched_edf_entity *bottom_left_entity;
+	bottom_left_entity = rb_entry(rq->edf.bottom_left,
+			struct sched_edf_entity, task_node);
+
+
+	unsigned long current_deadline = get_deadline(cur);
+	unsigned long bottom_left_deadline = bottom_left_entity->deadline;
+
+	if (current_deadline > bottom_left_deadline) {
+		/* current should be preempted. */
+		set_tsk_need_resched(cur);
+	}
 }
 
 static void task_new_edf(struct rq *rq, struct task_struct *p)
-- 
1.7.9.5


From 5ae7b62e862eeaa91334809d668d368eabfb8ee3 Mon Sep 17 00:00:00 2001
From: Riley Spahn <riley@cs.columbia.edu>
Date: Fri, 29 Mar 2013 17:38:25 -0400
Subject: [PATCH 65/99] -added switched_to function based on the fair
 scheduler one.

---
 kernel/sched_edf.c |   13 ++++++++++---
 1 file changed, 10 insertions(+), 3 deletions(-)

diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 74db641..d530566 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -112,7 +112,7 @@ static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 	if (rand_byte < limit) {
 		curr_deadline = get_deadline(rq->curr);
 		new_deadline = get_deadline(p);
-		if (new_deadline > curr_deadline)
+		if (new_deadline < curr_deadline)
 			resched_task(rq->curr);
 	} else {
 		resched_task(rq->curr);
@@ -236,12 +236,14 @@ static void task_tick_edf(struct rq *rq, struct task_struct *cur, int queued)
 {
 	/* Check if there is a function with a sooner deadline. */
 	struct sched_edf_entity *bottom_left_entity;
+	unsigned long current_deadline;
+	unsigned long bottom_left_deadline;
 	bottom_left_entity = rb_entry(rq->edf.bottom_left,
 			struct sched_edf_entity, task_node);
 
 
-	unsigned long current_deadline = get_deadline(cur);
-	unsigned long bottom_left_deadline = bottom_left_entity->deadline;
+	current_deadline = get_deadline(cur);
+	bottom_left_deadline = bottom_left_entity->deadline;
 
 	if (current_deadline > bottom_left_deadline) {
 		/* current should be preempted. */
@@ -260,6 +262,11 @@ static void prio_changed_edf(struct rq *rq, struct task_struct *p, int old,
 
 static void switched_to_edf(struct rq *rq, struct task_struct *p, int running)
 {
+	/* If the task is running then try to resched */
+	if (running)
+		resched_task(rq->curr);
+	else
+		check_preempt_curr_edf(rq, p, 0);
 }
 
 static const struct sched_class edf_sched_class = {
-- 
1.7.9.5


From 9d68be19cf4294c548c413d9e684baf5ae87c034 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Fri, 29 Mar 2013 23:05:30 -0400
Subject: [PATCH 66/99] -modified netlock.c to give users higher priorities
 than sleepers -modified the data type of spin in
 my_net_app.c to long

---
 kernel/netlock.c        |   15 +++++++++++++++
 user_tests/my_net_app.c |    4 ++--
 2 files changed, 17 insertions(+), 2 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 5f54e56..0b7cce3 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -5,9 +5,14 @@
 #include <linux/slab.h>
 #include <linux/syscalls.h>
 #include <linux/timer.h>
+#include <linux/types.h>
+#include <linux/delay.h>
+
+#define DELAY 100
 
 unsigned long earliest_deadline;
 struct timer_list edf_timer;
+atomic_t use_num;
 
 enum __netlock_t {
 	NET_LOCK_USE,
@@ -59,6 +64,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			return -EINVAL;
 		}
 		printk(KERN_DEBUG "NETLOCK: Acquiring NET_LOCK for user.\n");
+		atomic_inc(&use_num);
 		deadline = jiffies + timeout_val * HZ;
 		param->deadline = deadline;
 		param->sched_priority = 0;
@@ -89,6 +95,8 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
+		if (atomic_read(&use_num) > 0)
+			mdelay(DELAY);	
 		down_write(&radio_rw);
 		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
@@ -107,7 +115,12 @@ SYSCALL_DEFINE0(net_unlock)
 	int returnval;
 	if (current->netlock_type == NET_LOCK_USE) {
 		up_read(&radio_rw);
+		atomic_dec(&use_num);
 		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
+		if (param == NULL) {	
+			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
+			return -EINVAL;
+		} 
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
 		param->sched_priority = current->previous_prio;
 		returnval = sched_setscheduler(current,
@@ -129,6 +142,8 @@ SYSCALL_DEFINE0(net_unlock)
 
 void do_nothing(unsigned long data)
 {
+//	up_write(&radio_rw);
+//	printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
 	return;
 }
 
diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index e7a4d67..3e2715f 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -20,9 +20,9 @@ int main(int argc, char *argv[])
 	pid_t pid;
 	int wait;
 	int timeout;
-	int spin;
 	int flag;
 	int i;
+	long spin;
 	if (strcmp(argv[0], "./my_net_app") == 0) {
 		if (argc != 4) {
 			printf("Please provide a valid command.\n");
@@ -31,7 +31,7 @@ int main(int argc, char *argv[])
 		}
 		wait = atoi(argv[1]);
 		timeout = atoi(argv[2]);
-		spin = atoi(argv[3]);
+		spin = atol(argv[3]);
 		if (wait < 0 || timeout < 0 || spin < 0) {
 			printf("Please provide positive values.\n");
 			return -1;
-- 
1.7.9.5


From 6a0ab7c1805971d51e11345247b241304ee8361c Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sat, 30 Mar 2013 10:28:25 -0400
Subject: [PATCH 67/99] -added conditional that will bail out of net_monitor
 loop if it does not acquire the net_lock.

---
 user_tests/net_monitor.c |    8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
index e2fd1e0..d2b818e 100644
--- a/user_tests/net_monitor.c
+++ b/user_tests/net_monitor.c
@@ -14,8 +14,14 @@ int main(int argc, const char *argv[])
 	int flag3;
 	while (1) {
 		flag1 = syscall(__NR_net_lock, 1, 0);
-		if (flag1 != 0)
+		if (flag1 != 0) {
+			/* 
+			 * If you don't acquire the lock then you don't want to
+			 * continue and release the lock that you don't posses.
+			 */
 			printf("Requiring lock failed.\n");
+			continue;
+		}
 		flag2 = syscall(__NR_net_lock_wait_timeout);
 		if (flag2 != 0)
 			printf("Waking up sleeper failed.\n");
-- 
1.7.9.5


From ea23c5ed329c2db3f6090309e12ca1304348afdd Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sat, 30 Mar 2013 12:24:23 -0400
Subject: [PATCH 68/99] -added conditionals to net_monitor so that you do not
 try to acquire the net_lock if you already have it or
 release it if you do not. -added ULONG_MAX as the
 default for the earliest_deadline.  This way the
 timer does not return immediately.

---
 kernel/netlock.c         |    2 +-
 user_tests/net_monitor.c |   47 ++++++++++++++++++++++++++++++++--------------
 2 files changed, 34 insertions(+), 15 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 0b7cce3..d155b41 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -10,7 +10,7 @@
 
 #define DELAY 100
 
-unsigned long earliest_deadline;
+unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
 atomic_t use_num;
 
diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
index d2b818e..8186f84 100644
--- a/user_tests/net_monitor.c
+++ b/user_tests/net_monitor.c
@@ -12,22 +12,41 @@ int main(int argc, const char *argv[])
 	int flag1;
 	int flag2;
 	int flag3;
+	flag1 = flag2 = flag3 = 0;
 	while (1) {
-		flag1 = syscall(__NR_net_lock, 1, 0);
-		if (flag1 != 0) {
-			/* 
-			 * If you don't acquire the lock then you don't want to
-			 * continue and release the lock that you don't posses.
-			 */
-			printf("Requiring lock failed.\n");
-			continue;
+		/* Only acquire the net_lock if it was successfully unlocked. */
+		if (flag3 == 0) {
+			flag1 = syscall(__NR_net_lock, 1, 0);
+			if (flag1 != 0) {
+				/* 
+				 * If you don't acquire the lock then you don't want to
+				 * continue and release the lock that you don't posses.
+				 */
+				printf("Requiring lock failed.\n");
+				continue;
+			}
+		} else 
+			flag1 = -1;
+
+		/* 
+		 * It only makes sense to wait for the timeout if you have 
+		 * the lock.
+		 */
+		if (flag1 == 0) {
+			flag2 = syscall(__NR_net_lock_wait_timeout);
+			if (flag2 != 0)
+				printf("Waking up sleeper failed.\n");
+		}
+
+		/*
+		 * It makes no sense to try and release a lock that you do not
+		 * posses.
+		 */
+		if (flag1 == 0) {
+			flag3 = syscall(__NR_net_unlock);
+			if (flag3 != 0)
+				printf("Releasing lock failed.\n");
 		}
-		flag2 = syscall(__NR_net_lock_wait_timeout);
-		if (flag2 != 0)
-			printf("Waking up sleeper failed.\n");
-		flag3 = syscall(__NR_net_unlock);
-		if (flag3 != 0)
-			printf("Releasing lock failed.\n");
 	}
 	return 0;
 }
-- 
1.7.9.5


From 3e24d14d4c4fd2f33d0ece9e9b4b1074a97b4f80 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sat, 30 Mar 2013 13:27:56 -0400
Subject: [PATCH 69/99] -refactored net_monitor to use a has lock variable.

---
 user_tests/net_monitor.c |   14 +++++++++-----
 1 file changed, 9 insertions(+), 5 deletions(-)

diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
index 8186f84..14a403c 100644
--- a/user_tests/net_monitor.c
+++ b/user_tests/net_monitor.c
@@ -13,9 +13,10 @@ int main(int argc, const char *argv[])
 	int flag2;
 	int flag3;
 	flag1 = flag2 = flag3 = 0;
+	int has_lock = 0;
 	while (1) {
 		/* Only acquire the net_lock if it was successfully unlocked. */
-		if (flag3 == 0) {
+		if (!has_lock) {
 			flag1 = syscall(__NR_net_lock, 1, 0);
 			if (flag1 != 0) {
 				/* 
@@ -24,15 +25,16 @@ int main(int argc, const char *argv[])
 				 */
 				printf("Requiring lock failed.\n");
 				continue;
+			} else {
+				has_lock = 1;
 			}
-		} else 
-			flag1 = -1;
+		}
 
 		/* 
 		 * It only makes sense to wait for the timeout if you have 
 		 * the lock.
 		 */
-		if (flag1 == 0) {
+		if (has_lock) {
 			flag2 = syscall(__NR_net_lock_wait_timeout);
 			if (flag2 != 0)
 				printf("Waking up sleeper failed.\n");
@@ -42,10 +44,12 @@ int main(int argc, const char *argv[])
 		 * It makes no sense to try and release a lock that you do not
 		 * posses.
 		 */
-		if (flag1 == 0) {
+		if (has_lock) {
 			flag3 = syscall(__NR_net_unlock);
 			if (flag3 != 0)
 				printf("Releasing lock failed.\n");
+			else
+				has_lock = 0;
 		}
 	}
 	return 0;
-- 
1.7.9.5


From b073654b97610b46675a215f0aa7dfe99764758b Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sat, 30 Mar 2013 13:37:25 -0400
Subject: [PATCH 70/99] modified conditions to give readers higher priorities

---
 kernel/netlock.c |    9 ++-------
 1 file changed, 2 insertions(+), 7 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index d155b41..cd7edb1 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -6,9 +6,6 @@
 #include <linux/syscalls.h>
 #include <linux/timer.h>
 #include <linux/types.h>
-#include <linux/delay.h>
-
-#define DELAY 100
 
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
@@ -95,8 +92,8 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
-		if (atomic_read(&use_num) > 0)
-			mdelay(DELAY);	
+		while (atomic_read(&use_num) > 0)
+			schedule();
 		down_write(&radio_rw);
 		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
@@ -142,8 +139,6 @@ SYSCALL_DEFINE0(net_unlock)
 
 void do_nothing(unsigned long data)
 {
-//	up_write(&radio_rw);
-//	printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
 	return;
 }
 
-- 
1.7.9.5


From 0ba9d5f732ffd17e349bd410759328f30868e821 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sat, 30 Mar 2013 13:53:55 -0400
Subject: [PATCH 71/99] -removed debugging statements from scheduler.

---
 kernel/sched.c |   18 +++++++++---------
 1 file changed, 9 insertions(+), 9 deletions(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index 76299d9..434fed5 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -5375,7 +5375,7 @@ recheck:
 	 * 1..MAX_USER_RT_PRIO-1, valid priority for SCHED_NORMAL,
 	 * SCHED_BATCH and SCHED_IDLE is 0.
 	 */
-	printk(KERN_DEBUG "Testing for valid priorities %d .\n", cpid);
+	/* printk(KERN_DEBUG "Testing for valid priorities %d .\n", cpid); */
 	if (param->sched_priority < 0 ||
 	    (p->mm && param->sched_priority > MAX_USER_RT_PRIO-1) ||
 	    (!p->mm && param->sched_priority > MAX_RT_PRIO-1))
@@ -5384,8 +5384,8 @@ recheck:
 		return -EINVAL;
 
 
-	printk(KERN_DEBUG "Allow unpriv rt taskss to decrease priority %d.\n",
-			cpid);
+	/*printk(KERN_DEBUG "Allow unpriv rt taskss to decrease priority %d.\n",
+			cpid);*/
 	/*
 	 * Allow unprivileged RT tasks to decrease priority:
 	 */
@@ -5419,7 +5419,7 @@ recheck:
 			return -EPERM;
 	}
 
-	printk(KERN_DEBUG "if(user) %d\n", cpid);
+	/* printk(KERN_DEBUG "if(user) %d\n", cpid); */
 	if (user) {
 #ifdef CONFIG_RT_GROUP_SCHED
 		/*
@@ -5436,7 +5436,7 @@ recheck:
 			return retval;
 	}
 
-	printk(KERN_DEBUG "spin_lock_irqsave.\n");
+	/*printk(KERN_DEBUG "spin_lock_irqsave.\n");*/
 	/*
 	 * make sure no PI-waiters arrive (or leave) while we are
 	 * changing the priority of the task:
@@ -5468,18 +5468,18 @@ recheck:
 	oldprio = p->prio;
 
 	/* This is where the p->sched_class actually gets set. */
-	printk(KERN_DEBUG "__setscheduler.\n");
+	/*printk(KERN_DEBUG "__setscheduler.\n");*/
 	__setscheduler(rq, p, policy, param->sched_priority);
 
-	printk(KERN_DEBUG "if (running)\n");
+	/*printk(KERN_DEBUG "if (running)\n");*/
 	if (running) {
-		printk(KERN_DEBUG "Task is running: %d\n", cpid);
+		/*printk(KERN_DEBUG "Task is running: %d\n", cpid);*/
 
 		/* Bug may be here */
 		p->sched_class->set_curr_task(rq);
 	}
 	if (on_rq) {
-		printk(KERN_DEBUG "Task is on rq: %d\n", cpid);
+		/* printk(KERN_DEBUG "Task is on rq: %d\n", cpid); */
 
 		/* Bug may be here */
 		activate_task(rq, p, 0);
-- 
1.7.9.5


From 9a02c5459b255f703df2d87c43970ba703cf9610 Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Sat, 30 Mar 2013 14:03:48 -0400
Subject: [PATCH 72/99] -Implemented new readwrite_semaphore instead of using
 the rw_semaphore

---
 kernel/netlock.c |   41 +++++++++++++++++++++++++++++++++++++++++
 1 file changed, 41 insertions(+)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index d155b41..9b01767 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -13,6 +13,47 @@
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
 atomic_t use_num;
+/*
+struct semaphore rw_mutex;
+struct semaphore mutex;
+sema_init(&rw_mutex, 1);
+sema_init(&mutex, 1);
+atomic read_count=0;
+
+int down_read(struct semaphore *rw_mutex, struct semaphore mutex, count)
+{
+	wait(mutex);
+	atomic_inc(&read_count);
+	if (read_count == 1)
+		wait(rw_mutex);
+	signal(mutex);
+	return 0;
+}
+
+int up_read(struct semaphore *rw_mutex, struct semaphore mutex, count)
+{
+	wait(mutex);
+	atomic_dec(&read_count);
+	if (read_count == 0)
+		signal(rw_mutex);
+	signal(mutex);
+	return 0;
+}
+
+int down_write(struct semaphore *rw_mutex, struct semaphore mutex, count)
+{
+	while (read_count > 0);
+	wait(rw_mutex);
+	return 0;
+}
+
+int up_write(struct semaphore *rw_mutex, struct semaphore mutex, count)
+{
+	signal(rw_mutex);
+	return 0;
+}
+
+*/
 
 enum __netlock_t {
 	NET_LOCK_USE,
-- 
1.7.9.5


From 2e74eee8f31299984fd52fb651387d37abcc8194 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sat, 30 Mar 2013 14:14:02 -0400
Subject: [PATCH 73/99] -modified commented rw lock to be simpler.

---
 kernel/netlock.c |   17 ++++++++---------
 1 file changed, 8 insertions(+), 9 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index cd2c22c..1c53d53 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -12,34 +12,33 @@ struct timer_list edf_timer;
 atomic_t use_num;
 /*
 struct semaphore rw_mutex;
-struct semaphore mutex;
+struct semaphore count_mutex;
 sema_init(&rw_mutex, 1);
 sema_init(&mutex, 1);
-atomic read_count=0;
+unsigned long read_count=0;
 
 int down_read(struct semaphore *rw_mutex, struct semaphore mutex, count)
 {
-	wait(mutex);
-	atomic_inc(&read_count);
+	wait(count_mutex);
+	read_count ++;
 	if (read_count == 1)
 		wait(rw_mutex);
-	signal(mutex);
+	signal(count_mutex);
 	return 0;
 }
 
 int up_read(struct semaphore *rw_mutex, struct semaphore mutex, count)
 {
-	wait(mutex);
-	atomic_dec(&read_count);
+	wait(count_mutex);
+	read_count --;
 	if (read_count == 0)
 		signal(rw_mutex);
-	signal(mutex);
+	signal(count_mutex);
 	return 0;
 }
 
 int down_write(struct semaphore *rw_mutex, struct semaphore mutex, count)
 {
-	while (read_count > 0);
 	wait(rw_mutex);
 	return 0;
 }
-- 
1.7.9.5


From d6560fb93c5d371c8a03bc2055cb104413d8338d Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sat, 30 Mar 2013 14:45:08 -0400
Subject: [PATCH 74/99] moved to using a read priority rw.

---
 kernel/netlock.c |   64 +++++++++++++++++++++++++++++++++---------------------
 1 file changed, 39 insertions(+), 25 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 1c53d53..4b0f824 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -1,3 +1,4 @@
+#include <linux/semaphore.h>
 #include <linux/jiffies.h>
 #include <linux/kernel.h>
 #include <linux/rwsem.h>
@@ -10,46 +11,61 @@
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
 atomic_t use_num;
+
+/*
+ * ============================================================================
+ * This starts the implementation of a read write semaphore that favors
+ * readers.  The built in rw_semaphore does not meet our needs because a writer
+ * acquiring the lock will block readers.
+ *
+ * Note: The code is basically from the slides.
+ *	 rp appended to the functions indicates read priority.
+ * ============================================================================
+ */
 /*
 struct semaphore rw_mutex;
 struct semaphore count_mutex;
 sema_init(&rw_mutex, 1);
-sema_init(&mutex, 1);
-unsigned long read_count=0;
+sema_init(&count_mutex, 1);
+*/
+static DECLARE_MUTEX(rw_mutex);
+static DECLARE_MUTEX(count_mutex);
+unsigned long read_count = 0;
 
-int down_read(struct semaphore *rw_mutex, struct semaphore mutex, count)
+int down_read_rp()
 {
-	wait(count_mutex);
-	read_count ++;
+	down(&count_mutex);
+	read_count++;
+	printk(KERN_DEBUG "read_coutn = %d\n", read_count);
 	if (read_count == 1)
-		wait(rw_mutex);
-	signal(count_mutex);
+		down(&rw_mutex);
+	up(&count_mutex);
 	return 0;
 }
 
-int up_read(struct semaphore *rw_mutex, struct semaphore mutex, count)
+int up_read_rp()
 {
-	wait(count_mutex);
-	read_count --;
+	down(&count_mutex);
+	read_count--;
+	printk(KERN_DEBUG "read_coutn = %d\n", read_count);
 	if (read_count == 0)
-		signal(rw_mutex);
-	signal(count_mutex);
+		up(&rw_mutex);
+	up(&count_mutex);
 	return 0;
 }
 
-int down_write(struct semaphore *rw_mutex, struct semaphore mutex, count)
+int down_write_rp()
 {
-	wait(rw_mutex);
+	down(&rw_mutex);
 	return 0;
 }
 
-int up_write(struct semaphore *rw_mutex, struct semaphore mutex, count)
+int up_write_rp()
 {
-	signal(rw_mutex);
+	up(&rw_mutex);
 	return 0;
 }
 
-*/
 
 enum __netlock_t {
 	NET_LOCK_USE,
@@ -107,7 +123,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		param->sched_priority = 0;
 		update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
-		down_read(&radio_rw);
+		down_read_rp();
 		current->netlock_type = NET_LOCK_USE;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
@@ -132,9 +148,7 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
-		while (atomic_read(&use_num) > 0)
-			schedule();
-		down_write(&radio_rw);
+		down_write_rp();
 		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
 		earliest_deadline = ULONG_MAX;
@@ -151,13 +165,13 @@ SYSCALL_DEFINE0(net_unlock)
 	struct sched_param *param;
 	int returnval;
 	if (current->netlock_type == NET_LOCK_USE) {
-		up_read(&radio_rw);
+		up_read_rp();
 		atomic_dec(&use_num);
 		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
-		if (param == NULL) {	
+		if (param == NULL) {
 			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
 			return -EINVAL;
-		} 
+		}
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
 		param->sched_priority = current->previous_prio;
 		returnval = sched_setscheduler(current,
@@ -168,7 +182,7 @@ SYSCALL_DEFINE0(net_unlock)
 		printk(KERN_DEBUG "NET_LOCK: radio rw lock (read) is released.\n");
 		return 0;
 	} else if (current->netlock_type == NET_LOCK_SLEEP) {
-		up_write(&radio_rw);
+		up_write_rp();
 		printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
 		return 0;
 	} else {
-- 
1.7.9.5


From 0a8782bfc17a57866ef3f6df101934e0159c821e Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Sat, 30 Mar 2013 18:23:04 -0400
Subject: [PATCH 75/99] added condition check before down_write.

---
 kernel/netlock.c |   10 +++-------
 1 file changed, 3 insertions(+), 7 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 4b0f824..f130091 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -7,11 +7,11 @@
 #include <linux/syscalls.h>
 #include <linux/timer.h>
 #include <linux/types.h>
+#define delay 100
 
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
 atomic_t use_num;
-
 /*
  * ============================================================================
  * This starts the implementation of a read write semaphore that favors
@@ -22,12 +22,6 @@ atomic_t use_num;
  *	 rp appended to the functions indicates read priority.
  * ============================================================================
  */
-/*
-struct semaphore rw_mutex;
-struct semaphore count_mutex;
-sema_init(&rw_mutex, 1);
-sema_init(&count_mutex, 1);
-*/
 static DECLARE_MUTEX(rw_mutex);
 static DECLARE_MUTEX(count_mutex);
 unsigned long read_count = 0;
@@ -123,6 +117,8 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		param->sched_priority = 0;
 		update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
+		if use_num > 0
+			mdelay(delay);
 		down_read_rp();
 		current->netlock_type = NET_LOCK_USE;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
-- 
1.7.9.5


From 99910e5b67d4330bba07f50101dc7b512bfcd3fe Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Sat, 30 Mar 2013 19:49:06 -0400
Subject: [PATCH 76/99] Added priority stored and restored in net_lock and
 net_unlock.

---
 include/linux/sched.h |    2 ++
 kernel/netlock.c      |   13 ++++++++-----
 2 files changed, 10 insertions(+), 5 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index f9fe16a..acef9bd 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1141,6 +1141,8 @@ struct task_struct {
 
 	int prio, static_prio, normal_prio;
 	int previous_prio;	/* Added 3/27/13 */
+	int previous_rt_priority;
+	int previous_normal_prio;
 	unsigned int rt_priority;
 	const struct sched_class *sched_class;
 	struct sched_entity se;
diff --git a/kernel/netlock.c b/kernel/netlock.c
index f130091..33ab645 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -7,7 +7,6 @@
 #include <linux/syscalls.h>
 #include <linux/timer.h>
 #include <linux/types.h>
-#define delay 100
 
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
@@ -117,23 +116,24 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		param->sched_priority = 0;
 		update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
-		if use_num > 0
-			mdelay(delay);
 		down_read_rp();
 		current->netlock_type = NET_LOCK_USE;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
 				pid);
 		current->previous_policy = current->policy;
+		current->previous_prio = current->prio;
+		current->previous_rt_priority = current->rt_priority;
+		current->previous_normal_prio = current->normal_prio;
 		/*
 		 * I'm not quite sure if I assign the correct "priority" value
 		 * to current->previous_prio.
-		 */
 		if (current->previous_policy == SCHED_FIFO ||
 			current->previous_policy == SCHED_RR)
 			current->previous_prio = current->rt_priority;
 		else
 			current->previous_prio = current->prio;
+		*/
 		returnval = sched_setscheduler(current, SCHED_EDF, param);
 		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n",
 				returnval);
@@ -169,7 +169,10 @@ SYSCALL_DEFINE0(net_unlock)
 			return -EINVAL;
 		}
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
-		param->sched_priority = current->previous_prio;
+		current->prio = current->previous_prio;
+		current->normal_prio = current->previous_normal_prio;
+		current->rt_priority = current->previous_rt_priority;
+		param->sched_priority = current->previous_rt_priority;
 		returnval = sched_setscheduler(current,
 					current->previous_policy, param);
 		kfree(param);
-- 
1.7.9.5


From f600fdeddb29b2758dd0e1c3c4110149eafbb97b Mon Sep 17 00:00:00 2001
From: MENG YAO <my2372@columbia.edu>
Date: Sun, 31 Mar 2013 02:34:29 -0400
Subject: [PATCH 77/99] -added coversheet and README -deleted rw_semaphore in
 netlock.c

---
 README_HW3.txt                     |   38 +++++++++++++
 arch/x86/include/asm/unistd_32.h   |    1 -
 arch/x86/kernel/syscall_table_32.S |    1 -
 kernel/Makefile                    |    2 +-
 kernel/netlock.c                   |    9 +---
 kernel/user_setsched.c             |   21 --------
 pg_cover.txt                       |  103 ++++++++++++++++++++++++++++++++++++
 7 files changed, 143 insertions(+), 32 deletions(-)
 create mode 100644 README_HW3.txt
 delete mode 100644 kernel/user_setsched.c
 create mode 100644 pg_cover.txt

diff --git a/README_HW3.txt b/README_HW3.txt
new file mode 100644
index 0000000..65faef5
--- /dev/null
+++ b/README_HW3.txt
@@ -0,0 +1,38 @@
+README for OS Homework Assignment 3
+
+#Files:
+* kernel/netlock.c
+	* net_lock - the syscall 333 that we added, which is a reader-writer synchronization primitive that priorizes use over sleeping and sets the current process to our edf scheduler.
+	* net_unlock - the syscall 334 that releases the reader-writer lock and puts the current process to its previous scheduler.
+	* net_lock_wait_timeout - the syscall 335 we added that wake up the sleeper at the earliest timeout.
+
+* kernel/sched_edf.c
+
+
+	
+* kernel/sched.c
+	* added struct edf_rq to sched.c
+	* added struct edf_rq field to struct cfs_rq
+	* initialized edf variables in __sched_fork
+	* added case SCHED_EDF in __setscheduler
+	* init_edf_rq - function which initializes edf run queue.
+	
+* kernel/sched_rt.c
+	* modified .next field in struct sched_class to edf_sched_class
+
+* include/linux/sched.h
+	* defined SCHED_EDF as policy 6.
+	* added unsigned long deadline field to sched_param.
+	* added struct sche_edf_entity.
+	* added int previous_rt_priority, int previous_normal_prio, int previous_prio, int previous_policy, int netlock_type, struct sched_edf_entity field to task_struct;
+
+* user_tests/Makefile
+
+* user_tests/net_monitor.c
+	* contains the net_monitor user program that runs as a daemon which acquires a sleep net lock and turns on at the earliest timeout.
+	* to build: >> make
+
+* user_tests/my_net_app.c
+	* contains the my_net_app user program that aquires user lock and releases the lock after for loop.
+	* to build: >> make
+ 
diff --git a/arch/x86/include/asm/unistd_32.h b/arch/x86/include/asm/unistd_32.h
index 9407755..58ccdfa 100644
--- a/arch/x86/include/asm/unistd_32.h
+++ b/arch/x86/include/asm/unistd_32.h
@@ -341,7 +341,6 @@
 #define __NR_net_lock		333		/* Added on 3/5/2013 */
 #define __NR_net_unlock		334		/* Added on 3/5/2013 */
 #define __NR_net_lock_wait_timeout	335	/* Added on 3/5/2013 */
-#define __NR_user_setsched	336		/* Added on 3/22/2013*/
 
 #ifdef __KERNEL__
 
diff --git a/arch/x86/kernel/syscall_table_32.S b/arch/x86/kernel/syscall_table_32.S
index 54087fb..ad876bc 100644
--- a/arch/x86/kernel/syscall_table_32.S
+++ b/arch/x86/kernel/syscall_table_32.S
@@ -335,4 +335,3 @@ ENTRY(sys_call_table)
 	.long sys_net_lock				/* Added on 3/5/2013 */
 	.long sys_net_unlock				/* Added on 3/5/2013 */
 	.long sys_net_lock_wait_timeout /* 335 */	/* Added on 3/5/2013 */
-	.long sys_user_setsched		/* 336 */	/* Added on 3/22/2013*/
diff --git a/kernel/Makefile b/kernel/Makefile
index 8d21b72..34fea09 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -10,7 +10,7 @@ obj-y     = sched.o fork.o exec_domain.o panic.o printk.o \
 	    kthread.o wait.o kfifo.o sys_ni.o posix-cpu-timers.o mutex.o \
 	    hrtimer.o rwsem.o nsproxy.o srcu.o semaphore.o \
 	    notifier.o ksysfs.o pm_qos_params.o sched_clock.o cred.o \
-	    async.o netlock.o user_setsched.o
+	    async.o netlock.o
 
 ifdef CONFIG_FUNCTION_TRACER
 # Do not trace debug files and internal ftrace files
diff --git a/kernel/netlock.c b/kernel/netlock.c
index 33ab645..1b56a48 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -66,17 +66,10 @@ enum __netlock_t {
 };
 typedef enum __netlock_t netlock_t;
 
-DECLARE_RWSEM(radio_rw);
-
 /*
  * Called by the scheduler when a process on the EDF queue is moved to a queue
  * with a lower priority
- */
-int up_rw_lock()
-{
-	up_read(&radio_rw);
-	return 0;
-}
+*/
 
 void update_timer(unsigned long new_deadline)
 {
diff --git a/kernel/user_setsched.c b/kernel/user_setsched.c
deleted file mode 100644
index d36f2d6..0000000
--- a/kernel/user_setsched.c
+++ /dev/null
@@ -1,21 +0,0 @@
-#include <linux/timer.h>
-#include <linux/jiffies.h>
-#include <linux/kernel.h>
-#include <linux/syscalls.h>
-#include <linux/sched.h>
-
-/* int user_setsched(pid_t pid, int policy, u_int16_t timeout_val) */
-SYSCALL_DEFINE3(user_setsched, pid_t, pid, int, policy, u_int16_t, timeout_val)
-{
-	struct task_struct *crnt_tsk;
-	struct sched_param *param;
-	unsigned long deadline;
-
-	/* There is already a variable called 'current' that contains the
-	 * current task.
-	 * */
-	crnt_tsk = find_task_by_vpid(pid);
-	deadline = jiffies + timeout_val * HZ;
-	param->deadline = deadline;
-	return	sched_setscheduler(crnt_tsk, policy, param);
-}
diff --git a/pg_cover.txt b/pg_cover.txt
new file mode 100644
index 0000000..1690c79
--- /dev/null
+++ b/pg_cover.txt
@@ -0,0 +1,103 @@
+
+                     W4118 Spring 2013 Programming Assignment
+
+Assignment Number:  hw3
+   
+Group Number:  group11
+
+Name and UNI of Group Member 1: _________rbs2152________________
+   
+Name and UNI of Group Member 2: _________pq2117________________
+
+Name and UNI of Group Member 3: _________my2372________________
+   
+
+We certify that:
+   	   -->> Our code compiles and works for all reasonable inputs
+	   _ Our code compiles, but does not work for all inputs
+	   _ Our code does not compile
+
+    * While we may have discussed the assignment with others, the code
+       submitted is entirely our own group's work and no other student 
+       has edited it.
+     * So far as we have been able to determine, the program properly
+       handles all reasonable inputs.
+
+   Further instructions to the student: 
+     * Check your code to make sure it is readable. You may wish to
+       add some comments, change a variable name, or even restructure the
+       code. This also often helps you find bugs in the code.
+     * Include this file with the files you submit for your
+       programming assignment.  The file should be named  "pg_cover.txt".
+
+     * Describe below how each member of your group contributed to the
+       assignment.  Include a list of C functions and files that you modified
+       or implemented and which group member was primarily responsible
+       for doing each.  All group members are expected to contribute in
+       writing the code for each assignment.
+       
+Member Contributions:
+#Riley Spahn(rbs2151):
+
+
+
+#Pei Qin(pq2117):
+
+
+
+#Meng Yao(my2372):
+
+
+
+
+
+If your program does not work for all test inputs or does not compile,
+please complete the following section. You should describe below what 
+the bug is and how you tried to debug it. Document only the most
+significant bug. This is you chance to get partial credit for code
+that does not pass testing. If you do not make a good faith effort to fill this
+section in when you know your code doesn't compile/work, you may
+automatically be given a zero for those parts of the assignment
+
+     * Describe the conditions that cause the program to fail. For
+       example, you may know that it always fails for a particular input
+       or kind of input. Or you may know that it always fails when try it
+       for the second time, or when a certain procedure gets called with
+       a certain argument or when a particular global variable has a
+       particular value.
+       
+     
+
+
+
+     * When the program fails, what error message or other output does it
+       generate?
+       
+     
+     
+     
+     * What does the error message mean? 
+       
+     
+     
+     
+     * When the program fails, which of your procedures is it running?
+       
+     
+     
+     * In your source code, put comments /*** Buggy code here ***/
+       around the line that it is executing when it fails. Describe
+       below how you know that this is the right line.  If you can't 
+       determine which line then put BOLD comments around the 
+       different possible lines it could be executing. 
+       
+     
+     
+     * Do you believe the bug is in this procedure? If not, do you think
+       it's in a procedure that called it, or in some procedure that was
+       executed previously and that either returned a bad value, or that
+       placed a bad value in a variable someplace? Why? Note: we're not
+       asking you to get this right. We're just asking you to give a
+       plausible answer with a plausible justification, enough to show
+       that you're developing sound reasoning processes for diagnosis.
+ 
-- 
1.7.9.5


From 6e4e1230a2048bee11bf3124d045ce579825ec9a Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 10:16:56 -0400
Subject: [PATCH 78/99] -checkpatch test programs and netlock.c -deleted
 unused functions in netlock.c -added header files

---
 include/linux/netlock.h  |   10 +++++++++
 include/linux/sched.h    |    8 +++----
 kernel/netlock.c         |   53 ++++++++++++----------------------------------
 user_tests/my_net_app.c  |    7 +++---
 user_tests/net_monitor.c |   14 ++++++------
 user_tests/netlock.h     |   10 +++++++++
 6 files changed, 49 insertions(+), 53 deletions(-)
 create mode 100644 include/linux/netlock.h
 create mode 100644 user_tests/netlock.h

diff --git a/include/linux/netlock.h b/include/linux/netlock.h
new file mode 100644
index 0000000..371cb6a
--- /dev/null
+++ b/include/linux/netlock.h
@@ -0,0 +1,10 @@
+#ifndef NETLOCK_H_
+#define NETLOCK_H_
+
+enum __netlock_t {
+	NET_LOCK_USE,
+	NET_LOCK_SLEEP
+};
+typedef enum __netlock_t netlock_t;
+
+#endif
diff --git a/include/linux/sched.h b/include/linux/sched.h
index acef9bd..a7cfd24 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1140,9 +1140,9 @@ struct task_struct {
 #endif
 
 	int prio, static_prio, normal_prio;
-	int previous_prio;	/* Added 3/27/13 */
-	int previous_rt_priority;
-	int previous_normal_prio;
+	int prev_prio;	/* Added 3/27/13 */
+	int prev_rt_priority;
+	int prev_normal_prio;
 	unsigned int rt_priority;
 	const struct sched_class *sched_class;
 	struct sched_entity se;
@@ -1169,7 +1169,7 @@ struct task_struct {
 #endif
 
 	unsigned int policy;
-	unsigned int previous_policy; /* Added 3/27/13 */
+	unsigned int prev_policy; /* Added 3/27/13 */
 	cpumask_t cpus_allowed;
 
 #ifdef CONFIG_PREEMPT_RCU
diff --git a/kernel/netlock.c b/kernel/netlock.c
index 33ab645..378de16 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -7,6 +7,7 @@
 #include <linux/syscalls.h>
 #include <linux/timer.h>
 #include <linux/types.h>
+#include "linux/netlock.h"
 
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
@@ -23,13 +24,13 @@ atomic_t use_num;
  */
 static DECLARE_MUTEX(rw_mutex);
 static DECLARE_MUTEX(count_mutex);
-unsigned long read_count = 0;
+unsigned long read_count;
 
 int down_read_rp()
 {
 	down(&count_mutex);
 	read_count++;
-	printk(KERN_DEBUG "read_coutn = %d\n", read_count);
+	printk(KERN_DEBUG "read_count = %lu\n", read_count);
 	if (read_count == 1)
 		down(&rw_mutex);
 	up(&count_mutex);
@@ -40,7 +41,7 @@ int up_read_rp()
 {
 	down(&count_mutex);
 	read_count--;
-	printk(KERN_DEBUG "read_coutn = %d\n", read_count);
+	printk(KERN_DEBUG "read_count = %lu\n", read_count);
 	if (read_count == 0)
 		up(&rw_mutex);
 	up(&count_mutex);
@@ -59,25 +60,6 @@ int up_write_rp()
 	return 0;
 }
 
-
-enum __netlock_t {
-	NET_LOCK_USE,
-	NET_LOCK_SLEEP
-};
-typedef enum __netlock_t netlock_t;
-
-DECLARE_RWSEM(radio_rw);
-
-/*
- * Called by the scheduler when a process on the EDF queue is moved to a queue
- * with a lower priority
- */
-int up_rw_lock()
-{
-	up_read(&radio_rw);
-	return 0;
-}
-
 void update_timer(unsigned long new_deadline)
 {
 	earliest_deadline = min(new_deadline, earliest_deadline);
@@ -121,19 +103,10 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
 		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
 				pid);
-		current->previous_policy = current->policy;
-		current->previous_prio = current->prio;
-		current->previous_rt_priority = current->rt_priority;
-		current->previous_normal_prio = current->normal_prio;
-		/*
-		 * I'm not quite sure if I assign the correct "priority" value
-		 * to current->previous_prio.
-		if (current->previous_policy == SCHED_FIFO ||
-			current->previous_policy == SCHED_RR)
-			current->previous_prio = current->rt_priority;
-		else
-			current->previous_prio = current->prio;
-		*/
+		current->prev_policy = current->policy;
+		current->prev_prio = current->prio;
+		current->prev_rt_priority = current->rt_priority;
+		current->prev_normal_prio = current->normal_prio;
 		returnval = sched_setscheduler(current, SCHED_EDF, param);
 		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n",
 				returnval);
@@ -169,12 +142,12 @@ SYSCALL_DEFINE0(net_unlock)
 			return -EINVAL;
 		}
 		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
-		current->prio = current->previous_prio;
-		current->normal_prio = current->previous_normal_prio;
-		current->rt_priority = current->previous_rt_priority;
-		param->sched_priority = current->previous_rt_priority;
+		current->prio = current->prev_prio;
+		current->normal_prio = current->prev_normal_prio;
+		current->rt_priority = current->prev_rt_priority;
+		param->sched_priority = current->prev_rt_priority;
 		returnval = sched_setscheduler(current,
-					current->previous_policy, param);
+					current->prev_policy, param);
 		kfree(param);
 		if (returnval != 0)
 			return -1;
diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index 3e2715f..44b60f5 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -3,6 +3,7 @@
 #include <sys/syscall.h>
 #include <sys/time.h>
 #include <unistd.h>
+#include "netlock.h"
 
 #define __NR_net_lock 333
 #define __NR_net_unlock 334
@@ -20,9 +21,9 @@ int main(int argc, char *argv[])
 	pid_t pid;
 	int wait;
 	int timeout;
+	int spin;
 	int flag;
 	int i;
-	long spin;
 	if (strcmp(argv[0], "./my_net_app") == 0) {
 		if (argc != 4) {
 			printf("Please provide a valid command.\n");
@@ -31,7 +32,7 @@ int main(int argc, char *argv[])
 		}
 		wait = atoi(argv[1]);
 		timeout = atoi(argv[2]);
-		spin = atol(argv[3]);
+		spin = atoi(argv[3]);
 		if (wait < 0 || timeout < 0 || spin < 0) {
 			printf("Please provide positive values.\n");
 			return -1;
@@ -47,7 +48,7 @@ int main(int argc, char *argv[])
 		printf("calling_net_lock ");
 		printf("pid:%d\n", pid);
 		/* start acquiring the use lock */
-		flag = syscall(__NR_net_lock, 0, timeout);
+		flag = syscall(__NR_net_lock, NET_LOCK_USE, timeout);
 		if (flag != 0) {
 			printf("Requiring lock failed.\n");
 			return -1;
diff --git a/user_tests/net_monitor.c b/user_tests/net_monitor.c
index 14a403c..e51f4a7 100644
--- a/user_tests/net_monitor.c
+++ b/user_tests/net_monitor.c
@@ -2,6 +2,7 @@
 #include <stdlib.h>
 #include <sys/syscall.h>
 #include <unistd.h>
+#include "netlock.h"
 
 #define __NR_net_lock 333
 #define __NR_net_unlock 334
@@ -17,11 +18,12 @@ int main(int argc, const char *argv[])
 	while (1) {
 		/* Only acquire the net_lock if it was successfully unlocked. */
 		if (!has_lock) {
-			flag1 = syscall(__NR_net_lock, 1, 0);
+			flag1 = syscall(__NR_net_lock, NET_LOCK_SLEEP, 0);
 			if (flag1 != 0) {
-				/* 
-				 * If you don't acquire the lock then you don't want to
-				 * continue and release the lock that you don't posses.
+				/*
+				 * If you don't acquire the lock then you don't
+				 * want to continue and release the lock that
+				 * you don't posses.
 				 */
 				printf("Requiring lock failed.\n");
 				continue;
@@ -30,8 +32,8 @@ int main(int argc, const char *argv[])
 			}
 		}
 
-		/* 
-		 * It only makes sense to wait for the timeout if you have 
+		/*
+		 * It only makes sense to wait for the timeout if you have
 		 * the lock.
 		 */
 		if (has_lock) {
diff --git a/user_tests/netlock.h b/user_tests/netlock.h
new file mode 100644
index 0000000..371cb6a
--- /dev/null
+++ b/user_tests/netlock.h
@@ -0,0 +1,10 @@
+#ifndef NETLOCK_H_
+#define NETLOCK_H_
+
+enum __netlock_t {
+	NET_LOCK_USE,
+	NET_LOCK_SLEEP
+};
+typedef enum __netlock_t netlock_t;
+
+#endif
-- 
1.7.9.5


From 0254af08a9a3b35222c848101e5c016c99881887 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 10:38:19 -0400
Subject: [PATCH 79/99] -pushed it again, deleted it by accident just now

---
 kernel/netlock.c |  189 ++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 189 insertions(+)
 create mode 100644 kernel/netlock.c

diff --git a/kernel/netlock.c b/kernel/netlock.c
new file mode 100644
index 0000000..f43dd4f
--- /dev/null
+++ b/kernel/netlock.c
@@ -0,0 +1,189 @@
+#include <linux/semaphore.h>
+#include <linux/jiffies.h>
+#include <linux/kernel.h>
+#include <linux/rwsem.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/syscalls.h>
+#include <linux/timer.h>
+#include <linux/types.h>
+
+unsigned long earliest_deadline = ULONG_MAX;
+struct timer_list edf_timer;
+atomic_t use_num;
+/*
+ * ============================================================================
+ * This starts the implementation of a read write semaphore that favors
+ * readers.  The built in rw_semaphore does not meet our needs because a writer
+ * acquiring the lock will block readers.
+ *
+ * Note: The code is basically from the slides.
+ *	 rp appended to the functions indicates read priority.
+ * ============================================================================
+ */
+static DECLARE_MUTEX(rw_mutex);
+static DECLARE_MUTEX(count_mutex);
+unsigned long read_count;
+
+int down_read_rp()
+{
+	down(&count_mutex);
+	read_count++;
+	printk(KERN_DEBUG "read_count = %lu\n", read_count);
+	if (read_count == 1)
+		down(&rw_mutex);
+	up(&count_mutex);
+	return 0;
+}
+
+int up_read_rp()
+{
+	down(&count_mutex);
+	read_count--;
+	printk(KERN_DEBUG "read_count = %lu\n", read_count);
+	if (read_count == 0)
+		up(&rw_mutex);
+	up(&count_mutex);
+	return 0;
+}
+
+int down_write_rp()
+{
+	down(&rw_mutex);
+	return 0;
+}
+
+int up_write_rp()
+{
+	up(&rw_mutex);
+	return 0;
+}
+
+
+enum __netlock_t {
+	NET_LOCK_USE,
+	NET_LOCK_SLEEP
+};
+typedef enum __netlock_t netlock_t;
+
+void update_timer(unsigned long new_deadline)
+{
+	earliest_deadline = min(new_deadline, earliest_deadline);
+	if (earliest_deadline == new_deadline)
+		mod_timer(&edf_timer, earliest_deadline);
+}
+
+/* int net_lock(netlock_t type, u_int16_t timeout_val) */
+SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
+{
+	int returnval;
+	pid_t pid;
+	unsigned long deadline;
+	struct sched_param *param;
+
+	printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK: %d\n",
+			current->pid);
+
+	pid = current->pid;
+	if (type == NET_LOCK_USE) {
+		if (timeout_val < 0) {
+			printk(KERN_DEBUG "NETLOCK: timout_val should be >= 0.\n");
+			return -EINVAL;
+		}
+		printk(KERN_DEBUG "NETLOCK: attempting to acquire NETLOCK_USE.\n");
+		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
+		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
+		if (param == NULL) {
+			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
+			return -EINVAL;
+		}
+		printk(KERN_DEBUG "NETLOCK: Acquiring NET_LOCK for user.\n");
+		atomic_inc(&use_num);
+		deadline = jiffies + timeout_val * HZ;
+		param->deadline = deadline;
+		param->sched_priority = 0;
+		update_timer(deadline);
+		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
+		down_read_rp();
+		current->netlock_type = NET_LOCK_USE;
+		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (read) \n");
+		printk(KERN_DEBUG "NET_LOCK: Setting scheduler for : %d\n",
+				pid);
+		current->prev_policy = current->policy;
+		current->prev_prio = current->prio;
+		current->prev_rt_priority = current->rt_priority;
+		current->prev_normal_prio = current->normal_prio;
+		returnval = sched_setscheduler(current, SCHED_EDF, param);
+		printk(KERN_DEBUG "NET_LOCK: set_sched return = %d\n",
+				returnval);
+		kfree(param);
+		if (returnval == 0)
+			return 0;
+		else
+			return -1;
+	} else if (type == NET_LOCK_SLEEP) {
+		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
+		down_write_rp();
+		current->netlock_type = NET_LOCK_SLEEP;
+		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
+		earliest_deadline = ULONG_MAX;
+		return 0;
+	} else {
+		printk(KERN_DEBUG "NET_LOCK: invalid net_lock type.\n");
+		return -1;
+	}
+}
+
+/* int net_unlock(void) */
+SYSCALL_DEFINE0(net_unlock)
+{
+	struct sched_param *param;
+	int returnval;
+	if (current->netlock_type == NET_LOCK_USE) {
+		up_read_rp();
+		atomic_dec(&use_num);
+		param = kmalloc(sizeof(struct sched_param), GFP_KERNEL);
+		if (param == NULL) {
+			printk(KERN_DEBUG "NETLOCK: failed to allocate memory for set_sched param.\n");
+			return -EINVAL;
+		}
+		printk(KERN_DEBUG "NETLOCK: allocated param memory.\n");
+		current->prio = current->prev_prio;
+		current->normal_prio = current->prev_normal_prio;
+		current->rt_priority = current->prev_rt_priority;
+		param->sched_priority = current->prev_rt_priority;
+		returnval = sched_setscheduler(current,
+					current->prev_policy, param);
+		kfree(param);
+		if (returnval != 0)
+			return -1;
+		printk(KERN_DEBUG "NET_LOCK: radio rw lock (read) is released.\n");
+		return 0;
+	} else if (current->netlock_type == NET_LOCK_SLEEP) {
+		up_write_rp();
+		printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
+		return 0;
+	} else {
+		printk(KERN_DEBUG "NET_LOCK: invalid net_lock type.\n");
+		return -1;
+	}
+}
+
+void do_nothing(unsigned long data)
+{
+	return;
+}
+
+/* int net_lock_wait_timeout() */
+SYSCALL_DEFINE0(net_lock_wait_timeout)
+{
+	init_timer(&edf_timer);
+	edf_timer.expires = earliest_deadline;
+	edf_timer.data = 0;
+	edf_timer.function = do_nothing;
+	add_timer(&edf_timer);
+	/* block before timeout */
+	while (time_before(jiffies, earliest_deadline))
+		cond_resched();
+	return 0;
+}
-- 
1.7.9.5


From 342d7433f1feffbcd93912e6645d1eb9cea6c2d8 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 10:43:11 -0400
Subject: [PATCH 80/99] -included header file "linux/netlock.h"

---
 kernel/netlock.c |    8 +-------
 1 file changed, 1 insertion(+), 7 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index f43dd4f..378de16 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -7,6 +7,7 @@
 #include <linux/syscalls.h>
 #include <linux/timer.h>
 #include <linux/types.h>
+#include "linux/netlock.h"
 
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
@@ -59,13 +60,6 @@ int up_write_rp()
 	return 0;
 }
 
-
-enum __netlock_t {
-	NET_LOCK_USE,
-	NET_LOCK_SLEEP
-};
-typedef enum __netlock_t netlock_t;
-
 void update_timer(unsigned long new_deadline)
 {
 	earliest_deadline = min(new_deadline, earliest_deadline);
-- 
1.7.9.5


From 224279a761c1520de1911434f8dd41d19ac0613b Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 10:50:31 -0400
Subject: [PATCH 81/99] added notes in README_HW3.txt

---
 README_HW3.txt |   10 ++++++++--
 1 file changed, 8 insertions(+), 2 deletions(-)

diff --git a/README_HW3.txt b/README_HW3.txt
index 65faef5..d1439a4 100644
--- a/README_HW3.txt
+++ b/README_HW3.txt
@@ -2,7 +2,7 @@ README for OS Homework Assignment 3
 
 #Files:
 * kernel/netlock.c
-	* net_lock - the syscall 333 that we added, which is a reader-writer synchronization primitive that priorizes use over sleeping and sets the current process to our edf scheduler.
+	* net_lock - the syscall 333 that we added, which is a reader-writer synchronization primitive that priorizes use over sleep and sets the current process to our edf scheduler.
 	* net_unlock - the syscall 334 that releases the reader-writer lock and puts the current process to its previous scheduler.
 	* net_lock_wait_timeout - the syscall 335 we added that wake up the sleeper at the earliest timeout.
 
@@ -24,7 +24,10 @@ README for OS Homework Assignment 3
 	* defined SCHED_EDF as policy 6.
 	* added unsigned long deadline field to sched_param.
 	* added struct sche_edf_entity.
-	* added int previous_rt_priority, int previous_normal_prio, int previous_prio, int previous_policy, int netlock_type, struct sched_edf_entity field to task_struct;
+	* added int prev_rt_priority, int prev_normal_prio, int prev_prio, int prev_policy, int netlock_type, struct sched_edf_entity field to task_struct;
+
+* include/linux/netlock.h
+	* added enum __netlock_t.
 
 * user_tests/Makefile
 
@@ -35,4 +38,7 @@ README for OS Homework Assignment 3
 * user_tests/my_net_app.c
 	* contains the my_net_app user program that aquires user lock and releases the lock after for loop.
 	* to build: >> make
+
+* user_tests/netlock.h
+	* added enum __netlock_t.
  
-- 
1.7.9.5


From c4051249880cd4d8b064272ebe962192d4e8a8d1 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 13:03:54 -0400
Subject: [PATCH 82/99] added "void" as parameters in netlock.c to remove the
 warnings

---
 kernel/netlock.c |    8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 378de16..7e520fc 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -26,7 +26,7 @@ static DECLARE_MUTEX(rw_mutex);
 static DECLARE_MUTEX(count_mutex);
 unsigned long read_count;
 
-int down_read_rp()
+int down_read_rp(void)
 {
 	down(&count_mutex);
 	read_count++;
@@ -37,7 +37,7 @@ int down_read_rp()
 	return 0;
 }
 
-int up_read_rp()
+int up_read_rp(void)
 {
 	down(&count_mutex);
 	read_count--;
@@ -48,13 +48,13 @@ int up_read_rp()
 	return 0;
 }
 
-int down_write_rp()
+int down_write_rp(void)
 {
 	down(&rw_mutex);
 	return 0;
 }
 
-int up_write_rp()
+int up_write_rp(void)
 {
 	up(&rw_mutex);
 	return 0;
-- 
1.7.9.5


From afbf4744c667b3664d3d8dc178e67b2742402347 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 14:14:49 -0400
Subject: [PATCH 83/99] -modified to give user higher priorities than sleepers
 -added conditions to judge if timer has been
 initialized

---
 kernel/netlock.c |    6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 7e520fc..f78d8ee 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -96,7 +96,9 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		deadline = jiffies + timeout_val * HZ;
 		param->deadline = deadline;
 		param->sched_priority = 0;
-		update_timer(deadline);
+		/* if edf_timer has not been initialized yet, edf_timer.expires is 0 */
+		if (edf_timer.expires != 0)
+			update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
 		down_read_rp();
 		current->netlock_type = NET_LOCK_USE;
@@ -117,6 +119,8 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
+		while (atomic_read(&use_num) > 0)
+			schedule();
 		down_write_rp();
 		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
-- 
1.7.9.5


From ba0c43a2c1d4d085ef35057a9e1bd0b73af1cc8b Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 15:18:23 -0400
Subject: [PATCH 84/99] -added a mutex around setting the earliest deadline to
 protect from race conditions.

---
 kernel/netlock.c |    3 +++
 1 file changed, 3 insertions(+)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index f78d8ee..858291f 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -12,6 +12,7 @@
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
 atomic_t use_num;
+DECLARE_MUTEX(deadline_mutex);
 /*
  * ============================================================================
  * This starts the implementation of a read write semaphore that favors
@@ -62,9 +63,11 @@ int up_write_rp(void)
 
 void update_timer(unsigned long new_deadline)
 {
+	down(&deadline_mutex);
 	earliest_deadline = min(new_deadline, earliest_deadline);
 	if (earliest_deadline == new_deadline)
 		mod_timer(&edf_timer, earliest_deadline);
+	up(&deadline_mutex);
 }
 
 /* int net_lock(netlock_t type, u_int16_t timeout_val) */
-- 
1.7.9.5


From 4468f95246ef3721b8551c0eea69d67037252f81 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 15:36:51 -0400
Subject: [PATCH 85/99] -removed print statement form __setscheduler.

---
 kernel/sched.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/kernel/sched.c b/kernel/sched.c
index 434fed5..ee95617 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -5299,7 +5299,7 @@ __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 {
 
 	BUG_ON(p->se.on_rq);
-	printk(KERN_DEBUG "Setting scheduler for %d\n", p->pid);
+	/*printk(KERN_DEBUG "Setting scheduler for %d\n", p->pid);*/
 
 	p->policy = policy;
 	switch (p->policy) {
-- 
1.7.9.5


From 23b3815b9cec0a71dfdcff54afdb2b4c4dbebb07 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 15:55:14 -0400
Subject: [PATCH 86/99] -added parts about sched_edf.c to the README_HW3

---
 README_HW3.txt |    6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/README_HW3.txt b/README_HW3.txt
index d1439a4..eac3ff8 100644
--- a/README_HW3.txt
+++ b/README_HW3.txt
@@ -5,10 +5,12 @@ README for OS Homework Assignment 3
 	* net_lock - the syscall 333 that we added, which is a reader-writer synchronization primitive that priorizes use over sleep and sets the current process to our edf scheduler.
 	* net_unlock - the syscall 334 that releases the reader-writer lock and puts the current process to its previous scheduler.
 	* net_lock_wait_timeout - the syscall 335 we added that wake up the sleeper at the earliest timeout.
+    * We decided to use a read write semaphore that gives reader priority because it seemed like a natural extension of the net_lock.  We could have implemented our own wait queue but this seemed simpler and it uses a wait queue in the background when semaphores put processes to sleep.
 
 * kernel/sched_edf.c
-
-
+    * this file contains all of the functionality needed for the new scheduler module.
+    * we used the built in rbtree as the priority queue instead of writing our own data structure like a heap and we use the deadline as the key to the rbtree.
+    * we use the same bottom left cacheing that the cfs scheduler does.
 	
 * kernel/sched.c
 	* added struct edf_rq to sched.c
-- 
1.7.9.5


From 9308d4abe950b1e3f4c91fc9619913e670da0b3c Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 17:00:43 -0400
Subject: [PATCH 87/99] -added lock to try and fix race condition.

---
 kernel/sched.c     |    2 ++
 kernel/sched_edf.c |    4 ++++
 2 files changed, 6 insertions(+)

diff --git a/kernel/sched.c b/kernel/sched.c
index ee95617..c412d7b 100644
--- a/kernel/sched.c
+++ b/kernel/sched.c
@@ -406,6 +406,7 @@ struct edf_rq {
 	struct rb_root radio_task_root;
 	struct rb_node *bottom_left;
 	struct rq *rq;
+	spinlock_t edf_rq_lock;
 
 	/* We want to have a list of all tasks outside of the rb tree. */
 	struct list_head all_tasks;
@@ -8317,6 +8318,7 @@ static void init_edf_rq(struct edf_rq *edf_rq, struct rq *rq)
 
 	/* set up the rb tree and task list. */
 	edf_rq->radio_task_root = RB_ROOT;
+	spin_lock_init(&edf_rq->edf_rq_lock);
 	INIT_LIST_HEAD(&edf_rq->all_tasks);
 
 }
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index d530566..946790e 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -67,7 +67,9 @@ static void enqueue_task_edf(struct rq *rq, struct task_struct *p, int wakeup)
 		if (edf_se->erq == NULL)
 			edf_se->erq = &(rq->edf);
 		erq = edf_se->erq;
+		spin_lock(&erq->edf_rq_lock);
 		enqueue_edf_entity(erq, edf_se, wakeup);
+		spin_unlock(&erq->edf_rq_lock);
 	}
 }
 
@@ -131,7 +133,9 @@ static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
 
 	for_each_sched_edf_entity(ee) {
 		erq = ee->erq;
+		spin_lock(&erq->edf_rq_lock);
 		dequeue_entity_edf(erq, ee, -1);
+		spin_unlock(&erq->edf_rq_lock);
 	}
 }
 static void yield_task_edf(struct rq *rq)
-- 
1.7.9.5


From 8496099a780218a04b10850319adba83127bbead Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 19:19:57 -0400
Subject: [PATCH 88/99] -changed the data type of spin to long

---
 user_tests/my_net_app.c |    4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index 44b60f5..1056204 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -21,9 +21,9 @@ int main(int argc, char *argv[])
 	pid_t pid;
 	int wait;
 	int timeout;
-	int spin;
 	int flag;
 	int i;
+	long spin;
 	if (strcmp(argv[0], "./my_net_app") == 0) {
 		if (argc != 4) {
 			printf("Please provide a valid command.\n");
@@ -32,7 +32,7 @@ int main(int argc, char *argv[])
 		}
 		wait = atoi(argv[1]);
 		timeout = atoi(argv[2]);
-		spin = atoi(argv[3]);
+		spin = atol(argv[3]);
 		if (wait < 0 || timeout < 0 || spin < 0) {
 			printf("Please provide positive values.\n");
 			return -1;
-- 
1.7.9.5


From bdadfb238b68d94e942f789ad0d624311aa4dbc4 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 20:49:19 -0400
Subject: [PATCH 89/99] fixed data type bugs in my_net_app.c

---
 user_tests/my_net_app.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index 1056204..155959c 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -22,7 +22,7 @@ int main(int argc, char *argv[])
 	int wait;
 	int timeout;
 	int flag;
-	int i;
+	long i;
 	long spin;
 	if (strcmp(argv[0], "./my_net_app") == 0) {
 		if (argc != 4) {
-- 
1.7.9.5


From 4c68d0647ae19d8f901cc0b6ba235ba017520917 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 21:04:20 -0400
Subject: [PATCH 90/99] -added chance ofr passing on scheduler ot
 pick_next_task. -updated readme.

---
 README_HW3.txt     |    1 +
 kernel/sched_edf.c |   24 ++++++++++++------------
 2 files changed, 13 insertions(+), 12 deletions(-)

diff --git a/README_HW3.txt b/README_HW3.txt
index eac3ff8..ab43c82 100644
--- a/README_HW3.txt
+++ b/README_HW3.txt
@@ -11,6 +11,7 @@ README for OS Homework Assignment 3
     * this file contains all of the functionality needed for the new scheduler module.
     * we used the built in rbtree as the priority queue instead of writing our own data structure like a heap and we use the deadline as the key to the rbtree.
     * we use the same bottom left cacheing that the cfs scheduler does.
+    * we return NULL with a probability of 20% from pick_next_task function.  The assignment said that our scheduler should pass 20% of the time and pick_next_task is the entry point from the scheduler.
 	
 * kernel/sched.c
 	* added struct edf_rq to sched.c
diff --git a/kernel/sched_edf.c b/kernel/sched_edf.c
index 946790e..bdf10e6 100644
--- a/kernel/sched_edf.c
+++ b/kernel/sched_edf.c
@@ -103,22 +103,13 @@ static void check_preempt_curr_edf(struct rq *rq, struct task_struct *p,
 	 *
 	 */
 
-	unsigned char rand_byte;
-	unsigned char limit;
 	unsigned long curr_deadline;
 	unsigned long new_deadline;
 
-	limit = 205; /* 2^8*.8 ~= 205. */
-	get_random_bytes(&rand_byte, 1);
-
-	if (rand_byte < limit) {
-		curr_deadline = get_deadline(rq->curr);
-		new_deadline = get_deadline(p);
-		if (new_deadline < curr_deadline)
-			resched_task(rq->curr);
-	} else {
+	curr_deadline = get_deadline(rq->curr);
+	new_deadline = get_deadline(p);
+	if (new_deadline < curr_deadline)
 		resched_task(rq->curr);
-	}
 }
 
 static void dequeue_task_edf(struct rq *rq, struct task_struct *p, int sleep)
@@ -168,6 +159,15 @@ static struct sched_edf_entity *pick_next_entity_edf(struct edf_rq *erq)
  */
 static struct task_struct *pick_next_task_edf(struct rq *rq)
 {
+
+
+	unsigned char rand_byte;
+	unsigned char limit;
+	limit = 205; /* 2^8*.8 ~= 205. */
+	get_random_bytes(&rand_byte, 1);
+	if (rand_byte > limit)
+		return NULL;
+
 	struct sched_edf_entity *next_entity = pick_next_entity_edf(&rq->edf);
 
 	if (next_entity == NULL)
-- 
1.7.9.5


From ff28e47ea7f32bcbf73b2bf5a2aa15c21f08f083 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 22:31:10 -0400
Subject: [PATCH 91/99] -handled jiffies wraparound

---
 kernel/netlock.c |   42 ++++++++++++++++++++++++++++++++++++------
 1 file changed, 36 insertions(+), 6 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 858291f..1bc90e1 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -11,6 +11,8 @@
 
 unsigned long earliest_deadline = ULONG_MAX;
 struct timer_list edf_timer;
+int can_exit;
+atomic_t wraparound_flag;
 atomic_t use_num;
 DECLARE_MUTEX(deadline_mutex);
 /*
@@ -64,9 +66,33 @@ int up_write_rp(void)
 void update_timer(unsigned long new_deadline)
 {
 	down(&deadline_mutex);
-	earliest_deadline = min(new_deadline, earliest_deadline);
-	if (earliest_deadline == new_deadline)
+	if (new_deadline > jiffies) {
+		/* wraparound_flag
+		 * 0:current earliest_deadline not wraparound
+		 * 1:current earliest_deadline wraparound
+		 */
+		if (atomic_read(&wraparound_flag) == 0) {
+			earliest_deadline = min(new_deadline, earliest_deadline);
+		} else {
+			earliest_deadline = new_deadline;
+			atomic_set(&wraparound_flag, 0);
+			add_timer(&edf_timer);
+		}
 		mod_timer(&edf_timer, earliest_deadline);
+	} else {
+		if (jiffies < earliest_deadline && earliest_deadline != ULONG_MAX)
+			;
+		else {
+			atomic_set(&wraparound_flag, 1);
+			del_timer_sync(&edf_timer);
+			schedule_timeout(ULONG_MAX - jiffies);
+			if (atomic_read(&wraparound_flag) == 1) {
+				add_timer(&edf_timer);
+				earliest_deadline = min(new_deadline, earliest_deadline);
+				mod_timer(&edf_timer, earliest_deadline);
+			}
+		}
+	}
 	up(&deadline_mutex);
 }
 
@@ -121,9 +147,9 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		else
 			return -1;
 	} else if (type == NET_LOCK_SLEEP) {
-		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
 		while (atomic_read(&use_num) > 0)
 			schedule();
+		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (write) \n");
 		down_write_rp();
 		current->netlock_type = NET_LOCK_SLEEP;
 		printk(KERN_DEBUG "NET_LOCK: acquired radio rw lock (write) \n");
@@ -163,6 +189,8 @@ SYSCALL_DEFINE0(net_unlock)
 	} else if (current->netlock_type == NET_LOCK_SLEEP) {
 		up_write_rp();
 		printk(KERN_DEBUG "NET_LOCK: radio rw lock (write) is released.\n");
+		atomic_set(&wraparound_flag, 0);
+		can_exit = 0;
 		return 0;
 	} else {
 		printk(KERN_DEBUG "NET_LOCK: invalid net_lock type.\n");
@@ -170,8 +198,9 @@ SYSCALL_DEFINE0(net_unlock)
 	}
 }
 
-void do_nothing(unsigned long data)
+void ready_to_exit(unsigned long data)
 {
+	can_exit = 1;
 	return;
 }
 
@@ -181,10 +210,11 @@ SYSCALL_DEFINE0(net_lock_wait_timeout)
 	init_timer(&edf_timer);
 	edf_timer.expires = earliest_deadline;
 	edf_timer.data = 0;
-	edf_timer.function = do_nothing;
+	edf_timer.function = ready_to_exit;
 	add_timer(&edf_timer);
 	/* block before timeout */
-	while (time_before(jiffies, earliest_deadline))
+	while (!can_exit) {
 		cond_resched();
+	}
 	return 0;
 }
-- 
1.7.9.5


From d24946bd577bbec6c675dc169a16f8d6f4ac18ae Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 22:52:20 -0400
Subject: [PATCH 92/99] -added buggy code comments

---
 kernel/netlock.c |    6 ++++++
 1 file changed, 6 insertions(+)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 1bc90e1..0c18a32 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -73,6 +73,11 @@ void update_timer(unsigned long new_deadline)
 		 */
 		if (atomic_read(&wraparound_flag) == 0) {
 			earliest_deadline = min(new_deadline, earliest_deadline);
+	/* 
+	 * The following codes are executed when jiffies wraparound happens.
+	 * We have no ways to test this case.
+	 */
+	/*** FOLLOWING MAY BE BUGGY CODE ***/
 		} else {
 			earliest_deadline = new_deadline;
 			atomic_set(&wraparound_flag, 0);
@@ -92,6 +97,7 @@ void update_timer(unsigned long new_deadline)
 				mod_timer(&edf_timer, earliest_deadline);
 			}
 		}
+	/*** ABOVE MAY BE BUGGY CODE ***/
 	}
 	up(&deadline_mutex);
 }
-- 
1.7.9.5


From 708409c1fccaf4ac9ba560951e2e92fa4b31d223 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 22:57:45 -0400
Subject: [PATCH 93/99] added notes in pg_cover.txt

---
 pg_cover.txt |    5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/pg_cover.txt b/pg_cover.txt
index 1690c79..e491497 100644
--- a/pg_cover.txt
+++ b/pg_cover.txt
@@ -91,7 +91,10 @@ automatically be given a zero for those parts of the assignment
        determine which line then put BOLD comments around the 
        different possible lines it could be executing. 
        
-     
+    	-In update_timer() of netlock.c, we added conditionals that should be 
+	 used to handles cases when jiffies wraparound happens. However, since
+	 we cannot control the values of jiffies, the validity of codes cannot
+	 be verified.
      
      * Do you believe the bug is in this procedure? If not, do you think
        it's in a procedure that called it, or in some procedure that was
-- 
1.7.9.5


From 88b7d3dc3496fde3876947d87f5cb7ee761924fd Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 23:17:50 -0400
Subject: [PATCH 94/99] -added contributions to cover.

---
 pg_cover.txt |   18 +++++++++++++++++-
 1 file changed, 17 insertions(+), 1 deletion(-)

diff --git a/pg_cover.txt b/pg_cover.txt
index e491497..5a1c42c 100644
--- a/pg_cover.txt
+++ b/pg_cover.txt
@@ -38,7 +38,23 @@ We certify that:
        
 Member Contributions:
 #Riley Spahn(rbs2151):
-
+    * kernel/sched_edf.c
+        * enqueue_task_edf
+        * dequeue_task_edf
+        * check_preempt_curr_edf
+        * pick_next_task_edf
+        * select_task_rq_edf
+        * task_tick_edf
+        * task_new_edf
+        * switched_to_edf
+    * include/linux/sched.h
+        * struct sched_edf_entity
+    * kernel/sched.c
+        * struct edf_rq
+        * __setscheduler
+        * _sched_setscheduler
+        * init_edf_rq
+        * sched_init
 
 
 #Pei Qin(pq2117):
-- 
1.7.9.5


From 6398161c75dd2977a493e594976adae56a32f943 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 23:24:55 -0400
Subject: [PATCH 95/99] -added printf info -checkpatch netlock.c

---
 kernel/netlock.c        |   20 ++++++++++++--------
 user_tests/my_net_app.c |    1 +
 2 files changed, 13 insertions(+), 8 deletions(-)

diff --git a/kernel/netlock.c b/kernel/netlock.c
index 0c18a32..ba164f8 100644
--- a/kernel/netlock.c
+++ b/kernel/netlock.c
@@ -14,7 +14,7 @@ struct timer_list edf_timer;
 int can_exit;
 atomic_t wraparound_flag;
 atomic_t use_num;
-DECLARE_MUTEX(deadline_mutex);
+static DECLARE_MUTEX(deadline_mutex);
 /*
  * ============================================================================
  * This starts the implementation of a read write semaphore that favors
@@ -72,8 +72,9 @@ void update_timer(unsigned long new_deadline)
 		 * 1:current earliest_deadline wraparound
 		 */
 		if (atomic_read(&wraparound_flag) == 0) {
-			earliest_deadline = min(new_deadline, earliest_deadline);
-	/* 
+			earliest_deadline =
+				min(new_deadline, earliest_deadline);
+	/*
 	 * The following codes are executed when jiffies wraparound happens.
 	 * We have no ways to test this case.
 	 */
@@ -85,7 +86,8 @@ void update_timer(unsigned long new_deadline)
 		}
 		mod_timer(&edf_timer, earliest_deadline);
 	} else {
-		if (jiffies < earliest_deadline && earliest_deadline != ULONG_MAX)
+		if (jiffies < earliest_deadline &&
+			earliest_deadline != ULONG_MAX)
 			;
 		else {
 			atomic_set(&wraparound_flag, 1);
@@ -93,7 +95,8 @@ void update_timer(unsigned long new_deadline)
 			schedule_timeout(ULONG_MAX - jiffies);
 			if (atomic_read(&wraparound_flag) == 1) {
 				add_timer(&edf_timer);
-				earliest_deadline = min(new_deadline, earliest_deadline);
+				earliest_deadline =
+					min(new_deadline, earliest_deadline);
 				mod_timer(&edf_timer, earliest_deadline);
 			}
 		}
@@ -131,7 +134,9 @@ SYSCALL_DEFINE2(net_lock, netlock_t, type, u_int16_t, timeout_val)
 		deadline = jiffies + timeout_val * HZ;
 		param->deadline = deadline;
 		param->sched_priority = 0;
-		/* if edf_timer has not been initialized yet, edf_timer.expires is 0 */
+		/* if edf_timer has not been initialized yet, edf_timer.expires
+		 * is 0
+		 */
 		if (edf_timer.expires != 0)
 			update_timer(deadline);
 		printk(KERN_DEBUG "NET_LOCK: trying to acquire radio rw lock (read) \n");
@@ -219,8 +224,7 @@ SYSCALL_DEFINE0(net_lock_wait_timeout)
 	edf_timer.function = ready_to_exit;
 	add_timer(&edf_timer);
 	/* block before timeout */
-	while (!can_exit) {
+	while (!can_exit)
 		cond_resched();
-	}
 	return 0;
 }
diff --git a/user_tests/my_net_app.c b/user_tests/my_net_app.c
index 155959c..31ac9bb 100644
--- a/user_tests/my_net_app.c
+++ b/user_tests/my_net_app.c
@@ -68,6 +68,7 @@ int main(int argc, char *argv[])
 			printf("Requiring unlock failed.\n");
 			return -1;
 		}
+		printf("my_net_app finished pid:%d\n", pid);
 	}
 	return 0;
 }
-- 
1.7.9.5


From 07f7a942cc7d4a87c609d454949502215ba777e2 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 23:25:00 -0400
Subject: [PATCH 96/99] added to pg_cover.txt

---
 pg_cover.txt |   11 +++++++++--
 1 file changed, 9 insertions(+), 2 deletions(-)

diff --git a/pg_cover.txt b/pg_cover.txt
index 5a1c42c..ad5f5ad 100644
--- a/pg_cover.txt
+++ b/pg_cover.txt
@@ -55,6 +55,8 @@ Member Contributions:
         * _sched_setscheduler
         * init_edf_rq
         * sched_init
+    * kernel/netlock.c
+        * helped on various locking functionality.
 
 
 #Pei Qin(pq2117):
@@ -81,13 +83,18 @@ automatically be given a zero for those parts of the assignment
        for the second time, or when a certain procedure gets called with
        a certain argument or when a particular global variable has a
        particular value.
-       
-     
+
+        * We are seeing program hangs when my_net_app is trying to unlock the
+        net_lock. We think that it has something to do with overflow in the
+        timer.
 
 
 
      * When the program fails, what error message or other output does it
        generate?
+
+       * We added an message to the end of my_net_app that prints when it is
+       finished. You can assume that if this does not print then 
        
      
      
-- 
1.7.9.5


From 7d60c22809180459e1610d7b964ed04ff5ad3610 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 23:29:56 -0400
Subject: [PATCH 97/99] added notes to coversheet.

---
 pg_cover.txt |    5 +++++
 1 file changed, 5 insertions(+)

diff --git a/pg_cover.txt b/pg_cover.txt
index ad5f5ad..2209894 100644
--- a/pg_cover.txt
+++ b/pg_cover.txt
@@ -126,4 +126,9 @@ automatically be given a zero for those parts of the assignment
        asking you to get this right. We're just asking you to give a
        plausible answer with a plausible justification, enough to show
        that you're developing sound reasoning processes for diagnosis.
+            
+        * We do believe that the bug is associated with the net_monitor
+        because the same set of my_net_app runs will finish when running
+        without the net_app.  Because of this we feel that it is more likely
+        in the net_monitor than in the scheduler.
  
-- 
1.7.9.5


From d0f85d236817844e765023e8c78157330e30df08 Mon Sep 17 00:00:00 2001
From: Pei Qin <pq2117@columbia.edu>
Date: Sun, 31 Mar 2013 23:31:55 -0400
Subject: [PATCH 98/99] added notes in pg_cover.txt

---
 pg_cover.txt |   24 +++++++++++++++++++++++-
 1 file changed, 23 insertions(+), 1 deletion(-)

diff --git a/pg_cover.txt b/pg_cover.txt
index ad5f5ad..96886d2 100644
--- a/pg_cover.txt
+++ b/pg_cover.txt
@@ -60,12 +60,34 @@ Member Contributions:
 
 
 #Pei Qin(pq2117):
-
+	*Added system calls.
+	*Wrote the timer.
+		*handled jiffies wraparound.(untested)
+	*Wrote the most part of my_net_app().
+	*Modified net_monitor().
+	*Participated in completing net_lock() and net_unlock(), including:
+		*implementation of timer
+		*implementation of semaphores
+		*storing the previous policy and priority of current process
+		*assigning users higher priorities than sleepers
+	*Wrote dequeue_task_edf() in EDF scheduler.
+	*Added essential members in related structs.
 
 
 #Meng Yao(my2372):
 
 
+* participated in writing net_lock and net_unlock syscall, including:
+        * implemented initial version of reader-writer lock using two semaphores
+        * stored and restored current process's priority and policy
+        * set process to new edf scheduler
+	*modified timer
+* participated in implementing edf scheduler, work including:
+        * modified struct edf_rq in sched.c
+        * modified condition check of SCHED_EDF in __setscheduler
+        * modified struct sche_edf_entity.
+* wrote initial version of net_monitor.c
+* wrote initial version of my_net_app.chile (atomic_read(&use_num) > 0)
 
 
 
-- 
1.7.9.5


From b2259f74e9cbcfe4e5c83388212515535bf70996 Mon Sep 17 00:00:00 2001
From: Riley Spahn <rileyspahn@gmail.com>
Date: Sun, 31 Mar 2013 23:36:38 -0400
Subject: [PATCH 99/99] -added to pg_cover.

---
 pg_cover.txt |   11 ++++++++---
 1 file changed, 8 insertions(+), 3 deletions(-)

diff --git a/pg_cover.txt b/pg_cover.txt
index 69162e3..40533b4 100644
--- a/pg_cover.txt
+++ b/pg_cover.txt
@@ -116,17 +116,20 @@ automatically be given a zero for those parts of the assignment
        generate?
 
        * We added an message to the end of my_net_app that prints when it is
-       finished. You can assume that if this does not print then 
+       finished. You can assume that if this does not print then something failed.
        
      
      
      
      * What does the error message mean? 
-       
+        * We are printing a positive message that prints upon successful completion.
+        An error message is inappropriate here because it hangs.
+        
      
      
      
      * When the program fails, which of your procedures is it running?
+        * It is running in the net_unlock function.
        
      
      
@@ -152,5 +155,7 @@ automatically be given a zero for those parts of the assignment
         * We do believe that the bug is associated with the net_monitor
         because the same set of my_net_app runs will finish when running
         without the net_app.  Because of this we feel that it is more likely
-        in the net_monitor than in the scheduler.
+        in the net_monitor than in the scheduler. It has been hard to debug
+        because print statementsare not guaranteed to print in the correct
+        order.
  
-- 
1.7.9.5

